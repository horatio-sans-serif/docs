[{"body":"  Welcome to the LocalStack Documentation!\nExplore and learn about LocalStack.   Get Started Install and run LocalStack on your machine, and discover the benefits of local cloud development.\n   Integrations Use your favorite cloud development framework with LocalStack: CDK, Terraform, Serverless, and more!\n   LocalStack in CI Use LocalStack in your Continuous Integration pipelines.\n   Local AWS Services Browse through the AWS Services that LocalStack emulates.\n   LocalStack Tools Learn how to use LocalStack Cloud Developer Tools to boost your efficiency.\n   Understanding LocalStack Learn how LocalStack works and how you can tweak it for your use case.\n      Featured guides and articles Here are some commonly asked questions and related articles.  How do I get started with LocalStack Pro? What are Local Cloud Pods and how do I use them? How LocalStack improves your Lambda developer experience Which AWS services does LocalStack support? How do I use the Serverless Framework with LocalStack?       Support Where can I get help?  Pro: individual support on Slack Community support on Slack Discussion forum on GitHub Bug reports on GitHub        ","categories":"","description":"","excerpt":"  Welcome to the LocalStack Documentation!\nExplore and learn about …","ref":"/overview/","tags":"","title":"Overview"},{"body":"This page summarizes the implemented APIs and features provided by LocalStack, as well as their level of parity with the real cloud (e.g., AWS) or managed service provider.\nCoverage Levels / Support Tiers LocalStack provides a variety of different features and cloud APIs (e.g., AWS), but the level of support and parity with the real system differs for the different services:\n Tier 1 (⭐⭐⭐⭐): Feature fully supported by LocalStack maintainers; feature is guaranteed to pass all or the majority of tests Tier 2 (⭐⭐⭐): Feature supports the majority of use cases (e.g., CRUD operations), but some advanced usages may not be fully supported Tier 3 (⭐⭐): Feature may be lightly tested (or not), and so it should be considered unstable Tier 4 (⭐): Feature is experimental, only partially supported or implemented Tier 5 (-): Feature is not currently implemented, but on our roadmap  In the coverage tables below, the features are marked with their respective availability across different LocalStack versions:\n Community version (default, if not marked) Pro version (marked with “Pro”) Enterprise version (marked with “Enterprise”)  AWS Feature Coverage    Service / Feature Coverage Level Terraform Tests Notes     ACM      Certificates ⭐⭐⭐     Tags ⭐⭐⭐⭐     Account Configuration ⭐⭐     Amplify (Pro)      Apps ⭐⭐⭐     Backend Environments ⭐⭐     Branches ⭐⭐     Deployments ⭐⭐⭐     Domain Associations -     Jobs ⭐⭐     Tags ⭐⭐⭐⭐     Webhooks ⭐⭐     API Gateway      API Keys ⭐⭐⭐     Authorizers (Pro) ⭐⭐⭐⭐     Base Path Mappings ⭐⭐⭐⭐     Deployments ⭐⭐⭐⭐     Documentation Parts ⭐⭐⭐     Documentation Versions ⭐⭐⭐     Domain Names ⭐⭐⭐     Gateway / Integration / Method Responses ⭐⭐⭐⭐     Integrations ⭐⭐⭐⭐     Methods ⭐⭐⭐⭐     Models ⭐⭐⭐     Request Validators ⭐⭐     Resources ⭐⭐⭐⭐     REST APIs ⭐⭐⭐⭐     Stages ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Usage Plans ⭐⭐⭐     Usage Plan Keys ⭐⭐⭐     VPC Links ⭐⭐⭐     API Gateway v2 (Pro)      APIs ⭐⭐⭐⭐     API Mappings ⭐⭐⭐     Authorizers ⭐⭐⭐⭐     Deployments ⭐⭐⭐⭐     Domain Names ⭐⭐⭐     Import APIs from OpenAPI specs ⭐⭐⭐     Integrations ⭐⭐⭐     Integration Responses ⭐⭐⭐     Models ⭐⭐⭐     Routes ⭐⭐⭐⭐     Route Responses ⭐⭐⭐     Stages ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     VPC Links ⭐⭐⭐     AppConfig (Pro)      Applications ⭐⭐⭐     Configuration Profiles ⭐⭐⭐⭐     Configurations ⭐⭐⭐     Deployment Strategies ⭐⭐⭐⭐     Deployments ⭐⭐⭐     Environments ⭐⭐⭐⭐     Hosted Configuration Versions ⭐⭐⭐     Tags ⭐⭐⭐⭐     Application Autoscaling (Pro)      Scalable Targets ⭐⭐⭐     Scaling Activities ⭐⭐     Scaling Policies ⭐⭐     Scheduled Actions ⭐⭐     AppSync (Pro)      API Caches ⭐⭐⭐     API Keys ⭐⭐⭐     Data Sources ⭐⭐⭐     Functions ⭐⭐⭐     GraphQL APIs ⭐⭐⭐⭐     Resolvers ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Types ⭐⭐⭐⭐     Athena (Pro)      Data Catalogs ⭐⭐     Databases ⭐⭐     Named Queries -     Prepared Statements ⭐⭐⭐     Query Executions ⭐⭐⭐     Table Metadata ⭐⭐     Tags ⭐⭐⭐⭐     Work Groups -     Backup (Pro)      Backup Jobs ⭐⭐⭐     Backup Plans ⭐⭐⭐     Backup Selections ⭐⭐⭐     Backup Vaults ⭐⭐⭐     Backup Vault Access Policies -     Backup Vault Notifications -     Global Settings -     Protected Resources -     Recovery Points ⭐⭐⭐     Tags -     Batch (Pro)      Compute Environments ⭐⭐⭐     Job Queues ⭐⭐⭐     Job Definitions ⭐⭐⭐     Jobs ⭐⭐⭐     Tags ⭐⭐⭐⭐     CloudFormation      Change Sets ⭐⭐⭐⭐     Stacks ⭐⭐⭐⭐     Stack Drifts -     Stack Events ⭐⭐⭐⭐     Stack Instances ⭐⭐⭐⭐     Stack Policies ⭐⭐⭐     Stack Resources ⭐⭐⭐⭐     Stack Sets ⭐⭐⭐⭐     Publishers -     Templates ⭐⭐⭐⭐     Type Activations ⭐⭐     CloudFront (Pro)      Cache Policies -     Distributions ⭐⭐⭐     Field Level Encryption -     Functions ⭐⭐⭐     Invalidations ⭐⭐⭐     Key Groups -     Monitoring Subscriptions -     Origin Access Identities ⭐⭐     Origin Request Policies ⭐⭐⭐     Public Keys -     Realtime Log Configs -     Streaming Distributions -     Tags ⭐⭐⭐⭐     CloudTrail (Pro)      Event Selectors ⭐⭐⭐     Insight Selectors -     Tags ⭐⭐⭐⭐     Trails ⭐⭐⭐     Start/Stop Logging ⭐⭐⭐     CloudWatch      Alarms ⭐⭐     Alarm Histories -     Anomaly Detectors -     Dashboards -     Insight Rules -     Metric Data ⭐⭐⭐⭐     Metric Statistics ⭐⭐⭐     Metric Streams -     Tags ⭐⭐⭐     CloudWatch Logs      Destinations ⭐⭐⭐⭐     Export Tasks ⭐⭐     Log Events ⭐⭐⭐⭐     Log Groups ⭐⭐⭐⭐     Log Streams ⭐⭐⭐⭐     Metric Filters ⭐⭐⭐     Queries ⭐⭐⭐     Query Definitions ⭐⭐     Resource Policies ⭐⭐⭐⭐     Retention Policies ⭐⭐⭐     Subscription Filters ⭐⭐⭐     Tags ⭐⭐⭐⭐     CodeCommit (Pro)      Approval Rules -     Blobs / Files / Folders ⭐⭐     Branches ⭐⭐     Comments -     Commits ⭐⭐     Merge Commits / Conflicts -     Pull Requests -     Repositories ⭐⭐⭐     Tags ⭐⭐⭐⭐     Cognito Identity (Pro)      Developer Identities -     Identities ⭐⭐⭐     Identity Pool Roles -     Identity Pools ⭐⭐⭐⭐     OpenID Tokens -     Tags -     Cognito Identity Provider (IdP) (Pro)      Admin APIs ⭐⭐⭐     Devices ⭐⭐     Auth Flows ⭐⭐⭐     Groups ⭐⭐⭐⭐     Lambda Triggers ⭐⭐⭐⭐     MFA Configs ⭐⭐⭐     Resource Servers -     Risk Configurations -     Identity Providers ⭐⭐⭐     User Import Jobs -     User Pool Clients ⭐⭐⭐⭐     User Pool Domains ⭐⭐     User Pools ⭐⭐⭐⭐     Users ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     DynamoDB      Backups (Pro) ⭐⭐⭐⭐     Batch Operations ⭐⭐⭐⭐     Global Tables ⭐⭐⭐⭐     Items ⭐⭐⭐⭐     Kinesis Streaming Destinations -     PartiQL Queries ⭐⭐⭐⭐     Query / Scan Operations ⭐⭐⭐⭐     Tables ⭐⭐⭐⭐     Table Replica Autoscaling -     Tags ⭐⭐⭐⭐     DynamoDB Streams      Records ⭐⭐⭐⭐     Shard Iterators ⭐⭐⭐⭐     Streams ⭐⭐⭐⭐     EC2      Classic Links ⭐⭐⭐     Customer Gateways ⭐⭐⭐     DHCP Options ⭐⭐⭐     Allocate/Deallocate Elastic IPs ⭐⭐⭐     Fleets ⭐⭐     Flow Logs ⭐⭐⭐     Images ⭐⭐     Internet Gateways ⭐⭐⭐     Local Gateway Routes ⭐⭐⭐     Key Pairs ⭐⭐⭐⭐     Launch Templates ⭐⭐⭐     NAT Gateways ⭐⭐⭐     Network ACLs ⭐⭐⭐     Network Interfaces ⭐⭐⭐     Reserved Instances ⭐⭐⭐     Route Tables / Routes ⭐⭐⭐     Scheduled Instances ⭐⭐⭐     Security Groups / Egress / Ingress ⭐⭐⭐⭐     Snapshots ⭐⭐⭐     Spot Instances ⭐⭐⭐     Start Instances as VMs (Pro) ⭐⭐     Subnets ⭐⭐⭐     Tags ⭐⭐⭐⭐     Traffic Mirrors ⭐⭐⭐     Transit Gateways ⭐⭐⭐     Volumes ⭐⭐⭐     VPC Endpoint Connections ⭐⭐⭐     VPC Peering Connections ⭐⭐⭐     VPCs ⭐⭐⭐⭐     VPN Gateways / Connections ⭐⭐⭐     ECR (Pro)      Images ⭐⭐⭐     Image Scans -     Lifecycle Policies ⭐⭐⭐⭐     Registries ⭐⭐⭐⭐     Registry Policies -     Replication Configurations -     Repositories ⭐⭐⭐⭐     Repository Policies ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     ECS (Pro)      Account Settings -     Attributes ⭐⭐⭐⭐     Capacity Providers -     Clusters ⭐⭐⭐⭐     Container Instances ⭐⭐⭐⭐     Services ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Task Definitions ⭐⭐⭐⭐     Task Sets ⭐⭐⭐     Tasks ⭐⭐⭐⭐     EKS (Pro)      AddOns -     Clusters ⭐⭐⭐     Fargate Profiles ⭐⭐     Identity Provider Configs -     Node Groups -     Tags ⭐⭐⭐⭐     Updates -     ElastiCache (Pro)      Cache Clusters (Memcached) -     Cache Parameter Groups ⭐⭐⭐⭐     Cache Security Groups ⭐⭐⭐⭐     Cache Subnet Groups ⭐⭐⭐⭐     Global Replication Groups -     Replication Groups ⭐⭐⭐⭐     Snapshots -     Tags ⭐⭐⭐⭐     Users / User Groups -     Elasticsearch Service      Cross-Cluster Search Connections -     Elasticsearch Domains ⭐⭐⭐⭐     Packages -     Reserved Instances -     Tags ⭐⭐⭐⭐     EMR (Pro)      Clusters ⭐⭐⭐⭐     Instance Fleets ⭐⭐⭐     Job Flow Steps ⭐⭐⭐     Managed Scaling Policies -     Notebook Executions -     Run Job Flows (Queries) ⭐⭐⭐     Security Configurations -     Studios -     Tags ⭐⭐⭐⭐     EventBridge (CloudWatch Events)      API Destinations ⭐⭐⭐⭐     Archives -     Connections -     Event Buses ⭐⭐⭐⭐     Event Sources ⭐⭐⭐⭐     Partner Event Sources -     Replays -     Rules ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Firehose      Delivery Streams ⭐⭐⭐⭐     Destinations ⭐⭐⭐⭐     Records ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Glue (Pro)      Classifiers ⭐⭐⭐     Connections ⭐⭐⭐     Crawlers ⭐⭐⭐     Databases ⭐⭐⭐     Dev Endpoints -     Jobs ⭐⭐⭐     ML Transforms -     Partitions ⭐⭐⭐     Registries ⭐⭐⭐     Schemas ⭐⭐⭐     Scripts -     Security Configurations ⭐⭐⭐     Tables ⭐⭐⭐     Triggers ⭐⭐⭐     Tags ⭐⭐⭐     User Defined Functions -     Workflows ⭐⭐⭐     IAM      Access Keys ⭐⭐⭐     Account Aliases ⭐⭐⭐     Credential Reports -     Groups ⭐⭐⭐⭐     Instance Profiles ⭐⭐⭐     Login Profiles ⭐⭐⭐     OIDC Providers -     Policies ⭐⭐⭐⭐     Roles ⭐⭐⭐⭐     SAML Providers -     Server Certificates ⭐⭐⭐     Service Linked Roles ⭐⭐⭐     Users ⭐⭐⭐⭐     Virtual MFA Devices ⭐⭐     IoT (IoT Analytics, IoT Data) (Pro)      Authorizers -     Billing Groups -     Certificates ⭐⭐     Channels ⭐⭐     Custom Metrics -     Datasets ⭐⭐⭐     Dimensions -     Domain Configurations -     Jobs ⭐⭐⭐     Jobs Executions ⭐⭐⭐     Jobs Templates -     Mitigation Actions -     Policies ⭐⭐⭐     Provisioning Claims / Templates ⭐⭐     Role Aliases -     Security Profiles -     Shadows ⭐⭐     Streams -     Tags ⭐⭐⭐⭐     Thing Groups ⭐⭐⭐     Thing Types ⭐⭐⭐     Things ⭐⭐⭐     Topic Rules ⭐⭐⭐     Kinesis      Records ⭐⭐⭐⭐     Split / Merge Shards ⭐⭐⭐⭐     Stream Consumers ⭐⭐⭐⭐     Stream Encryption -     Streams ⭐⭐⭐⭐     Subscribe to Shard ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     KMS      Aliases ⭐⭐⭐⭐     Custom Key Stores ⭐⭐⭐     Encrypt / Decrypt / Sign Data ⭐⭐⭐⭐     Grants -     Key Policies -     Keys ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Lambda      Aliases ⭐⭐⭐⭐     Code Signing Configs ⭐⭐     Custom Images (Pro) ⭐⭐⭐⭐     Event Invoke Configs ⭐⭐⭐⭐     Event Source Mappings ⭐⭐⭐⭐     Function Concurrencies ⭐⭐⭐     Functions ⭐⭐⭐⭐     Invoke Functions ⭐⭐⭐⭐     Layers (Pro) ⭐⭐⭐⭐     Permissions ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Managed Streaming for Kafka (MSK) (Pro)      Brokers ⭐⭐     Cluster Operations ⭐⭐     Clusters ⭐⭐⭐⭐     Configurations ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     MediaStore (Pro)      Access Logging -     Container Policies -     Containers ⭐⭐⭐     CORS Policies -     Lifecycle Policies -     Metric Policies -     Tags -     Neptune DB (Pro)      DB Clusters ⭐⭐⭐⭐     DB Cluster Endpoints ⭐⭐⭐⭐     DB Cluster Parameter Groups ⭐⭐⭐⭐     DB Cluster Snapshots -     Engine Default Parameters ⭐⭐     Event Subscriptions -     Events -     Tags -     QLDB (Pro)      Blocks ⭐⭐⭐     Digests ⭐⭐⭐     Journal Kinesis Streams ⭐⭐⭐     Journal S3 Exports ⭐⭐⭐     Ledgers ⭐⭐⭐⭐     Send Commands / Run Queries ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     RDS / Aurora Serverless (Pro)      DB/Cluster Parameter Groups ⭐⭐⭐     DB/Cluster Snapshots ⭐⭐⭐     DB Clusters/Instances ⭐⭐⭐⭐     DB Proxies ⭐⭐     DB Security/Subnet Groups ⭐⭐⭐     Event Subscriptions -     Option Groups ⭐⭐⭐⭐     Postgres AWS Extension Functions ⭐⭐⭐     Tags ⭐⭐⭐⭐     Redshift      Authorize/Revoke Access -     Cluster Parameter Groups ⭐⭐⭐     Cluster Snapshots ⭐⭐⭐     Clusters/Instances ⭐⭐⭐⭐     Event Subscriptions -     HSM Configurations -     Partners -     Security/Subnet Groups ⭐⭐⭐     Tags ⭐⭐⭐⭐     Usage Limits ⭐⭐     Route53      DNS Server Integration (Pro) ⭐⭐⭐⭐     Geo Locations -     Health Checks ⭐⭐     Hosted Zones ⭐⭐⭐⭐     Query Logging Configs -     Resource Record Sets ⭐⭐⭐⭐     Reusable Delegation Sets ⭐⭐⭐     Tags ⭐⭐⭐⭐     Traffic Policies ⭐⭐⭐     S3      Bucket ACLs ⭐⭐⭐     Bucket CORS ⭐⭐⭐     Bucket Encryptions ⭐⭐⭐     Bucket Lifecycles ⭐⭐⭐     Bucket Loggings ⭐⭐⭐     Bucket Metrics Configurations ⭐⭐⭐     Bucket Notifications ⭐⭐⭐     Bucket Ownership Controls ⭐⭐⭐     Bucket Policies ⭐⭐⭐     Bucket Replications ⭐⭐⭐     Bucket Request Payments ⭐⭐⭐     Bucket Versionings ⭐⭐⭐     Bucket Websites ⭐⭐⭐     Buckets ⭐⭐⭐⭐     Object Retentions ⭐⭐     Object Versions ⭐⭐⭐⭐     Objects ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Upload/Download Files ⭐⭐⭐⭐     SageMaker (Pro)      Actions ⭐⭐     Algorithms -     App Image Configs ⭐⭐     Apps ⭐⭐⭐     Artifacts ⭐⭐⭐     Associations -     Auto ML Jobs -     Code Repositories -     Compilation Jobs -     Contexts -     Data Quality Job Definitions -     Device Fleets -     Devices -     Domains -     Edge Packaging Jobs -     Endpoints / Endpoint Configs -     Experiments -     Feature Groups -     Flow Definitions -     Hyper Parameter Tuning Jobs -     Images / Image Versions -     Labelling Jobs -     Model Bias/Explainability Jobs -     Model Packages -     Models ⭐⭐     Monitoring Executions/Schedules -     Notebook Instances -     Pipeline Executions -     Pipelines -     Projects -     Tags -     Training Jobs -     Transform Jobs -     Trials -     User Profiles -     Workforces / Workteams -     SecretsManager      Resource Policies ⭐⭐⭐⭐     Secret Replications ⭐⭐     Secret Rotations ⭐⭐     Secrets ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     SES      Configuration Sets ⭐⭐⭐     Identities ⭐⭐     Identity Policies ⭐⭐     Quotas / Statistics ⭐⭐     Receipt Filters ⭐⭐⭐     Receipt Rules ⭐⭐⭐     Sending Emails via SMTP (Pro) ⭐⭐⭐⭐     Templates ⭐⭐⭐⭐     SNS      Platform Applications ⭐⭐⭐     Publish/Subscribe to Topics ⭐⭐⭐⭐     SMS Attributes / Sandbox Accounts ⭐⭐     Subscriptions ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     Topics ⭐⭐⭐⭐     SQS      Message Visibility ⭐⭐⭐⭐     Messages ⭐⭐⭐⭐     Permission ⭐⭐⭐     Queues ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     SSM      Associations ⭐⭐⭐     Calendar States ⭐⭐     Commands / Command Invocations ⭐⭐⭐     Compliance Items ⭐⭐     Documents ⭐⭐⭐     Inventory Entries -     Ops Metadata ⭐⭐     Parameters ⭐⭐⭐⭐     Resource Compliance Summaries -     Tags ⭐⭐⭐⭐     StepFunctions      Activities ⭐⭐⭐⭐     Executions / Execution History ⭐⭐⭐⭐     State Machines ⭐⭐⭐⭐     Tags ⭐⭐⭐⭐     STS      Assume Role (Pro) ⭐⭐⭐⭐     Get Access Key Info ⭐⭐⭐⭐     Get Caller Identity ⭐⭐⭐⭐     Session Tokens ⭐⭐⭐⭐     Timestream (Pro)      Databases ⭐⭐⭐     Run Query ⭐⭐⭐     Tables ⭐⭐⭐     Tags ⭐⭐⭐⭐     Write Records ⭐⭐⭐⭐     Transfer (Pro)      Accesses -     Security Policies -     Servers ⭐⭐⭐     SSH Public Keys ⭐⭐⭐     Tags -     Users ⭐⭐⭐     XRay (Pro)      Encryption Configs -     Groups ⭐⭐     Insights -     Sampling Rules ⭐⭐⭐     Service Graph -     Tags -     Telemetry Records ⭐⭐⭐⭐     Trace Graph -     Trace Segments / Summaries ⭐⭐⭐      API Persistence Coverage (Pro) The list below summarizes the APIs for which persistence has been implemented and (ideally) tested in the Pro version (list may not be exhaustive/complete). More details following soon.\n Amplify Athena Backup Cognito Identity Cognito Identity Provider DynamoDB EC2 Elastic File System Kinesis QLDB S3 Secrets Manager SNS SQS Route53 RDS Appconfig Appsync Lambda CloudFormation CloudFront CodeCommit Cost Explorer Glue IoT Lake Formation Serverless Repo SES STS  ","categories":"","description":"Overview of the implemented APIs and features provided by LocalStack\n","excerpt":"Overview of the implemented APIs and features provided by LocalStack\n","ref":"/aws/feature-coverage/","tags":"","title":"AWS Service Feature Coverage"},{"body":"Overview The AWS Command Line Interface (CLI) is a unified tool to manage AWS services from the command line. All CLI commands that access services that are implemented in LocalStack can be run against LocalStack.\nThere are two ways to use the CLI:\n Use our awslocal drop-in replacement: $ awslocal kinesis list-streams Configure AWS test environment variables and add the --endpoint-url=\u003clocalstack-url\u003e flag to your aws CLI invocations. For example: $ export AWS_ACCESS_KEY_ID=\"test\" $ export AWS_SECRET_ACCESS_KEY=\"test\" $ export AWS_DEFAULT_REGION=\"us-east-1\" $ aws --endpoint-url=http://localhost:4566 kinesis list-streams  AWS CLI Use the below command to install aws, if not installed already.\n$ pip install awscli Setting up local region and credentials to run LocalStack aws requires the region and the credentials to be set in order to run the aws commands. Create the default configuration and the credentials. Below key will ask for the Access key id, secret Access Key, region \u0026 output format. Config \u0026 credential file will be created under ~/.aws folder\n$ aws configure --profile default Note Please use test as value for AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to make pre-signed URLs for S3 buckets work. Our pre-signed URL signature verification algorithm validates the pre-signed URL and its expiration. You can configure credentials into the system environment using export command on Linux/Mac systems. You also can add credentials in ~/.aws/credentials file directly.\nexport AWS_ACCESS_KEY_ID=test export AWS_SECRET_ACCESS_KEY=test   LocalStack AWS CLI (awslocal) awslocal is a thin wrapper and a drop-in replacement for the aws command that runs commands directly against LocalStack (no need to specify --endpoint-url anymore). The source code can be found on GitHub: https://github.com/localstack/awscli-local\nInstallation You can install the awslocal command via pip:\n$ pip install awscli-local[ver1] Note that the command above also installs the latest version of the underlying AWS CLI version 1 (awscli) package. Use this command if you prefer to manage your own version of awscli (e.g., v1/v2) and install the wrapper script only: $ pip install awscli-local\nNote: Automatic installation of AWS CLI version 2 is currently not supported yet (at the time of writing there is no official pypi package for v2 available), but the awslocal technically also works with AWS CLI v2 (see this section for more details).  Usage The awslocal command has the same usage as the aws command. For detailed usage, please refer to the man pages of aws help.\nConfigurations You can use the following environment variables for configuration:\n   Variable Description     LOCALSTACK_HOST Set the hostname for the localstack instance. Useful when you have localstack is bound to another interface (i.e. docker-machine).   USE_SSL Whether to use https endpoint URLs (required if LocalStack has been started with USE_SSL=true enabled). Defaults to false.   DEFAULT_REGION Set the default region. Overrides AWS_DEFAULT_REGION environment variable.    Limitations Please note that there is a known limitation for using the cloudformation package ... command with the AWS CLI v2. The problem is that the AWS CLI v2 is not available as a package on pypi.org, but is instead shipped as a binary package that cannot be easily patched from awslocal. To work around this issue, you have 2 options:\n Downgrade to the v1 AWS CLI (this is the recommended approach) There is an inofficial way to install AWS CLI v2 from sources. We do not recommend this, but it is technically possible. Also, you should install these libraries in a Python virtualenv, to avoid version clashes with other libraries on your system:  $ virtualenv .venv $ . .venv/bin/activate $ pip install https://github.com/boto/botocore/archive/v2.zip https://github.com/aws/aws-cli/archive/v2.zip AWS CLI v2 Automatic installation of AWS CLI version 2 is currently not supported (at the time of writing there is no official pypi package for v2 available), but the awslocal technically also works with AWS CLI v2 (see this section for more details).\nAWS CLI v2 with Docker and LocalStack By default, the container running amazon/aws-cli is isolated from 0.0.0.0:4566 on the host machine, that means that aws-cli cannot reach localstack through your shell.\nTo ensure that the two docker containers can communicate create a network on the docker engine:\n$ docker network create localstack 0c9cb3d37b0ea1bfeb6b77ade0ce5525e33c7929d69f49c3e5ed0af457bdf123 Then modify the docker-compose.yml specifying the network to use:\nnetworks:default:external:name:\"localstack\"Run AWS Cli v2 docker container using this network (example):\n$ docker run --network localstack --rm -it amazon/aws-cli --endpoint-url=http://localstack:4566 lambda list-functions { \"Functions\": [] } If you use AWS CLI v2 from a docker container often, create an alias:\n$ alias laws='docker run --network localstack --rm -it amazon/aws-cli --endpoint-url=http://localstack:4566' So you can type:\n$ laws lambda list-functions { \"Functions\": [] } ","categories":"","description":"How to use the AWS Command Line Interface (CLI) with LocalStack.\n","excerpt":"How to use the AWS Command Line Interface (CLI) with LocalStack.\n","ref":"/integrations/aws-cli/","tags":"","title":"AWS Command Line Interface"},{"body":"LocalStack is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.\nLocalStack supports a growing number of AWS services, like AWS Lambda, S3, DynamoDB, Kinesis, SQS, SNS, and many more! The Pro version of LocalStack supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our ⭐ Feature Coverage page.\nLocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack’s Cloud Developer Tools.\nGet LocalStack Up and Running The first thing when getting started with LocalStack is to choose your preferred way of starting and managing your LocalStack instance.\nLocalStack currently provides the following options:\n  LocalStack CLI\nThe easiest way to start and manage LocalStack - either on your machine, in a Docker container on your machine, or even on a remote Docker host.\n  Docker\nUse the docker CLI to manually start the LocalStack Docker container.\n  Docker-Compose\nUse docker-compose to configure and start your LocalStack Docker container.\n  Helm\nUse helm to create a LocalStack deployment in a Kubernetes cluster.\n  LocalStack CLI The LocalStack CLI aims to simplify starting and managing LocalStack. It provides convenience features to start LocalStack on your local machine, as a Docker container on your machine, or even on a remote Docker host. In addition you can easily check the status or open a shell in your LocalStack instance if you want to take a deep-dive.\nPrerequisites Please make sure to install the following tools on your machine before moving on:\n python (Python 3.6 up to 3.9 is supported) pip (Python package manager) docker  Installation The easiest way to install the LocalStack CLI is via pip:\n$ python3 -m pip install localstack Note: Please do not use sudo or the root user - LocalStack should be installed and started entirely under a local non-root user. If you have problems with permissions in MacOS X Sierra, install with python3 -m pip install --user localstack.  Afterwards you should be able to use the LocalStack CLI in your terminal:\n$ localstack --help Usage: localstack [OPTIONS] COMMAND [ARGS]... The LocalStack Command Line Interface (CLI) Options: ... Troubleshooting The installation is successful, but I cannot execute localstack on my terminal. If you can successfully install LocalStack using pip but you cannot use it in your terminal, you most likely haven’t set up your operating system’s / terminal’s PATH variable (in order to tell them where to find programs installed via pip).\n If you are using Windows, you can enable the PATH configuration when installing Python, as described in the official docs of Python. If you are using a MacOS or Linux operating system, please make sure that the PATH is correctly set up - either system wide, or in your terminal.  As a workaround you can call the LocalStack CLI python module directly: $ python3 -m localstack.cli.main\nStarting LocalStack with the LocalStack CLI By default, LocalStack is started inside a Docker container by running:\n$ localstack start Notes   This command starts all services provided by LocalStack. You can limit the services to a subset by setting the environment variable SERVICES (for example with SERVICES=\"dynamodb,s3\" localstack start).\n  By default, LocalStack uses the image tagged latest that is cached on your machine, and will not pull the latest image automatically from Docker Hub (i.e., the image needs to be pulled manually if needed).\n  On MacOS you may have to run TMPDIR=/private$TMPDIR localstack start --docker if $TMPDIR contains a symbolic link that cannot be mounted by Docker.\n  From 2020-07-11 onwards, the default image localstack/localstack in Docker Hub refers to the “light version”, which has some large dependency files like Elasticsearch removed (and lazily downloads them, if required). (Note that the localstack/localstack-light image alias may get removed in the future). In case you need the full set of dependencies, the localstack/localstack-full image can be used instead. Please also refer to the USE_LIGHT_IMAGE environment variable.\n  Although we strongly recommend to use Docker, the infrastructure can also be spun up directly on the host machine using the --host startup flag. Note that this will require additional dependencies, and is not supported on some operating systems, including Windows.\n   Docker If you do not want to use the LocalStack CLI, you can also decide to manually start the LocalStack Docker container.\nPrerequisites Please make sure that you have a working docker environment on your machine before moving on. You can check if docker is correctly configured on your machine by executing docker info in your terminal. If it does not report an error (but shows information on your Docker system), you’re good to go.\nStarting LocalStack with Docker You can start the Docker container simply by executing the following docker run command: $ docker run --rm -it -p 4566:4566 -p 4571:4571 localstack/localstack\nNotes   This command pulls the current nighty build from the master branch (if you don’t have the image locally) and not the latest supported version. If you want to use a specific version, use the appropriate tag (for example localstack/localstack:0.12.18).\n  This command reuses the image if it’s already on your machine, i.e. it will not pull the latest image automatically from Docker Hub.\n  This command does not bind all ports which are potentially used by LocalStack, nor does it mount any volumes. When using Docker to manually start LocalStack, you will have to configure the container on your own. This could be seen as the “expert mode” of starting LocalStack. If you are looking for a simpler method of starting LocalStack, please use the LocalStack CLI.\n  This command starts all services provided by LocalStack. You can limit the services to a subset by setting the environment variable SERVICES (for example with -e \"SERVICES=dynamodb,s3\").\n  To facilitate interoperability, configuration variables can be prefixed with LOCALSTACK_ in docker. For instance, setting LOCALSTACK_SERVICES=s3 is equivalent to SERVICES=s3.\n   Docker-Compose If you want to manually manage your Docker container, it’s usually a good idea to use docker-compose in order to simplify your container configuration.\nPrerequisites  docker docker-compose (version 1.9.0+)  Starting LocalStack with Docker-Compose You can use the docker-compose.yml file from the official LocalStack repository and use this command (currently requires docker-compose version 1.9.0+):\n$ docker-compose up Notes   This command pulls the current nighty build from the master branch (if you don’t have the image locally) and not the latest supported version. If you want to use a specific version, use the appropriate tag (for example localstack/localstack:0.12.18).\n  This command reuses the image if it’s already on your machine, i.e. it will not pull the latest image automatically from Docker Hub.\n  On MacOS you may have to run TMPDIR=/private$TMPDIR docker-compose up if $TMPDIR contains a symbolic link that cannot be mounted by Docker.\n  To facilitate interoperability, configuration variables can be prefixed with LOCALSTACK_ in docker. For instance, setting LOCALSTACK_SERVICES=s3 is equivalent to SERVICES=s3.\n   Helm If you want to deply LocalStack in your Kubernetes cluster, you can use Helm.\nPrerequisites  Kubernetes Helm  Deploy LocalStack using Helm You can deploy LocalStack in a Kubernetes cluster by running these commands: $ helm repo add localstack-repo https://helm.localstack.cloud $ helm upgrade --install localstack localstack-repo/localstack\nThe Helm charts are not maintained in the main repository, but in a separate one.\nRan into trouble? We strive to make it as easy as possible for you to use LocalStack, and we are very grateful for any feedback. If you run into any issues or problems with this guide, please submit an issue.\nWhat’s next? Now that you have LocalStack up and running, the following resources might be useful for your next steps:\n Use the LocalStack integrations to interact with LocalStack and other integrated tools, for example:  Use awslocal to use the AWS CLI against your local cloud! Use the Serverless Framework with LocalStack! And many more!   Find out how to configure LocalStack such that it perfectly fits your need. Use LocalStack in your CI environment to increase your code quality. Checkout LocalStack’s Cloud Developer Tools to further increase your development efficiency with LocalStack. Find out about the ways you can configure LocalStack.  ","categories":"","description":"How to get up to speed with LocalStack.\n","excerpt":"How to get up to speed with LocalStack.\n","ref":"/get-started/","tags":"","title":"Get Started"},{"body":"General Application Architecture The coarse-grained system architecture is illustrated in the figure below. The LocalStack components are either installed on the local machine, or the entire application runs in a Docker container. The application exposes a set of external network ports (see defaults in constants.py). Client applications can use the standard AWS SDKs to connect to LocalStack; most SDKs have a configuration option to configure the endpoint URLs of the target services (e.g., configure http://localhost:4572 as endpoint URL to connect to local DynamoDB).\nTo handle incoming requests on the external network ports, LocalStack uses proxy threads which inspect the incoming request message, forward the requests to corresponding backend service processes, and perform any additional processing. The additional processing is required because some of the backend services only provide the basic “CRUD” functionality for maintaining API state, and LocalStack provides integrations on top of these services. This makes the backend services easily replaceable with best-of-breed implementations.\nProxy Interceptors For the basic “CRUD” functionality of most services we’re using a mock implementation (e.g., based on moto) in the background, and LocalStack adds a bunch of integrations on top of these services. We start up an HTTP proxy which intercepts all invocations and forwards requests to the backend. This allows us to add extended functionality without having to change the backend service.\nThe figure below illustrates the proxy mechanism and ports for the API Gateway service. (The default ports can be found in https://github.com/localstack/localstack/blob/master/localstack/constants.py )\n -------- ------------- ------------- | Client | -\u003e | Proxy | -\u003e | Backend | | | | (port 4567) | | (port 4566) | -------- ------------- ------------- The proxy follows a simple protocol by implementing 2 methods: forward_request which is called before a request is forwarded to the backend, and return_response which is called after a response has been received from the backend: https://github.com/localstack/localstack/blob/master/localstack/services/generic_proxy.py\nThe proxy implementation for API Gateway can be found here: https://github.com/localstack/localstack/blob/master/localstack/services/apigateway/apigateway_listener.py#L81\nPatching/Releasing a Third-Party Libraries To enable a fast release cycle of LocalStack, we’re using forked versions of various third-party libraries. For example, we have a forked version of moto which is published as a separate moto-ext pip package: https://github.com/whummer/moto/tree/localstack-fixes . If you decide to extend moto, you can either raise a PR against that repo, or against the main repo spulec/moto (then we need to take care of cross-merging and releasing new versions).\n","categories":"","description":"This document contains a few essential instructions for developing new features and bug fixes for *LocalStack*.\n","excerpt":"This document contains a few essential instructions for developing new …","ref":"/developer-guide/basics/","tags":"","title":"Basics"},{"body":"This guide describes how to start and use LocalStack in your CircleCI pipelines.\nThe LocalStack Circle CI Orb LocalStack is an official partner of Circle CI and can easily be integrated into your pipeline by using the official CircleCI Orb.\nThe Orb’s documentation features examples, as well as a description of the available commands.\nWhen using the official CircleCI Orb, using LocalStack in your pipeline is as easy as adding the Orb to your pipeline and executing the startup command.\nThe following example CircleCI config (.circleci/config.yml) starts LocalStack, creates a new S3 bucket, and prints a nice message in the end:\nversion:2.1orbs:localstack:localstack/platform@1.0jobs:run-integration-tests:executor:localstack/defaultsteps:- localstack/startup- run:command:awslocal s3 mb s3://test-bucket- run:command:echo \"Execute your tests here :)\"workflows:integration-test:jobs:- run-integration-testsActivate LocalStack Pro You can easily enable LocalStack Pro by adding your API key to the project’s environment variables. The LocalStack Orb will automatically pick it up and activate the Pro features.\nJust go to the project settings in CircleCI, click on Environment Variables in the sidebar and add your API key:\nRan into trouble? If you run into any issues or problems while integrating LocalStack with CircleCI, please submit an issue.\n","categories":"","description":"Use LocalStack in [Circle CI](https://circleci.com/)\n","excerpt":"Use LocalStack in [Circle CI](https://circleci.com/)\n","ref":"/ci/circle-ci/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"CircleCI"},{"body":"Overview This guide explains how to integrate LocalStack with the Serverless Framework. Although it probably requires a few code changes, integrating LocalStack with the Serverless Framework is fairly straightforward.\nIn particular, the setup consists of the following two steps.\n Installing and configuring the Serverless-LocalStack plugin. Adjusting AWS endpoints in Lambda functions.  Prerequisites This guide assumes that you have the following tools installed.\n LocalStack (Install) Serverless (Install)  It also assumes that you already have a Serverless app set up consisting of a couple of Lambda functions and a serverless.yml file similar to the following. An example Serverless app integrated with LocalStack can be found here:  Simple REST API using the Serverless Framework and LocalStack\nservice:my-serviceframeworkVersion:\"\u003e=1.1.0 \u003c=2.50.0\"provider:name:awsruntime:python3.8environment:DYNAMODB_TABLE:${self:service}-${opt:stage, self:provider.stage}iamRoleStatements:- Effect:AllowAction:- dynamodb:Query- ...Resource:\"arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE}\"functions:create:handler:todos/create.createevents:- http:path:todosmethod:postcors:true...resources:Resources:TodosDynamoDbTable:Type:'AWS::DynamoDB::Table'DeletionPolicy:RetainProperties:...TableName:${self:provider.environment.DYNAMODB_TABLE}Install and configure Serverless-LocalStack Plugin To install the plugin, execute the following command in the root of your project. $ npm install -D serverless-localstack\nNext, set up the plugin by adding the following properties to serverless.yml.\n...plugins:- serverless-localstackcustom:localstack:stages:- localThis sets up Serverless to use the LocalStack plugin but only for the stage “local”. Next, you need make minor adjustments to your function code in order to make your application work no matter if it is deployed on AWS or LocalStack.\nAdjust AWS endpoints in Lambda functions You are likely using an AWS SDK (such as Boto3 for Python) in your Lambda functions to interact with other AWS services such as DynamoDB.\nFor example, in Python, your code to set up a connection to DynamoDB may look like this:\n... dynamodb = boto3.resource('dynamodb') ... By default, this call attempts to create a connection via the usual AWS endpoints. However, when running services in LocalStack, we need to make sure, our applications creates a connection via the LocalStack endpoint instead.\nUsually, all of LocalStack’s services are available via a specific port on localhost (e.g. localhost:4566). However, this endpoint only works when accessing LocalStack from outside its Docker runtime.\nSince the Lambda functions execute within the LocalStack Docker container, Lambda functions cannot access other services via the usual localhost endpoint.\nInstead, LocalStack provides a special environment variable LOCALSTACK_HOSTNAME which contains the internal endpoint of the LocalStack services from within its runtime environment.\nHence, you need to configure the Lambda functions to use the LOCALSTACK_HOSTNAME endpoint when accessing other AWS services in LocalStack.\nIn Python, this may look something like. The code detects if it is running in LocalStack by checking if the LOCALSTACK_HOSTNAME variable exists and then configures the endpoint URL accordingly.\n... if 'LOCALSTACK_HOSTNAME' in os.environ: dynamodb_endpoint = 'http://%s:4566' % os.environ['LOCALSTACK_HOSTNAME'] dynamodb = boto3.resource('dynamodb', endpoint_url=dynamodb_endpoint) else: dynamodb = boto3.resource('dynamodb') ...  Ideally, we want to make LocalStack’s Lambda execution environment “LocalStack-agnostic”, so that you are not required to adjust endpoints in your function code anymore. You want to help us with that? Drop us a line in Slack!.\n Deploying to LocalStack You can now deploy your Serverless service to LocalStack.\nFirst, start LocalStack by running $ localstack start\nThen deploy the endpoint by running $ serverless deploy --stage local\nThe expected result should be similar to:\nServerless: Packaging service... Serverless: Excluding development dependencies... Serverless: Creating Stack... Serverless: Checking Stack create progress... ........ Serverless: Stack create finished... Serverless: Uploading CloudFormation file to S3... Serverless: Uploading artifacts... Serverless: Uploading service my-service.zip file to S3 (38.3 KB)... Serverless: Validating template... Serverless: Skipping template validation: Unsupported in Localstack Serverless: Updating Stack... Serverless: Checking Stack update progress... ..................................... Serverless: Stack update finished... Service Information service: my-service stage: local region: us-east-1 stack: my-service-local resources: 35 api keys: None endpoints: http://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_ functions: ... layers: None Use the displayed endpoint http://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_/my/custom/endpoint to make requests to the deployed service.\nAdvanced topics Local code mounting for lambda functions serverless-localstack supports a feature for lambda functions that allows local code mounting:\n# serverless.ymlcustom:localstack:# ...lambda:mountCode:TrueWhen this flag is set, the lambda code will be mounted into the container running the function directly from your local directory instead of packaging and uploading it.\nIf you want to use this feature together with the local lambda executor (LAMBDA_EXECUTOR=local), you need to make sure the container running localstack itself can find the code. To do that, you need to manually mount the code into the localstack container, here is a snippet using a docker-compose.yml with the essentials. Where /absolute/path/to/todos is the path on your local machine that points to the todos/ directory containing the lambda code from our previous example.\n# docker-compose.yml to start localstackservices:localstack:# ...environment:- LAMBDA_EXECUTOR=local- LAMBDA_REMOTE_DOCKER=0# ...volumes:# ...- \"/absolute/path/to/todos:/absolute/path/to/todos\"Ran into trouble? If you run into any issues or problems while integrating LocalStack with your Serverless app, please submit an issue.\n","categories":"","description":"Use the Serverless Framework with LocalStack\n","excerpt":"Use the Serverless Framework with LocalStack\n","ref":"/integrations/serverless-framework/","tags":["serverless-framework"],"title":"Serverless Framework"},{"body":"Development requirements You will need the following tools for local development of LocalStack.\n Python 3.7+ Sasl Pip Virtualenv OpenJDK Node \u0026 npm Maven Gradle Terraform Docker Docker-Compose  Installation instructions Here are very basic installation instructions for the dependencies you will need.\n Python 3.7+ update-alternatives --install /usr/bin/python python /usr/bin/python3.8 2  Sasl apt install libsasl2-dev  Pip apt-get install python3-pip update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 2  Virtualenv pip install virtualenv  OpenJDK apt-get install openjdk-11-jdk  Node curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - apt-get install -y nodejs  Maven wget https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.zip -O /opt/apache-maven-3.6.3-bin.zip unzip /opt/apache-maven-3.6.3-bin.zip -d /opt/  Gradle wget https://services.gradle.org/distributions/gradle-6.7-bin.zip -O /opt/gradle-6.7-bin.zip unzip /opt/gradle-6.7-bin.zip -d /opt/  Terraform curl -L -o /opt/terraform/terraform.zip https://releases.hashicorp.com/terraform/0.13.4/terraform_0.13.4_linux_amd64.zip (cd /opt/terraform \u0026\u0026 unzip -q /opt/terraform/terraform.zip \u0026\u0026 rm /opt/terraform/terraform.zip)  Adding Environment variable echo \"PATH=$PATH:/opt/apache-maven-3.6.3/bin:/opt/gradle-6.7/bin:/opt/terraform\" \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc  Docker curl -sSLk https://get.docker.com | bash -  Docker-Compose sudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose   Tips  Python 3.9+ currently does not work. Use pyenv (https://github.com/pyenv/pyenv) to manage python versions. Quick start:pyenv install 3.8.10 \u0026\u0026 pyenv global 3.8.10 If virtualenv chooses system python installations before your pyenv installations, manually initialize virtualenv before running make install like this: virtualenv -p ~/.pyenv/shims/python3.8 .venv . Terraform needs version \u003c0.14 to work currently. Use tfenv (https://github.com/tfutils/tfenv) to manage terraform versions comfortable. Quick start: tfenv install 0.13.7 \u0026\u0026 tfenv use 0.13.7 Set env variable LS_LOG=‘trace’ to print every http request sent to localstack and their responses. Useful for debugging certain issues. As per dev guide, it requires libsasl2-dev. Arch based Distro equivalent: libsasl  ","categories":"","description":"Set up your development environment for developing LocalStack.\n","excerpt":"Set up your development environment for developing LocalStack.\n","ref":"/developer-guide/setup/","tags":"","title":"Setup and requirements"},{"body":"Overview In this guide, you will learn how to use LocalStack to test your serverless applications powered by Spring Cloud Function framework.\n   Complexity ★★★☆☆     Time to read 30 minutes   Edition community [pro]   Platform x64_86 (-aarch64)    aarch64 warning Some features and services described in this document may not work properly on aarch64, including Apple’s M1 silicon  Covered Topics We will create a new Rest API application that will route requests to a Cloud Function using functionRouter and routing expressions.\nThe primary language for the application is Kotlin powered by Gradle build tool, but the described concepts would work for any other JVM setup.\n Limitations Setting up an Application  Starting a new Project Project Settings Configure Log4J2 for AWS Lambda Configure Spring Cloud Function for Rest API Define an Application class Configure Jackson Define Logging Utility Add Request/Response utilities Creating a sample Model / DTO Creating Rest API endpoints Cold Start and Warmup (PRO) Creating other lambda Handlers   Setting up Deployment Testing, Debugging and Code hot-swapping Useful links  Limitations This document demonstrates the usage of the Spring Cloud Function framework together with LocalStack. It does not cover some of the application-specific topics, like 404 error handling, or parametrized routing, that you need to consider when building production-ready applications.\nSetting up an Application We recommend using jenv to manage multiple Java runtimes.\nStarting a new Project Please follow the instructions from the official website to install the Gradle build tool on your machine.\nThen run the following command to initialize a new Gradle project\n$ gradle init After initialization, you will find the Gradle wrapper script gradlew. From now on, we will use the wrapper instead of the globally installed Gradle binary:\n$ ./gradlew \u003ccommand\u003e Project Settings Let’s give our project a name: open settings.gradle, and adjust the autogenerated name to something meaningful.\nrootProject.name = 'localstack-sampleproject' Now we need to define our dependencies. Here’s a list of what we will be using in our project.\nGradle plugins:\n java kotlin jvm kotlin spring plugin spring boot plugin spring dependency management plugin shadow plugin  Dependencies:\n kotlin stdlib spring cloud starter function web spring cloud function adapter for aws lambda log4j2 lambda events jackson core jackson databind jackson annotations jackson module kotlin  In order to deploy our application to AWS, we need to build so-called “fat jar” which contains all application dependencies. To that end, we use the “Shadow Jar” plugin.\nHere’s our final build.gradle:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  plugins { id \"java\" id \"org.jetbrains.kotlin.jvm\" version '1.5.31' id \"org.jetbrains.kotlin.plugin.spring\" version '1.5.31' id 'org.springframework.boot' version '2.5.5' id \"io.spring.dependency-management\" version '1.0.11.RELEASE' id \"com.github.johnrengelman.shadow\" version '7.0.0' } group = 'org.localstack.sampleproject' sourceCompatibility = 11 tasks.withType(JavaCompile) { options.encoding = 'UTF-8' } repositories { mavenCentral() maven { url \"https://plugins.gradle.org/m2/\" } } ext { springCloudVersion = \"3.1.4\" awsLambdaLog4jVersion = \"1.2.0\" awsLambdaJavaEventsVersion = \"3.10.0\" jacksonVersion = \"2.12.5\" } dependencies { implementation \"org.jetbrains.kotlin:kotlin-stdlib\" implementation \"org.springframework.cloud:spring-cloud-starter-function-web:$springCloudVersion\" implementation \"org.springframework.cloud:spring-cloud-function-adapter-aws:$springCloudVersion\" implementation \"com.amazonaws:aws-lambda-java-log4j2:$awsLambdaLog4jVersion\" implementation \"com.amazonaws:aws-lambda-java-events:$awsLambdaJavaEventsVersion\" implementation \"com.fasterxml.jackson.core:jackson-core:$jacksonVersion\" implementation \"com.fasterxml.jackson.core:jackson-databind:$jacksonVersion\" implementation \"com.fasterxml.jackson.core:jackson-annotations:$jacksonVersion\" implementation \"com.fasterxml.jackson.module:jackson-module-kotlin:$jacksonVersion\" } import com.github.jengelman.gradle.plugins.shadow.transformers.* // Configure the main class jar { manifest { attributes 'Start-Class': 'org.localstack.sampleproject.Application' } } // Build a fatjar (with dependencies) for aws lambda shadowJar { transform(Log4j2PluginsCacheFileTransformer) dependencies { exclude( dependency(\"org.springframework.cloud:spring-cloud-function-web:${springCloudVersion}\") ) } // Required for Spring  mergeServiceFiles() append 'META-INF/spring.handlers' append 'META-INF/spring.schemas' append 'META-INF/spring.tooling' transform(PropertiesFileTransformer) { paths = ['META-INF/spring.factories'] mergeStrategy = \"append\" } } assemble.dependsOn shadowJar   Please note that we will be using org.localstack.sampleproject as a working namespace, and org.localstack.sampleproject.Application as an entry class for our application. You can adjust it for your needs, but don’t forget to change your package names accordingly.\nConfigure Log4J2 for AWS Lambda Spring framework comes with Log4J logger, so all we need to do is to configure it for AWS Lambda. In this project, we are following official documentation to setup up src/main/resources/log4j2.xml content.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cConfiguration packages=\"com.amazonaws.services.lambda.runtime.log4j2.LambdaAppender\"\u003e \u003cAppenders\u003e \u003cLambda name=\"Lambda\"\u003e \u003cPatternLayout\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH:mm:ss} %X{AWSRequestId} %-5p %c{1}:%L - %m%n\u003c/pattern\u003e \u003c/PatternLayout\u003e \u003c/Lambda\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003cRoot level=\"debug\"\u003e \u003cAppenderRef ref=\"Lambda\" /\u003e \u003c/Root\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e Configure Spring Cloud Function for Rest API Spring Function comes with functionRouter that can route requests to different Beans based on predefined routing expressions. Let’s configure it to lookup our function Beans by HTTP method and path, create a new application.properties file under src/main/resources/application.properties with the following content:\nspring.main.banner-mode=off spring.cloud.function.definition=functionRouter spring.cloud.function.routing-expression=headers['httpMethod'].concat(' ').concat(headers['path']) spring.cloud.function.scan.packages=org.localstack.sampleproject.api Once configured, you can use FunctionInvoker as a handler for your Rest API lambda function. It will automatically pick up the configuration we have just set.\norg.springframework.cloud.function.adapter.aws.FunctionInvoker::handleRequest Define an Application class Now our application needs an entry-class, the one we referenced earlier. Let’s add it under src/main/kotlin/org/localstack/sampleproject/Application.kt.\n1 2 3 4 5 6 7 8 9 10  package org.localstack.sampleproject import org.springframework.boot.autoconfigure.SpringBootApplication @SpringBootApplication class Application fun main(args: Array\u003cString\u003e) { // Do nothing unless you use a custom runtime }   Configure Jackson In our sample project we are using a JSON format for reqeusts and responses. The easiest way to get started with JSON is to use the Jackson library. Let’s configure it by creating a new configuration class JacksonConfiguration.kt under src/main/kotlin/org/localstack/sampleproject/config:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package org.localstack.sampleproject.config import com.fasterxml.jackson.annotation.JsonInclude import com.fasterxml.jackson.databind.* import org.springframework.context.annotation.Bean import org.springframework.context.annotation.Configuration import org.springframework.context.annotation.Primary import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder import java.text.DateFormat @Configuration class JacksonConfiguration { @Bean fun jacksonBuilder() = Jackson2ObjectMapperBuilder() .dateFormat(DateFormat.getDateInstance(DateFormat.FULL)) @Bean @Primary fun objectMapper(): ObjectMapper = ObjectMapper().apply { configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) configure(SerializationFeature.WRITE_ENUMS_USING_TO_STRING, true) configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false) configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true) configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true) setSerializationInclusion(JsonInclude.Include.NON_NULL) findAndRegisterModules() } }   In applications where you need support for multiple formats or a format different from JSON (for example, SOAP/XML applications) simply use multiple beans with corresponding ObjectMapper implementations.\nDefine Logging Utility Let’s create a small logging utility to simplify interactions with the logger\n1 2 3 4 5 6 7 8  package org.localstack.sampleproject.util import org.apache.logging.log4j.LogManager import org.apache.logging.log4j.Logger open class Logger { val LOGGER: Logger = LogManager.getLogger(javaClass.enclosingClass) }   Add Request/Response utilities To reduce the amount of boilerplate code, we are going to introduce three utility functions for our Rest API communications:\n to build regular json response to build error json response to parse request payload using ObjectMapper. Note that ObjectMapper does not necessarily need to be a JSON only. It could also be XML or any other Mapper extended from standard ObjectMapper. Your application may even support multiple protocols with different request/response formats at once.  Let’s define utility functions to to build API gateway responses:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package org.localstack.sampleproject.util import org.springframework.messaging.Message import org.springframework.messaging.support.MessageBuilder data class ResponseError( val message: String, ) fun \u003cT\u003ebuildJsonResponse(data: T, code: Int = 200): Message\u003cT\u003e { return MessageBuilder .withPayload(data) .setHeader(\"Content-Type\", \"application/json\") .setHeader(\"Access-Control-Allow-Origin\", \"*\") .setHeader(\"Access-Control-Allow-Methods\", \"OPTIONS,POST,GET\") .setHeader(\"statusCode\", code) .build() } fun buildJsonErrorResponse(message: String, code: Int = 500) = buildJsonResponse(ResponseError(message), code)   And now a utility function to process API Gateway requests:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package org.localstack.sampleproject.util import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent import com.fasterxml.jackson.databind.ObjectMapper import org.springframework.messaging.Message import java.util.function.Function fun \u003cT\u003eapiGatewayFunction( objectMapper: ObjectMapper, callable: (message: Message\u003cT\u003e, context: APIGatewayProxyRequestEvent) -\u003e Message\u003c*\u003e ): Function\u003cMessage\u003cT\u003e, Message\u003c*\u003e\u003e = Function { input -\u003e try { val context = objectMapper.readValue( objectMapper.writeValueAsString(input.headers), APIGatewayProxyRequestEvent::class.java ) return@Function callable(input, context) } catch (e: Throwable) { val message = e.message?.replace(\"\\n\", \"\")?.replace(\"\\\"\", \"'\") return@Function buildJsonErrorResponse(message ?: \"\", 500) } }   Creating a sample Model / DTO To transfer data from requests into something more meaningful than JSON strings (and back) you will be using a lot of Models and Data Transfer Objects (DTOs). It’s time to define our first one.\n1 2 3 4 5 6 7 8 9 10 11  package org.localstack.sampleproject.model import com.fasterxml.jackson.annotation.JsonIgnore data class SampleModel( val id: Int, val name: String, @JsonIgnore val jsonIgnoredProperty: String? = null, )   Creating Rest API endpoints Let’s add our first endpoints to simulate CRUD operations on previously defined SampleModel:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  package org.localstack.sampleproject.api import com.fasterxml.jackson.databind.ObjectMapper import org.localstack.sampleproject.model.SampleModel import org.localstack.sampleproject.util.Logger import org.localstack.sampleproject.util.apiGatewayFunction import org.localstack.sampleproject.util.buildJsonResponse import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component private val SAMPLE_RESPONSE = mutableListOf( SampleModel(id = 1, name = \"Sample #1\"), SampleModel(id = 2, name = \"Sample #2\"), ) @Component class SampleApi(private val objectMapper: ObjectMapper) { companion object : Logger() @Bean(\"POST /v1/entities\") fun createSampleEntity() = apiGatewayFunction\u003cSampleModel\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling POST /v1/entities\") SAMPLE_RESPONSE.add(input.payload) buildJsonResponse(input.payload, code = 201) } @Bean(\"GET /v1/entities\") fun listSampleEntities() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling GET /v1/entities\") buildJsonResponse(\"hello world\") } @Bean(\"GET /v1/entities/get\") fun getSampleEntity() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling GET /v1/entities/get\") val desiredId = context.queryStringParameters[\"id\"]!!.toInt() buildJsonResponse(SAMPLE_RESPONSE.find { it.id == desiredId }) } }   Note how we used Spring’s dependency injection to inject ObjectMapper Bean we configured earlier.\nCold Start and Warmup (PRO) Pro Features Please note that EVENTS is a LocalStack PRO feature and is not supported in Community version  We know Java’s cold start is always a pain. To minimize this pain, we will try to define a pre-warming endpoint within the Rest API. By invoking this function every 5-10 mins we can make sure Rest API lambda is always kept in a pre-warmed state.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package org.localstack.sampleproject.api import com.fasterxml.jackson.databind.ObjectMapper import org.localstack.sampleproject.util.apiGatewayFunction import org.localstack.sampleproject.util.buildJsonResponse import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component @Component class ScheduleApi(private val objectMapper: ObjectMapper) { @Bean(\"SCHEDULE warmup\") fun warmup() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e // execute scheduled events  buildJsonResponse(\"OK\") } }   Now you can add a scheduled event to the Rest API lambda function with the following synthetic payload (to simulate API gateway request). This way, you can define any other scheduled events, but we recommend using pure lambda functions.\n{ \"httpMethod\": \"SCHEDULE\", \"path\": \"warmup\" } As you may have guessed, this input will get mapped to the SCHEDULE warmup Bean.\n For more information, please read the “Setting up Deployment” section.\n Creating other lambda Handlers HTTP requests are not the only thing our Spring Function-powered lambdas can do. We can still define pure lambda functions, DynamoDB stream handlers, and so on.\nBelow you can find a little example of few lambda functions grouped in LambdaApi class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  package org.localstack.sampleproject.api import com.amazonaws.services.lambda.runtime.events.DynamodbEvent import org.localstack.sampleproject.model.SampleModel import org.localstack.sampleproject.util.Logger import org.springframework.cloud.function.adapter.aws.SpringBootStreamHandler import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component import java.util.function.Function @Component class LambdaApi : SpringBootStreamHandler() { companion object : Logger() @Bean fun functionOne(): Function\u003cAny, String\u003e { return Function { LOGGER.info(\"calling function one\") return@Function \"ONE\"; } } @Bean fun functionTwo(): Function\u003cSampleModel, SampleModel\u003e { return Function { LOGGER.info(\"calling function two\") return@Function it; } } @Bean fun dynamoDbStreamHandlerExample(): Function\u003cDynamodbEvent, Unit\u003e { return Function { LOGGER.info(\"handling DynamoDB stream event\") } } }   As you can see from the example above, we are using SpringBootStreamHandler class as a base that takes care of the application bootstrapping process and AWS requests transformation.\nNow org.localstack.sampleproject.api.LambdaApi can be used as a handler for your lambda function along with FUNCTION_NAME environmental variable with the function bean name.\nYou may have noticed we used DynamodbEvent in the last example. The Lambda-Events package comes with a set of predefined wrappers that you can use to handle different lifecycle events from AWS.\nSetting up Deployment Check our sample project for usage examples.\nServerless  AWS CDK  Terraform   service:localstack-sampleproject-serverlessprovider:name:awsruntime:java11stage:${opt:stage}region:us-west-1lambdaHashingVersion:20201221deploymentBucket:name:deployment-bucketpackage:artifact:build/libs/localstack-sampleproject-all.jarplugins:- serverless-localstack- serverless-deployment-bucketcustom:localstack:stages:- localfunctions:http_proxy:timeout:30handler:org.springframework.cloud.function.adapter.aws.FunctionInvoker::handleRequestevents:- http:path:/{proxy+}method:ANYcors:true# Please, note that events are a LocalStack PRO feature- schedule:rate:rate(10 minutes)enabled:trueinput:httpMethod:SCHEDULEpath:warmuplambda_helloOne:timeout:30handler:org.localstack.sampleproject.api.LambdaApienvironment:FUNCTION_NAME:functionOnelambda_helloTwo:timeout:30handler:org.localstack.sampleproject.api.LambdaApienvironment:FUNCTION_NAME:functionTwo package org.localstack.cdkstack import java.util.UUID import software.amazon.awscdk.core.Construct import software.amazon.awscdk.core.Duration import software.amazon.awscdk.core.Stack import software.amazon.awscdk.services.apigateway.CorsOptions import software.amazon.awscdk.services.apigateway.LambdaRestApi import software.amazon.awscdk.services.apigateway.StageOptions import software.amazon.awscdk.services.events.Rule import software.amazon.awscdk.services.events.RuleTargetInput import software.amazon.awscdk.services.events.Schedule import software.amazon.awscdk.services.events.targets.LambdaFunction import software.amazon.awscdk.services.lambda.* import software.amazon.awscdk.services.lambda.Function import software.amazon.awscdk.services.s3.Bucket private val STAGE = System.getenv(\"STAGE\") ?: \"local\" private const val JAR_PATH = \"../../build/libs/localstack-sampleproject-all.jar\" class ApplicationStack(parent: Construct, name: String) : Stack(parent, name) { init { val restApiLambda = Function.Builder.create(this, \"RestApiFunction\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.springframework.cloud.function.adapter.aws.FunctionInvoker\") .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .tracing(Tracing.ACTIVE) .build() val corsOptions = CorsOptions.builder().allowOrigins(listOf(\"*\")).allowMethods(listOf(\"*\")).build() LambdaRestApi.Builder.create(this, \"ExampleRestApi\") .proxy(true) .restApiName(\"ExampleRestApi\") .defaultCorsPreflightOptions(corsOptions) .deployOptions(StageOptions.Builder().stageName(STAGE).build()) .handler(restApiLambda) .build() val warmupRule = Rule.Builder.create(this, \"WarmupRule\") .schedule(Schedule.rate(Duration.minutes(10))) .build() val warmupTarget = LambdaFunction.Builder.create(restApiLambda) .event(RuleTargetInput.fromObject(mapOf(\"httpMethod\" to \"SCHEDULE\", \"path\" to \"warmup\"))) .build() // Please note that events is a LocalStack PRO feature  warmupRule.addTarget(warmupTarget) SingletonFunction.Builder.create(this, \"ExampleFunctionOne\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionOne\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() SingletonFunction.Builder.create(this, \"ExampleFunctionTwo\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionTwo\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() } } variable \"STAGE\" { type = string default = \"local\" } variable \"AWS_REGION\" { type = string default = \"us-east-1\" } variable \"JAR_PATH\" { type = string default = \"build/libs/localstack-sampleproject-all.jar\" } provider \"aws\" { access_key = \"test_access_key\" secret_key = \"test_secret_key\" region = var.AWS_REGION s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudformation = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatch = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatchevents = var.STAGE == \"local\" ? \"http://localhost:4566\" : null iam = var.STAGE == \"local\" ? \"http://localhost:4566\" : null lambda = var.STAGE == \"local\" ? \"http://localhost:4566\" : null s3 = var.STAGE == \"local\" ? \"http://localhost:4566\" : null } } resource \"aws_iam_role\" \"lambda-execution-role\" { name = \"lambda-execution-role\" assume_role_policy = \u003c\u003cEOF{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"sts:AssumeRole\", \"Principal\": { \"Service\": \"lambda.amazonaws.com\" }, \"Effect\": \"Allow\", \"Sid\": \"\" } ] } EOF } resource \"aws_lambda_function\" \"restApiLambdaFunction\" { filename = var.JAR_PATH function_name = \"RestApiFunction\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.springframework.cloud.function.adapter.aws.FunctionInvoker\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) } resource \"aws_api_gateway_rest_api\" \"rest-api\" { name = \"ExampleRestApi\" } resource \"aws_api_gateway_resource\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id parent_id = aws_api_gateway_rest_api.rest-api.root_resource_id path_part = \"{proxy+}\" } resource \"aws_api_gateway_method\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id resource_id = aws_api_gateway_resource.proxy.id http_method = \"ANY\" authorization = \"NONE\" } resource \"aws_api_gateway_integration\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id resource_id = aws_api_gateway_method.proxy.resource_id http_method = aws_api_gateway_method.proxy.http_method integration_http_method = \"POST\" type = \"AWS_PROXY\" uri = aws_lambda_function.restApiLambdaFunction.invoke_arn } resource \"aws_api_gateway_deployment\" \"rest-api-deployment\" { depends_on = [aws_api_gateway_integration.proxy] rest_api_id = aws_api_gateway_rest_api.rest-api.id stage_name = var.STAGE } resource \"aws_cloudwatch_event_rule\" \"warmup\" { name = \"warmup-event-rule\" schedule_expression = \"rate(10 minutes)\" } resource \"aws_cloudwatch_event_target\" \"warmup\" { target_id = \"warmup\" rule = aws_cloudwatch_event_rule.warmup.name arn = aws_lambda_function.restApiLambdaFunction.arn input = \"{\\\"httpMethod\\\": \\\"SCHEDULE\\\", \\\"path\\\": \\\"warmup\\\"}\" } resource \"aws_lambda_permission\" \"warmup-permission\" { statement_id = \"AllowExecutionFromCloudWatch\" action = \"lambda:InvokeFunction\" function_name = aws_lambda_function.restApiLambdaFunction.function_name principal = \"events.amazonaws.com\" source_arn = aws_cloudwatch_event_rule.warmup.arn } resource \"aws_lambda_function\" \"exampleFunctionOne\" { filename = var.JAR_PATH function_name = \"ExampleFunctionOne\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionOne\" } } } resource \"aws_lambda_function\" \"exampleFunctionTwo\" { filename = var.JAR_PATH function_name = \"ExampleFunctionTwo\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionTwo\" } } }  Testing, Debugging and Code hot-swapping Please read our Lambda Tools documentation to learn more about testing, debugging and code hot-swapping for JVM Lambda functions.\nUseful Links  Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Use Spring Cloud Function framework with LocalStack\n","excerpt":"Use Spring Cloud Function framework with LocalStack\n","ref":"/integrations/spring-cloud-function/","tags":["serverless-framework","spring","spring-cloud","spring-cloud-function","jvm","kotlin"],"title":"Spring Cloud Function"},{"body":"   Complexity ★☆☆☆☆     Time to read 5 minutes   Edition community/pro   Platform any    Quickly iterating over Lambda function code can be quite cumbersome, as you need to deploy your function on every change. With LocalStack you can avoid this hurdle by mounting your code directly from the source folder. This way, any saved change inside your source file directly affects the already deployed Lambda function – without any redeployment!\nCovered Topics Application Configuration Examples:\n Code hot-swapping for JVM Lambdas Code hot-swapping for Python Lambdas Debugging Nodejs lambdas (under development)  Deployment Configuration Examples:\n Serverless Framework Configuration AWS Cloud Development Kit (CDK) Configuration Terraform Configuration  Useful Links\nApplication Configuration Examples Code hot-swapping for JVM Lambdas Since lambda containers lifetime is usually limited, regular hot code swapping techniques are not applicable here.\nIn our implementation, we will be watching for fs changes under the project folder, then build a FatJar, unzip it, and mount it into the Lambda Docker Container.\nWe assume you already have:\n watchman configured JVM project capable of building FatJars using your preferred build tool  First, create a watchman wrapper by using one of our examples\nDon’t forget to adjust permissions: $ chmod +x bin/watchman.sh\nNow configure your build tool to unzip the FatJar to some folder, which will be then mounted to LocalStack. We are using Gradle build tool to unpack the FatJar into the build/hot folder:\n// We assume you are using something like `Shadow` plugin that comes with `shadowJar` task task buildHot(type: Copy) { from zipTree(\"${project.buildDir}/libs/${project.name}-all.jar\") into \"${project.buildDir}/hot\" } buildHot.dependsOn shadowJar Now run the following command to start watching your project in a hot-swapping mode:\n$ bin/watchman.sh src \"./gradlew buildHot\" Please note that you still need to configure your deployment tool to use local code mounting. Read the “Deployment Configuration Examples” for more information.\nCode hot-swapping for Python Lambdas We will show you how you can do this with a simple example function, taken directly from the AWS Lambda developer guide.\nYou can check out that code, or use your own lambda functions to follow along. To use the example just do:\n$ cd /tmp $ git clone git@github.com:awsdocs/aws-doc-sdk-examples.git Starting up LocalStack First, we need to make sure we start LocalStack with the right configuration. This is as simple as setting LAMBDA_REMOTE_DOCKER(see the Configuration Documentation for more information):\n$ LAMBDA_REMOTE_DOCKER=0 localstack start Accordingly, if you are launching LocalStack via Docker or Docker Compose:\n#docker-compose.ymlservices:localstack:...environment:...- LAMBDA_REMOTE_DOCKER=falseCreating the Lambda Function To create the Lambda function, you just need to take care of two things:\n Deploy via an S3 Bucket. You need to use the magic variable __local__ as the bucket. Set the S3 key to the path of the directory your lambda function resides in. The handler is then referenced by the filename of your lambda code and the function in that code that needs to be invoked.  So, using the AWS example, this would be:\n$ awslocal lambda create-function --function-name my-cool-local-function \\ --code S3Bucket=\"__local__\",S3Key=\"/tmp/aws-doc-sdk-examples/python/example_code/lambda/boto_client_examples\" \\ --handler lambda_handler_basic.lambda_handler \\ --runtime python3.8 \\ --role cool-stacklifter You can also check out some of our “Deployment Configuration Examples”.\nWe can also quickly make sure that it works by invoking it with a simple payload:\n$ awslocal lambda invoke --function-name my-cool-local-function --payload '{\"action\": \"square\", \"number\": 3}' output.txt The invocation returns itself returns:\n{ \"StatusCode\": 200, \"LogResult\": \"\", \"ExecutedVersion\": \"$LATEST\" } and output.txt contains:\n{\"result\":9} Changing things up Now, that we got everything up and running, the fun begins. Because the function is now mounted as a file in the executing container, any change that we save on the file will be there in an instant.\nFor example, we can now make a minor change to the API and replace the response in line 41 with the following:\nresponse = {'math_result': result} Without redeploying or updating the function, the result of the previous request will look like this:\n{\"math_result\":9} Cool!\nUsage with Viertualenv For Virtualenv-driven projects, all dependencies should be available under the same folder as the project itself. The easiest way to achieve that is to implement a watchman script that will be preparing a special folder for hot code swapping.\nIn our example, we are using build/hot folder as a mounting point for our Lambdas.\nFirst, create a watchman wrapper by using one of our examples\nAfter that, you can use the following Makefile snippet, or implement another shell script to prepare the codebase for hot swapping:\nVENV_DIR ?= .venv VENV_RUN ?= . $(VENV_DIR)/bin/activate BUILD_FOLDER ?= build PROJECT_MODULE_NAME = my_project_module build-hot: $(VENV_RUN); rm -rf $(BUILD_FOLDER)/hot \u0026\u0026 mkdir -p $(BUILD_FOLDER)/hot; cp -r $(VENV_DIR)/lib/python$(shell python --version | grep -oE '[0-9]\\.[0-9]')/site-packages/* $(BUILD_FOLDER)/hot; cp -r $(PROJECT_MODULE_NAME) $(BUILD_FOLDER)/hot/$(PROJECT_MODULE_NAME); cp *.toml $(BUILD_FOLDER)/hot; watch: bin/watchman.sh $(PROJECT_MODULE_NAME) \"make build-hot\" .PHONY: build-hot watch As you can see, all we do here is just copying the project module PROJECT_MODULE_NAME along with all dependencies into the build/hot folder, which is then mounted to LocalStack’s Lambda container.\nTo run the example above run make watch\nDeployment Configuration Examples Serverless Framework Configuration Enable local code mounting\ncustom:localstack:...lambda:mountCode:true# or if you need to enable code mounting only for specific stagescustom:stages:local:mountCode:truetesting:mountCode:falselocalstack:stages:- local- testinglambda:mountCode:${self:custom.stages.${opt:stage}.mountCode}Pass LAMBDA_MOUNT_CWD env var with path to the built code directory (in our case to the folder with unzipped FatJar):\n$ LAMBDA_MOUNT_CWD=$(pwd)/build/hot serverless deploy --stage local AWS Cloud Development Kit (CDK) Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package org.localstack.cdkstack import java.util.UUID import software.amazon.awscdk.core.Construct import software.amazon.awscdk.core.Duration import software.amazon.awscdk.core.Stack import software.amazon.awscdk.services.lambda.* import software.amazon.awscdk.services.s3.Bucket private val STAGE = System.getenv(\"STAGE\") ?: \"local\" private val LAMBDA_MOUNT_CWD = System.getenv(\"LAMBDA_MOUNT_CWD\") ?: \"\" private const val JAR_PATH = \"build/libs/localstack-sampleproject-all.jar\" class ApplicationStack(parent: Construct, name: String) : Stack(parent, name) { init { val lambdaCodeSource = this.buildCodeSource() SingletonFunction.Builder.create(this, \"ExampleFunctionOne\") .code(lambdaCodeSource) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionOne\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() } /** * Mount code for hot-reloading when STAGE=local */ private fun buildCodeSource(): Code { if (STAGE == \"local\") { val bucket = Bucket.fromBucketName(this, \"HotReloadingBucket\", \"__local__\") return Code.fromBucket(bucket, LAMBDA_MOUNT_CWD) } return Code.fromAsset(JAR_PATH) } }   Then to bootstrap and deploy the stack run the following shell script\n$ STAGE=local \u0026\u0026 LAMBDA_MOUNT_CWD=$(pwd)/build/hot \u0026\u0026 cdklocal bootstrap aws://000000000000/$(AWS_REGION) \u0026\u0026 \\ cdklocal deploy Terraform Configuration ariable \"STAGE\" { type = string default = \"local\" } variable \"AWS_REGION\" { type = string default = \"us-east-1\" } variable \"JAR_PATH\" { type = string default = \"build/libs/localstack-sampleproject-all.jar\" } variable \"LAMBDA_MOUNT_CWD\" { type = string } provider \"aws\" { access_key = \"test_access_key\" secret_key = \"test_secret_key\" region = var.AWS_REGION s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudformation =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatch =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatchevents =var.STAGE == \"local\" ? \"http://localhost:4566\" : null iam =var.STAGE == \"local\" ? \"http://localhost:4566\" : null lambda =var.STAGE == \"local\" ? \"http://localhost:4566\" : null s3 =var.STAGE == \"local\" ? \"http://localhost:4566\" : null } } resource \"aws_iam_role\" \"lambda-execution-role\" { name = \"lambda-execution-role\" assume_role_policy = \u003c\u003cEOF { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"sts:AssumeRole\", \"Principal\": { \"Service\": \"lambda.amazonaws.com\" }, \"Effect\": \"Allow\", \"Sid\": \"\" } ] } EOF } resource \"aws_lambda_function\" \"exampleFunctionOne\" { s3_bucket =var.STAGE == \"local\" ? \"__local__\" : null s3_key =var.STAGE == \"local\" ? var.LAMBDA_MOUNT_CWD : null filename =var.STAGE == \"local\" ? null : var.JAR_PATH function_name = \"ExampleFunctionOne\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionOne\" } } }  $ terraform init \u0026\u0026 \\ terraform apply -var \"STAGE=local\" -var \"LAMBDA_MOUNT_CWD=$(pwd)/build/hot\" Useful Links  Lambda Code Mounting and Debugging (Python) Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Hot code swapping for Lambda functions using LocalStack's code mounting\n","excerpt":"Hot code swapping for Lambda functions using LocalStack's code …","ref":"/tools/lambda-tools/hot-swapping/","tags":"","title":"Hot Swapping"},{"body":"LocalStack Event Analytics LocalStack allows for transparent collection of execution events, in order to provide usage analytics and insights into the testing process overall.\nSimply configure your system with the LOCALSTACK_API_KEY environment variable, and the system will start making your events accessible on the LocalStack dashboard at https://app.localstack.cloud/dashboard.\nData Privacy Please note that data privacy is one of our key concerns; data is only collected in an anonymized way, and never exposes any sensitive information about your application.  The following screenshot shows an the Analytics Dashboard in action:\nThe top row shows a summary of your LocalStack usage. A test process or Process ID refers to a single run of LocalStack. The table shows the detailed list of events sorted by date.\nConfiguration You can disable event reporting on your LocalStack client by setting the environment variable DISABLE_EVENTS=1.\n","categories":["LocalStack Pro"],"description":"An Introduction to the LocalStack Pro Analytics Dashboard\n","excerpt":"An Introduction to the LocalStack Pro Analytics Dashboard\n","ref":"/tools/analytics-dashboard/","tags":"","title":"Analytics Dashboard"},{"body":"Overview Architect enables you to quickly build large serverless apps without worrying about the underlying infrastructure. On this page we discuss how Architect and LocalStack can be used together. If you are adapting an existing configuration, you might be able to skip certain steps at your own discretion.\nExample Setup To use Architect in conjunction with Localstack, simply install the arclocal command (sources can be found here). $ npm install -g architect-local @architect/architect aws-sdk\nThe arclocal command has the same usage as the arc command, so you can start right away.\nCreate a test directory\n$ mkdir architect_quickstart \u0026\u0026 cd architect_quickstart then create an architect project\n$ arclocal init Deployment Now you need to start LocalStack. For Architect to work properly, you need to start the following services in LocalStack (using the SERVICES configuration option):\n s3 ssm cloudformation  After LocalStack has started you can deploy your Architect setup via: $ arclocal deploy\nFurther reading For more architect examples, you can take a look at the official architect docs.\n","categories":"","description":"Use the Architect Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Architect Infrastructure as Code framework with LocalStack\n","ref":"/integrations/architect/","tags":["architect","infrastructure-as-code"],"title":"Architect"},{"body":"Overview The AWS Copilot CLI is a command line tool for developer, to release and operate containerized applications using the AWS services ECS, Fargate and App runner. Copilot CLI makes it very simple to deploy your application, without the need for manual configuration of the mentioned services.\nCopilot Local copilotlocal is a fork of AWS Copilot CLI, where the endpoints for all services are redirected to http://localhost:4566. Using copilotlocal instead of copilot in your command line therefore ensures the deployment of your service on LocalStack instead of AWS.\nDownload / Installation Linux AMD64  Linux ARM64  Mac OS  Windows Powershell   curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/linux-amd64/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/linux-arm64/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/macos-darwin/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ Invoke-WebRequest -Uri https://github.com/localstack/copilot-cli/raw/localstack-builds/build/windows/copilotlocal.exe -OutFile copilotlocal.exe   Configuration  LOCALSTACK_HOSTNAME: Target hostname under which LocalStack endpoints are available (default: localhost.localstack.cloud) EDGE_PORT: Target port under which LocalStack endpoints are available (default: 4566) LOCALSTACK_DISABLE: Optional flag to disable the local endpoints and use the default behavior of copilot (set to 1 or true to enable)  Usage copilotlocal can be used as a drop-in replacement for copilot. You can execute any copilot command as copilotlocal to run your intended action against LocalStack instead of AWS.\nTo deploy your init your copilot environment, execute the following command in your project folder:\ncopilotlocal init For more information about how to use the AWS Copilot CLI, checkout the copilot documentation. Just remember to replace copilot with copilotlocal.\n","categories":"","description":"Build, Release and Operate Containerized Applications on AWS with AWS Copilot CLI\n","excerpt":"Build, Release and Operate Containerized Applications on AWS with AWS …","ref":"/integrations/copilot/","tags":["continuous-delivery"],"title":"AWS Copilot CLI"},{"body":"Local Cloud Pods are a mechanism that allows you to take a snapshot of your local instance, persist it to a storage backend (e.g., git repository), and easily share it out with your team members.\nYou can create and manage Local Cloud Pods via the Web UI, and in order to load and store the persistent state of pods, you can use the localstack command line interface (CLI).\nBelow is a simple example of how you can push and pull Local Cloud Pods using the localstack CLI:\n# User 1 pushes state of Cloud Pod to persistent server $ awslocal kinesis list-streams {\"StreamNames\": [\"mystream123\"]} $ localstack pod push mypod1 ... # User 2 pulls state from the server to local instance $ localstack pod pull mypod1 $ awslocal kinesis list-streams {\"StreamNames\": [\"mystream123\"]}  Persistence configuration Using local Cloud pods requires setting the DATA_DIR configuration variable to point to a folder on your local machine - this folder will be used to persist and load the state of cloud pods in your local instance.  Local Cloud Pods support different storage mechanisms - currently we’re focusing on using git repositories as the storage backend, as git is often readily available on developers' machines and is easy to integrate with (no additional access control settings required). Support for more storage backends is coming soon (e.g., S3 buckets, FTP servers, etc.).\nYou can use the LocalStack Web UI to create a new Local Cloud Pod (make sure to adjust the Git URL and branch name to point to your repository):\nOnce the pod has been created, can use the CLI to log in and list the pod in your terminal: $ export LOCALSTACK_API_KEY=... $ localstack login ... $ localstack pod list Name Backend URL Size State ------ --------- --------------------------------- ------ ------- pod1 git ssh://git@github.com/your_org/... 1.68MB Shared\nLocalStack Pro feature Cloud Pods are a feature of LocalStack Pro. Please ensure that the LOCALSTACK_API_KEY is properly configured.  After the pod definition has been created, you should be able to use the push/pull commands listed above to push and pull the pod state to the Git repo. After pulling the pod, LocalStack will automatically inject pod state in your instance at runtime without requiring a restart.\nIn some cases, you may want to reset your current application state before pulling a pod. This can be achieved by manually deleting the DATA_DIR and restarting the application with the localstack pod reset command.\nBackup your state If you pull a Local Cloud Pod, it will attempt to merge the stored pod state with the existing state in your LocalStack instance. Please make sure to create a backup of any data before pulling a cloud pod, if required.  ","categories":["LocalStack Pro","Tools","Persistence"],"description":"Cloud Pods provides a new way of collaborating in cloud application development workflows.\n","excerpt":"Cloud Pods provides a new way of collaborating in cloud application …","ref":"/tools/cloud-pods/","tags":"","title":"Cloud Pods"},{"body":"LocalStack allows for many different configuration options. You can pass these via environment variables, e.g., like the following:\n$ SERVICES=kinesis,lambda,sqs,dynamodb DEBUG=1 localstack start Core    Variable Example Values Description     SERVICES kinesis,lambda,sqs,serverless Comma-separated list of AWS CLI service names or shorthands to start up.   EDGE_BIND_HOST 127.0.0.1 (default), 0.0.0.0 (docker) Address the edge service binds to.   EDGE_PORT 4566 (default) Port number for the edge service, the main entry point for all API invocations.   HOSTNAME localhost (default) Name of the host to expose the services internally. For framework-internal communication, e.g., services are started in different containers using docker-compose.   HOSTNAME_EXTERNAL localhost (default) Name of the host to expose the services externally. This host is used, e.g., when returning queue URLs from the SQS service to the client.   DEBUG 0|1 Flag to increase log level and print more verbose logs (useful for troubleshooting issues)   \u003cSERVICE\u003e_PORT_EXTERNAL 4567 Port number to expose a specific service externally . SQS_PORT_EXTERNAL, e.g. , is used when returning queue URLs from the SQS service to the client.   IMAGE_NAME localstack/localstack (default), localstack/localstack:0.11.0 Specific name and tag of LocalStack Docker image to use.   USE_LIGHT_IMAGE 1 (default) Whether to use the light-weight Docker image. Overwritten by IMAGE_NAME.   TMPDIR /tmp (default) Temporary folder on the host running the CLI and inside the LocalStack container .   HOST_TMP_FOLDER /some/path Temporary folder on the host that gets mounted as $TMPDIR/localstack into the LocalStack container. Required only for Lambda volume mounts when using LAMBDA_REMOTE_DOCKER=false.   DATA_DIR blank (disabled/default), /tmp/localstack/data Local directory for saving persistent data (see: TODO)   PERSISTENCE_SINGLE_FILE true (default) Specify if persistence files should be combined.   \u003cSERVICE\u003e_BACKEND  Custom endpoint URL to use for a specific service, where  is the uppercase service name. See (TODO) for supported services and (TODO) for examples for third-party integration   MAIN_CONTAINER_NAME localstack_main (default) Specify the main docker container name   INIT_SCRIPTS_PATH /some/path Specify the path to the initializing files with extensions .sh that are found default in /docker-entrypoint-initaws.d.   LS_LOG trace, trace-internal, debug, info, warn, error, warning Specify the log level. Currently overrides the DEBUG configuration. trace for detailed request/response, trace-internal for internal calls, too.    Docker Docker is used extensively by LocalStack, and there are several configuration parameters for how LocalStack interacts with Docker.\n   Variable Example Values Description     DOCKER_FLAGS  Allows to pass custom flags (e.g., volume mounts) to “docker run” when running LocalStack in Docker.   DOCKER_SOCK /var/run/docker.sock Path to local Docker UNIX domain socket   DOCKER_BRIDGE_IP 172.17.0.1 IP of the docker bridge used to enable access between containers   LEGACY_DOCKER_CLIENT 0|1 Whether LocalStack should use the command-line Docker client and subprocess execution to run Docker commands, rather than the Docker SDK.   DOCKER_CMD docker (default), sudo docker Shell command used to run Docker containers (only used in combination with LEGACY_DOCKER_CLIENT)   FORCE_NONINTERACTIVE  When running with Docker, disables the --interactive and --tty flags. Useful when running headless.    Local AWS Services This section covers configuration values that are specific to AWS services.\n DynamoDB Kinesis Lambda Stepfunctions  DynamoDB    Variable Example Values Description     DYNAMODB_ERROR_PROBABILITY Decimal value between 0.0(default) and 1.0 Randomly inject ProvisionedThroughputExceededException errors into DynamoDB API responses.   DYNAMODB_HEAP_SIZE 256m (default), 1G Sets the JAVA EE maximum memory size for DynamoDB; full table scans require more memory    Kinesis    Variable Example Values Description     KINESIS_ERROR_PROBABILITY Decimal value between 0.0(default) and 1.0 Randomly inject ProvisionedThroughputExceededException errors into Kinesis API responses.   KINESIS_SHARD_LIMIT 100 (default), Infinity (to disable) Integer value , causing the Kinesis API to start throwing exceptions to mimick the default shard limit.   KINESIS_LATENCY 500 (default), 0 (to disable) Integer value of milliseconds, causing the Kinesis API to delay returning a response in order to mimick latency from a live AWS call.   KINESIS_INITIALIZE_STREAMS \"my-first-stream:1,my-other-stream:2:us-west-2,my-last-stream:1\" A comma-delimited string of stream names, its corresponding shard count and an optional region to initialize during startup. If the region is not provided, the default region is used. Only works with the kinesis-mock KINESIS_PROVIDER.    Lambda    Variable Example Values Description     LAMBDA_EXECUTOR  Method to use for executing Lambda functions. For docker and docker-reuse, if LocalStack itself is started inside Docker, then the docker command needs to be available inside the container (usually requires to run the container in privileged mode). More information in Lambda Executor Modes.    docker (default) Run each function invocation in a separate Docker container.    local (fallback) Run Lambda functions in a temporary directory on the local machine.    docker-reuse Create one Docker container per function and reuse it across invocations.   LAMBDA_REMOTE_DOCKER  determines whether Lambda code is copied or mounted into containers    true (default) your Lambda function definitions will be passed to the container by copying the zip file (potentially slower). It allows for remote execution, where the host and the client are not on the same machine.    false your Lambda function definitions will be passed to the container by mounting a volume (potentially faster). This requires to have the Docker client and the Docker host on the same machine. Also, HOST_TMP_FOLDER must be set properly, and a volume mount like ${HOST_TMP_FOLDER}:/tmp/localstack needs to be configured if you’re using docker-compose.   BUCKET_MARKER_LOCAL  Optional bucket name for running lambdas locally.   LAMBDA_CODE_EXTRACT_TIME 25 Time in seconds to wait at max while extracting Lambda code. By default it is 25 seconds for limiting the execution time to avoid client/network timeout issues.   LAMBDA_DOCKER_NETWORK  Optional Docker network for the container running your lambda function.   LAMBDA_DOCKER_DNS  Optional DNS server for the container running your lambda function.   LAMBDA_DOCKER_FLAGS -e KEY=VALUE, -v host:container, -p host:container, --add-host domain:ip Additional flags passed to Lambda Docker run|create commands (e.g., useful for specifying custom volume mounts). Does only support environment, volume, port and add-host flags   LAMBDA_CONTAINER_REGISTRY lambci/lambda (default) An alternative docker registry from where to pull lambda execution containers.   LAMBDA_REMOVE_CONTAINERS true (default) Whether to remove containers after Lambdas finished executing.   LAMBDA_FALLBACK_URL  Fallback URL to use when a non-existing Lambda is invoked. Either records invocations in DynamoDB (value dynamodb://\u003ctable_name\u003e) or forwards invocations as a POST request (value http(s)://...).   LAMBDA_FORWARD_URL  URL used to forward all Lambda invocations (useful to run Lambdas via an external service).   LAMBDA_JAVA_OPTS -Xmx512M Allow passing custom JVM options to Java Lambdas executed in Docker. Use _debug_port_ placeholder to configure the debug port, e.g., -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=_debug_port_.   HOSTNAME_FROM_LAMBDA localstack Endpoint host under which APIs are accessible from Lambda containers (optional). This can be useful in docker-compose stacks to use the local container hostname if neither IP address nor container name of the main container are available (e.g., in CI). Often used in combination with LAMBDA_DOCKER_NETWORK.    Stepfunction    Variable Example Values Description     STEPFUNCTIONS_LAMBDA_ENDPOINT default URL to use as the Lambda service endpoint in Step Functions. By default this is the LocalStack Lambda endpoint. Use default to select the original AWS Lambda endpoint.    Security Please be aware that the following configurations may have severe security implications!\n   Variable Example Values Description     DISABLE_CORS_CHECKS 0 (default) Whether to disable all CSRF mitigations.   DISABLE_CUSTOM_CORS_S3 0 (default) Whether to disable CORS override by S3.   DISABLE_CUSTOM_CORS_APIGATEWAY 0 (default) Whether to disable CORS override by apigateway.   EXTRA_CORS_ALLOWED_ORIGINS  Comma-separated list of origins that are allowed to communicate with localstack.   EXTRA_CORS_ALLOWED_HEADERS  Comma-separated list of header names to be be added to Access-Control-Allow-Headers CORS header.   EXTRA_CORS_EXPOSE_HEADERS  Comma-separated list of header names to be be added to Access-Control-Expose-Headers CORS header.    Provider Some of the services can be configured to switch to a particular provider:\n   Variable Valid options     KINESIS_PROVIDER kinesis-mock (default) and kinesalite   KMS_PROVIDER moto (default) and local-kms   SQS_PROVIDER moto (default) and elasticmq    Miscellaneous    Variable Example Values Description     SKIP_INFRA_DOWNLOADS  Whether to skip downloading additional infrastructure components (e.g., specific Elasticsearch versions).   IGNORE_ES_DOWNLOAD_ERRORS  Whether to ignore errors (e.g., network/SSL) when downloading Elasticsearch plugins.   OVERRIDE_IN_DOCKER  Overrides the check whether LocalStack is executed within a docker container. If set to true, LocalStack assumes it runs in a docker container. Should not be set unless necessary.   EDGE_FORWARD_URL  Optional target URL to forward all edge requests to (e.g., for distributed deployments).   DISABLE_EVENTS 1 Whether to disable publishing LocalStack events    Debugging    Variable Example Values Description     DEVELOP  Starts a debugpy server before starting LocalStack services   DEVELOP_PORT  Port number for debugpy server   WAIT_FOR_DEBUGGER  Forces LocalStack to wait for a debugger to start the services    DNS More information here.\n   Variable Example Values Description     DNS_ADDRESS 0.0.0.0 (default) Address the LocalStack should bind the DNS server on (port 53 tcp/udp). Value 0 to disable.   DNS_SERVER 8.8.8.8 (default) Fallback DNS server for non-modified queries.   DNS_LOCAL_NAME_PATTERNS  Names which should be resolved to the LocalStack IP, as python-compatible regex.    LocalStack Pro More information here.\n   Variable Example Values Description     LOCALSTACK_API_KEY  API key to activate LocalStack Pro.   LOG_LICENSE_ISSUES 1 (default) Whether to log issues with the license activation to the console.   REQUIRE_PRO 0 (default) Whether to require license activation to succeed to start LocalStack. If set to 0 (default) LocalStack will start as community version if the license cannot be activated.    Read-only    Variable Usage Example Description     LOCALSTACK_HOSTNAME http://${LOCALSTACK_HOSTNAME}:4566 Name of the host where LocalStack services are available. Use this hostname as endpoint in order to access the services from within your Lambda functions (e.g., to store an item to DynamoDB or S3 from a Lambda).    Deprecated    Variable Example Values Description     USE_SSL false (default) Whether to use https://… URLs with SSL encryption. Deprecated as of version 0.11.3 - each service endpoint now supports multiplexing HTTP/HTTPS traffic over the same port.   DEFAULT_REGION  AWS region to use when talking to the API (needs to be activated via USE_SINGLE_REGION=1). Deprecated and inactive as of version 0.12.17 - LocalStack now has full multi-region support.   USE_SINGLE_REGION  Whether to use the legacy single-region mode, defined via DEFAULT_REGION.    ","categories":"","description":"Environment variables which affect LocalStack.\n","excerpt":"Environment variables which affect LocalStack.\n","ref":"/localstack/configuration/","tags":"","title":"Configuration"},{"body":"This guide shows you how to start LocalStack in a Github Actions job.\nSetting up your Github Actions job In order to start LocalStack, we recommend to start it in a separate build step, to separate its log output / status from the rest of your job.\nWe recommend taking the following steps:\n Install the LocalStack CLI (and maybe also awslocal). Make sure your LocalStack docker image is up-to-date by pulling the latest version. Use the LocalStack CLI to start LocalStack. Make sure to use the DOCKER_FLAGS='-d' to start the LocalStack docker container in detached mode. Wait for the container to report that it is up and running.  An official GitHub action for this also planned, to make the configuration easier and less verbose.\nThe following example can be integrated into your GitHub workflow. As an example, it will use awslocal to create bucket and list it afterwards.\nname:localstack-action-exampleon:pushjobs:example-job:runs-on:ubuntu-lateststeps:- name:Start LocalStackenv:LOCALSTACK_API_KEY:${{ secrets.LOCALSTACK_API_KEY }}run:|# install LocalStack cli and awslocal pip install localstack awscli-local[ver1] # Make sure to pull the latest version of the image docker pull localstack/localstack # Start LocalStack DOCKER_FLAGS='-d' localstack start # Wait for the LocalStack docker container to become ready echo \"Waiting for LocalStack startup...\" for i in {1..45}; do if [ `docker logs localstack_main | grep 'Ready.'` ]; then break; fi; sleep 1; done echo \"Startup complete\"- name:Run some Tests against LocalStackrun:|awslocal s3 mb s3://test awslocal s3 ls echo \"Test Execution complete!\"If you want to add further configuration for LocalStack, you can use the env section of your build step to set the configuration variables as described here.\nActivating LocalStack Pro If you want to use LocalStack Pro in your GitHub Actions job, you should use a Github Encrypted Secret to store your API key securely. In the above example, you can see us setting the LOCALSTACK_API_KEY environment variable to the value of the secret LOCALSTACK_API_KEY.\nYou can set your secret at an environment, repository or organization level, for more information see here. In the simplest case, you just set it at the repository level. For this, you go, in your repository, to Settings =\u003e Secrets and press “New Repository Secret”.\nThere, you create the secret for your API key like in the following image, replacing foobar with your API key.\n","categories":"","description":"Use LocalStack in [GitHub Actions](https://github.com/features/actions)\n","excerpt":"Use LocalStack in [GitHub …","ref":"/ci/github-actions/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"GitHub Actions"},{"body":"LocalStack has an extensive set of integration tests. This document describes how to run and write integration tests.\nRunning the test suite To run the tests you can use the make target and set the TEST_PATH variable.\nTEST_PATH=\"tests/integration\" make test or run it manually within the virtual environment:\npython -m pytest --log-cli-level=INFO tests/integration Running individual tests You can further specify the file and test class you want to run in the test path:\nTEST_PATH=\"tests/integration/docker/test_docker.py::TestDockerClient\" make test Test against a running LocalStack instance When you run the integration tests, LocalStack is automatically started (via the pytest conftest mechanism in tests/integration/conftest.py). You can disable this behavior by setting the environment variable TEST_SKIP_LOCALSTACK_START=1.\nTest against real AWS It can be useful to run an integration test against the real AWS cloud using your credentials. You can do this by setting the environment variable TEST_TARGET=\"AWS_CLOUD\".\nWriting a test We use pytest for our testing framework. Older tests were written using the unittest framework, but its use is discouraged.\nIf your test matches the pattern tests/integration/**/test_*.py it will be picked up by the integration test suite.\nFunctional-style tests You can write functional style tests by defining a function with the prefix test_ with basic asserts:\ndef test_something(): assert True is not False Class-style tests Or you can write class-style tests by grouping tests that logically belong together in a class:\nclass TestMyThing: def test_something(self): assert True is not False Fixtures We use the pytest fixture concept, and provide several fixtures you can use when writing AWS tests. For example, to inject a Boto client for SQS, you can specify the sqs_client in your test method:\nclass TestMyThing: def test_something(self, sqs_client): assert len(sqs_client.list_queues()[\"QueueUrls\"]) == 0 We also provide fixtures for certain disposable resources, like buckets:\ndef test_something_on_a_bucket(s3_bucket): s3_bucket # s3_bucket is a boto s3 bucket object that is created before # the test runs, and removed after it returns. Another pattern we use is the factory as fixture pattern.\ndef test_something_on_multiple_buckets(s3_create_bucket): bucket1 = s3_create_bucket() bucket2 = s3_create_bucket() # both buckets will be deleted after the test returns You can find the list of available fixtures in the fixtures.py.\n","categories":"","description":"How to run and write integration tests.\n","excerpt":"How to run and write integration tests.\n","ref":"/developer-guide/integration-tests/","tags":"","title":"Integration tests"},{"body":"Overview LocalStack currently supports three different modes for lambda execution. They differ in when and where your lambda code is executed, and in term of feature set and execution speed.\nExecution modes The active lambda executor can be set using the LAMBDA_EXECUTOR environment variable, which has the 3 possible options local, docker and docker-reuse.\nThe default option is docker, unless LocalStack has no access to a docker daemon itself when it will be set to local.\nLocal execution Configuration: LAMBDA_EXECUTOR=local\nIn this execution mode, the lambda code is executed directly in the context of LocalStack itself. Therefore, if LocalStack is executed within docker, all the Lambda executions take place within that same container, and if it is executed in host mode, it will be executed directly on your machine. If lambda container images are used, and the local executor is set, the execution of these images will automatically take place using the docker executor (regular lambdas will continue to use the local executor).\nLocal executor mode currently supports the following Lambda Platforms:\n Python Nodejs Java Go  Lambdas on other platforms like .Net currently need to be executed in on of the docker modes.\nDocker Configuration: LAMBDA_EXECUTOR=docker\nThe docker execution mode will execute lambdas in an docker container. For this, every lambda invocation creates and runs a new docker container and returns its result when its finished. The advantage of this mode is the fresh lambda environment from each start, so possible leftovers during previous invocations will be purged. Due to the nature of this mode, mainly recreating the container for each invocation, this mode is rather slow. A typical invocation of a dummy python lambda can take around 3 seconds from start to finish (awscli invoke - start to finish). All supported lambda types can be used with this executor.\nDocker re-use Configuration: LAMBDA_EXECUTOR=docker-reuse\nThis execution mode provides a balance between the speed of a local execution and the feature set and isolation of the docker executor. While the initial call, which creates the container, will take roughly the same time of docker executor, the subsequent invocations will only take around 1 second (start to finish, invoked using the awscli), which roughly the time an actual aws invocation using this method takes. The container is kept running 10 minutes after the last invocation for this lambda, then it will be destroyed (and recreated if necessary for the next invocation).\n","categories":"","description":"Overview of the different Lambda execution modes\n","excerpt":"Overview of the different Lambda execution modes\n","ref":"/localstack/lambda-executors/","tags":"","title":"Lambda Executor Modes"},{"body":"Covered Topics  JVM Testing Utils  JVM Testing Utils LocalStack provides Java Utils library that integrates with JUnit and provides LocalStack-targeted AWS Clients.\nInstallation Maven  Gradle   \u003cdependency\u003e \u003cgroupId\u003ecloud.localstack\u003c/groupId\u003e \u003cartifactId\u003elocalstack-utils\u003c/artifactId\u003e \u003cversion\u003e0.2.15\u003c/version\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e testImplementation group: 'cloud.localstack', name: 'localstack-utils', version: '0.2.15'  Usage Java  Kotlin   ... import cloud.localstack.LocalstackTestRunner; import cloud.localstack.ServiceName; import cloud.localstack.TestUtils; import cloud.localstack.docker.annotation.LocalstackDockerProperties; @RunWith(LocalstackTestRunner.class) @LocalstackDockerProperties(services = { ServiceName.S3, \"sqs\", \"kinesis\" }) public class MyCloudAppTest { @Test public void testLocalS3API() { AmazonS3 s3 = TestUtils.getClientS3() List\u003cBucket\u003e buckets = s3.listBuckets(); ... } } ... import cloud.localstack.LocalstackTestRunner import cloud.localstack.ServiceName import cloud.localstack.TestUtils import cloud.localstack.docker.annotation.LocalstackDockerProperties @RunWith(LocalstackTestRunner::class) @LocalstackDockerProperties(services = [ServiceName.S3, \"sqs\", \"kinesis\"]) public class MyCloudAppTest { @Test fun testLocalS3API() { val s3 = TestUtils.getClientS3() val buckets = s3.listBuckets(); ... } }  Powermock You can use the PowerMock Library to call the builders default method and still get LocalStack version of the AWS clients.\n... @RunWith(PowerMockRunner.class) @PowerMockRunnerDelegate(LocalstackTestRunner.class) @LocalstackDockerProperties(services = { \"ses\" }) @PrepareForTest({ AmazonSimpleEmailServiceClientBuilder.class, AmazonSimpleEmailServiceAsyncClientBuilder.class }) @PowerMockIgnore({\"javax.crypto.*\", \"org.hamcrest.*\", \"javax.net.ssl.*\", \"com.sun.org.apache.xerces.*\", \"javax.xml.*\", \"org.xml.*\", \"javax.management.*\", \"javax.security.*\", \"org.w3c.*\"}) public class SESMessagingTest { .... @Before public void mockSES() { AmazonSimpleEmailService mockSes = TestUtils.getClientSES(); PowerMockito.mockStatic(AmazonSimpleEmailServiceClientBuilder.class); when(AmazonSimpleEmailServiceClientBuilder.defaultClient()).thenReturn(mockSes); } @Test public void testSendEmail() throws Exception { AmazonSimpleEmailService client = amazonSimpleEmailServiceClientBuilder.defaultClient(); .... PowerMockLocalStack Utility This utility makes easier to use PowerMock with Localstack.\n... public class PowerMockLocalStackExampleTest extends PowerMockLocalStack{ private static final String TOPIC = \"topic\"; @Before public void mock() { PowerMockLocalStack.mockSNS(); } @Test public void testSendMessage() throws JMSException { final AmazonSNS clientSNS = AmazonSNSClientBuilder.defaultClient(); ... } } ","categories":["LocalStack Community","LocalStack Pro"],"description":"Tools to simplify application testing\n","excerpt":"Tools to simplify application testing\n","ref":"/tools/testing-tools/","tags":"","title":"LocalStack Testing Tools"},{"body":"The persistence mechanism is essentially a “pause and resume” feature for your LocalStack application state. For instance, you may want to run consecutive integration tests where each test loads in a different context but depends on the state produced by a previous test. Commonly, you may simply have a local development server that relies on a non-ephemeral application state.\nWhile the persistence mechanism covers most services, not all of them are supported yet. Please make sure to check the feature coverage page to see whether your desired services are covered. Please note that the coverage is only guaranteed for the Pro version, while the Community version attempts to restore the state on a best-effort basis using a record-and-replay approach (more on that in the Technical Details section).\nTo enable the persistence mechanism simply set the DATA_DIR environment variable. For instance, DATA_DIR=/tmp/localstack/data will store all relevant files to the /tmp/localstack/data directory. Please note that the path is created recursively, that is you do not have to make sure that the set path exists.\nWhen working with Docker you may want to specify a different location for temporary folders using the HOST_TMP_FOLDER flag. In this case, it is advisable to use a $TMPDIR variable, which you can re-use for both flags. For instance, you’ll set $TMPDIR=/tmp/my-tmp then your environment configuration in your docker-compose file could look as follows:\n...environment:- LOCALSTACK_API_KEY=...- DATA_DIR=${TMPDIR}/localstack/data- HOST_TMP_FOLDER=${TMPDIR}volumes:- ${TMPDIR}:/tmp/localstackOnce the application has been set and configured properly, the /health endpoint of LocalStack will indicate whether the persistence mechanism has been initialized successfully.\n\"features\": { \"persistence\": \"initialized\" } Otherwise, the endpoint will inform you that the mechanism is disabled.\n\"features\": { \"persistence\": \"disabled\" } Technical Details Depending on whether you use the Pro or the Community version, the persistence mechanism uses different ways to restore the application state.\nPersistence Mechanism - Community Version When starting the Community version of LocalStack the persistence mechanism is based on a simplistic record-and-replay approach. That is, API calls are recorded while the application is running, which then are replayed once the application reboots. Whether API calls have successfully been replayed can be seen in the logs. For instance, starting the application and creating an SQS queue with the awslocal sqs create-queue --queue-name sample-queue CLI command, followed by a reboot will produce the following log:\n2021-09-27T14:38:07:INFO:localstack.utils.persistence: Restored 1 API calls from persistent file: /tmp/localstack/data/recorded_api_calls.json While this approach is generic enough to cover a sizable amount of services, there are three crucial limitations:\n Every recorded API call is literally being replayed on startup, which will inevitability lead to prolonged startup times. Replaying the exact same API calls is not guaranteed to converge to the same state. Rather, diverging states is the more likely outcome. This limitation is not the result of any implementation details related to LocalStack, but a result of how related AWS resources reference each other. For instance, sending messages to an SQS queue is done by providing the queue URL. However, there is no guarantee that our sample-queue will have the same URL after a reboot, which then would result in NonExistingQueue during the replay of send-message API calls. For this reason, LocalStack provides no guarantees of the correctness and completeness for any state restored using the record-and-replay approach. The state recorded this way cannot be used to create CloudPods.  Persistence Mechanism - Pro Version The persistence mechanism of the Pro version is much more sophisticated and is based on serialized state. Starting the Pro version of LocalStack will traverse the DATA_DIR root folder recursively and directly deserialize the file into the application state. Typically, each service has one state file for each region.\nEach serialization mechanism has its own root folder. As of now, all supported services are serialized as pickle files, except for Kinesis (which is serialized as JSON) and DynamoDB (which is serialized as an SQLite database). This is illustrated with the diagram below.\nThis approach does not suffer from the same limitations as record-and-replay. Restoring the state – even for large projects – usually only takes a few milliseconds. Moreover, since the files store accurate snapshots of application state it can restore a state that is identical to the one prior to the reboot.\nHowever, the limitation of this approach is that it is not quite as generic. The record-and-replay approach can treat the AWS services as “black-boxes”, i.e. the persistence mechanism is entirely decoupled from the underlying services, while the serialized state approach is coupled to the serialization mechanism of each service. The consequence of this limitation is that, as of now, not all services have a supported persistence mechanism yet.\n","categories":"","description":"How the LocalStack persistence mechanism works and how you can configure it.\n","excerpt":"How the LocalStack persistence mechanism works and how you can …","ref":"/localstack/persistence-mechanism/","tags":"","title":"Persistence Mechanism Configuration"},{"body":"Overview This guide covers the remote debugging of Lambda functions with Visual Studio Code or IntelliJ IDEA as an IDE. For a simple working example of this feature, check out our samples repository.\n   Complexity ★☆☆☆☆     Time to read 5 minutes   Edition community/pro   Platform any    More examples and tooling support for local Lambda debugging (including support for other IDEs like PyCharm) is coming soon - stay tuned!\nCovered Topics  Debugging Python lambdas Debugging JVM lambdas Useful Links  Debugging Python lambdas Lambda functions debugging used to be a difficult task. LocalStack changes that with the same local code mounting functionality that also helps you to iterate quickly over your function code.\nFor a simple working example of this feature, you can refer to our samples. There, the necessary code fragments for enabling debugging are already present.\nConfigure LocalStack for remote Python debugging First, make sure that LocalStack is started with the following configuration (see the Configuration docs for more information): $ LAMBDA_REMOTE_DOCKER=0 \\ LAMBDA_DOCKER_FLAGS='-p 19891:19891' \\ DEBUG=1 localstack start\nPreparing your code For providing the debug server, we use debugpy inside the Lambda function code. In general, all you need is the following code fragment placed inside your handler code:\nimport debugpy debugpy.listen(19891) debugpy.wait_for_client() # blocks execution until client is attached For extra convenience, you can use the wait_for_debug_client function from our example. It implements the above-mentioned start of the debug server and also adds an automatic cancellation of the wait task if the debug client (i.e. VSCode) doesn’t connect.\ndef wait_for_debug_client(timeout=15): \"\"\"Utility function to enable debugging with Visual Studio Code\"\"\" import time, threading import sys, glob sys.path.append(glob.glob(\".venv/lib/python*/site-packages\")[0]) import debugpy debugpy.listen((\"0.0.0.0\", 19891)) class T(threading.Thread): daemon = True def run(self): time.sleep(timeout) print(\"Canceling debug wait task ...\") debugpy.wait_for_client.cancel() T().start() print(\"Waiting for client to attach debugger ...\") debugpy.wait_for_client() Creating the Lambda function To create the Lambda function, you just need to take care of two things:\n Deploy the function via an S3 Bucket. You need to use the magic variable __local__ as the bucket name. Set the S3 key to the path of the directory your lambda function resides in. The handler is then referenced by the filename of your lambda code and the function in that code that should be invoked.  So, in our example, this would be:\n$ awslocal lambda create-function --function-name my-cool-local-function \\ --code S3Bucket=\"__local__\",S3Key=\"$(pwd)/\" \\ --handler handler.handler \\ --runtime python3.8 \\ --role cool-stacklifter We can quickly verify that it works by invoking it with a simple payload:\n$ awslocal lambda invoke --function-name my-cool-local-function --payload '{\"message\": \"Hello from LocalStack!\"}' output.txt Configuring Visual Studio Code for remote Python debugging For attaching the debug server from Visual Studio Code, you need to add a run configuration.\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Python: Remote Attach\", \"type\": \"python\", \"request\": \"attach\", \"connect\": { \"host\": \"localhost\", \"port\": 19891 }, \"pathMappings\": [ { \"localRoot\": \"${workspaceFolder}\", \"remoteRoot\": \".\" } ] } ] } With our function from above you have about 15 seconds (the timeout is configurable) to switch to Visual Studio Code and run the preconfigured remote debugger. Make sure to set a breakpoint in the Lambda handler code first, which can then later be inspected.\nThe screenshot below shows the triggered breakpoint with our 'Hello from LocalStack!' in the variable inspection view:\nLimitations Due to the ports used by the debugger, you can currently only debug one Lambda at a time. Multiple concurrent invocations will not work.\nDebugging JVM lambdas Configure LocalStack for remote JVM debugging Set LAMBDA_JAVA_OPTS with jdwp settings and expose the debug port (you can use any other port of your choice):\n#docker-compose.ymlservices:localstack:...environment:...- LAMBDA_JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=*:5050- LAMBDA_DOCKER_FLAGS=-p 127.0.0.1:5050:5050Note the suspend=y option here, it will delay code execution until debugger is attached to debgger server. If you want to change that simply switch to suspend=n.\nConfiguring IntelliJ IDEA for remote JVM debugging Open the Run/Debug Configurations window and create a new Shell Script with the following content:\nwhile [[ -z $(docker ps | grep :5050) ]]; do sleep 1; done This shell script should simplify the process a bit since the debugger server is not immediately available (only once lambda container is up).\nThen create a new Remote JVM Debug configuration and use the script from above as a Before launch target:\nNow to debug your lambda function, simply click on the Debug icon with Remote JVM on LS Debug configuration selected, and then invoke your lambda function.\nConfiguring Visual Studio Code for remote JVM debugging Make sure you installed the following extensions:\n Language Support for Java(TM) by Red Hat Debugger for Java  Add a new task by creating/modifying the .vscode/tasks.json file:\n{ \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"Wait Remote Debugger Server\", \"type\": \"shell\", \"command\": \"while [[ -z $(docker ps | grep :5050) ]]; do sleep 1; done; sleep 1;\" } ] } Create a new launch.json file or edit an existing one from the Run and Debug tab, then add the following configuration:\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"java\", \"name\": \"Remote JVM on LS Debug\", \"projectRoot\": \"${workspaceFolder}\", \"request\": \"attach\", \"hostName\": \"localhost\", \"preLaunchTask\": \"Wait Remote Debugger Server\", \"port\": 5050 } ] } Now to debug your lambda function, click on the Debug icon with Remote JVM on LS Debug configuration selected, and then invoke your lambda function.\nResources  Lambda Code Mounting and Debugging (Python) Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Attach a debugger to your Lambda functions from your IDE.\n","excerpt":"Attach a debugger to your Lambda functions from your IDE.\n","ref":"/tools/lambda-tools/debugging/","tags":"","title":"Remote Debugging"},{"body":"Overview Terraform allows you to automate the management of AWS resources such as containers, lambda functions and so on by declaring them in the HashiCorp Configuration Language (HCL). On this page we discuss how Terraform and LocalStack can be used together. If you are adapting an existing configuration, you might be able to skip certain steps at your own discretion.\nExample If you have not done so yet, install Terraform.\nUsing Terraform with LocalStack requires little extra configuration. Apart from some information Terraform expects there are basically only two things to take care of in the configuration.\nBefore we start changing the configuration, create and change into a new directory for this sample\n$ mkdir terraform_quickstart \u0026\u0026 cd terraform_quickstart Inside this directory, create a file called main.tf. The following changes go into this file.\nGeneral Configuration First, we have to specify mock credentials for the AWS provider:\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\" } Request Management Second, we need to avoid issues with routing and authentication (as we do not need it). Therefore we need to supply some general parameters:\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\" s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true } Services Additionally, we have to point the individual services to LocalStack. In case of S3, this looks like the following snippet\nendpoints { s3 = \"http://localhost:4566\" }  Note: To enable domain style routing for s3 buckets, the endpoint http://s3.localhost.localstack.cloud:4566 should be used.  S3 Bucket Now we are adding a minimal s3 bucket outside the provider\nresource \"aws_s3_bucket\" \"test-bucket\" { bucket = \"my-bucket\" } Final Configuration The final (minimal) configuration to deploy an s3 bucket thus looks like this\nprovider \"aws\" { access_key = \"mock_access_key\" secret_key = \"mock_secret_key\" region = \"us-east-1\" s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { s3 = \"http://s3.localhost.localstack.cloud:4566\" } } resource \"aws_s3_bucket\" \"test-bucket\" { bucket = \"my-bucket\" } After starting LocalStack you can now deploy the s3 bucket via terraform and interact with the (still empty) s3 bucket via awslocal!\nAll you need to do is to initialize Terraform\n$ terraform init and then deploy the configuration $ terraform deploy\nEndpoint configuration Here is a configuration example with additional endpoints:\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\" s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway = \"http://localhost:4566\" cloudformation = \"http://localhost:4566\" cloudwatch = \"http://localhost:4566\" dynamodb = \"http://localhost:4566\" ec2 = \"http://localhost:4566\" es = \"http://localhost:4566\" elasticache = \"http://localhost:4566\" firehose = \"http://localhost:4566\" iam = \"http://localhost:4566\" kinesis = \"http://localhost:4566\" lambda = \"http://localhost:4566\" rds = \"http://localhost:4566\" redshift = \"http://localhost:4566\" route53 = \"http://localhost:4566\" s3 = \"http://localhost:4566\" secretsmanager = \"http://localhost:4566\" ses = \"http://localhost:4566\" sns = \"http://localhost:4566\" sqs = \"http://localhost:4566\" ssm = \"http://localhost:4566\" stepfunctions = \"http://localhost:4566\" sts = \"http://localhost:4566\" } } Further reading For more examples, you can take a look at our terraform sample or the terraform localstack section.\nCommunity resources  Localstack with Terraform and Docker for running AWS locally. 2021-07-04  ","categories":"","description":"Use the Terraform Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Terraform Infrastructure as Code framework with LocalStack\n","ref":"/integrations/terraform/","tags":["terraform","infrastructure-as-code"],"title":"Terraform"},{"body":"Overview LocalStack Pro supports transparent execution mode, which means that your application code automatically accesses the LocalStack APIs as opposed to the real APIs on AWS.\nWhen the system starts up, the log output contains the IP address of the local DNS server. Typically, this address by default is either 0.0.0.0 (see example below) or 127.0.0.1 if LocalStack cannot bind to 0.0.0.0 due to a conflicting service.\nStarting DNS servers (tcp/udp port 53 on 0.0.0.0)... Configuration The DNS server can be configured to match your usecase.\n  The DNS server can be configured using the DNS_ADDRESS environment variable. To bind the server to 127.0.0.1, you can set:\nDNS_ADDRESS=127.0.0.1   You can disable the DNS server (which will prevent LocalStack from binding port 53) using:\nDNS_ADDRESS=0   You can also specify which exact URLs should be redirected to LocalStack by defining a hostname regex like:\nDNS_LOCAL_NAME_PATTERNS='.*(ecr|lambda).*.amazonaws.com' Using this configuration, the LocalStack DNS server only redirects ECR and Lambda domains to LocalStack, and the rest will be resolved via $DNS_SERVER. This can be used for hybrid setups, where certain API calls (e.g., ECR, Lambda) target LocalStack, whereas other services will target real AWS.\nNote: We generally do not recommend connecting to real AWS from within LocalStack, in fact you should avoid using real AWS credentials anywhere in your LocalStack apps. Use this configuration with caution.\n  There is the possibility to manually set the DNS server all not-redirected queries will be forwarded to:\nDNS_SERVER=1.1.1.1 Per default, LocalStack uses the Google DNS resolver at 8.8.8.8.\n  Limitations When you configure transparent execution mode using DNS, you may still have to configure your application’s AWS SDK to accept self-signed certificates. This is a technical limitation caused by the SSL certificate validation mechanism, due to the fact that we are repointing AWS domain names (e.g., *.amazonaws.com) to localhost. For example, the following command will fail with an SSL error: $ aws kinesis list-streams SSL validation failed for https://kinesis.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076) … whereas the following command works: $ PYTHONWARNINGS=ignore aws --no-verify-ssl kinesis list-streams { \"StreamNames\": [] }\nDisabling SSL validation depends on the programming language and version of the AWS SDK used. For example, the boto3 AWS SDK for Python provides a parameter verify=False to disable SSL verification. Similar parameters are available for most other AWS SDKs.\nSystem DNS configuration In order to use transparent execution mode, the system needs to be configured to use the predefined DNS server. This is necessary if you want to test code running directly on your system against LocalStack, instead of AWS. The configuration depends on the operating system.\nNote: Please be careful when changing the network configuration on your system, as this may have undesired side effects.\nMac OS In Mac OS it can be configured in the Network System Settings, under Linux this is usually achieved by configuring /etc/resolv.conf as follows:\nnameserver 0.0.0.0 The example above needs to be adjusted to the actual IP address of the DNS server. You can also configure a custom IP address by setting the DNS_ADDRESS environment variable (e.g., DNS_ADDRESS=127.0.0.1).\nLinux In Linux, the configuration depends on your network manager / DNS configuration.\nsystemd-resolved On many modern systemd-based distributions, like Ubuntu, systemd-resolved is used for name resolution. LocalStack provides a CLI command for exactly this scenario. To use systemd-resolved and the LocalStack domain resolution, try the following steps.\n  Start LocalStack Pro with DNS_ADDRESS=127.0.0.1 as environment variable. This makes LocalStack bind port 53 on 127.0.0.1, whereas systemd-resolved binds its stub resolver to 127.0.0.53:53, which prevents a conflict. Once LocalStack is started, you can test the DNS server using dig @127.0.0.1 s3.amazonaws.com versus dig @127.0.0.53 s3.amazonaws.com, the former should return an A record 127.0.0.1, the latter the real AWS DNS result.\n  Run: $ localstack dns systemd-resolved\nTo revert, please run: $ localstack dns systemd-resolved --revert\nNote: You need sudo privileges to execute this command.\nThis command sets the DNS server of the bridge interface of the docker network LocalStack currently runs in to the LocalStack container’s IP address. (The command does not work with host networking or without LocalStack running for this reason.) Also, it configures the DNS route to exclusively (and only) route the following DNS names (and its subdomains) to the LocalStack DNS:\n~amazonaws.com ~aws.amazon.com ~cloudfront.net ~localhost.localstack.cloud   If you want to perform this action manually, please do the following steps:\n  Find out the bridge interface and container IP of your LocalStack container. Use docker inspect localstack_main to get the IP address and network, then docker inspect network to get the interface name. If the interface name is not mentioned, it is usually the first 12 characters of the network ID prefixed with br-, like br-0ae393d3345e. If you use the default bridge network, it is usually docker0.\n  Configure the DNS resolver for the bridge network: # resolvectl dns \u003cnetwork_name\u003e \u003ccontainer_ip\u003e\n  Set the DNS route to route only the above mentioned domain names (and subdomains) to LocalStack: # resolvectl domain \u003cnetwork_name\u003e ~amazonaws.com ~aws.amazon.com ~cloudfront.net ~localhost.localstack.cloud\n  In both cases, you can use resolvectl query s3.amazonaws.com or resolvectl query example.com to check which interface your DNS request is routed through, to confirm only the above mentioned domains (and its subdomains) are routed to LocalStack.\nWhen correctly configured, either using the LocalStack CLI command or manually, only the requests for the mentioned domain names are routed to LocalStack, all other queries will resolve as usual.\nOther resolution settings Depending on your Linux distribution, the settings to set a DNS server can be quite different. In some systems, directly editing /etc/resolv.conf is possible, like described in Mac OS. If your /etc/resolv.conf is overwritten by some service, it might be possible to install and enable/start resolvconf and specify the nameserver in /etc/resolvconf/resolv.conf.d/head with nameserver 127.0.0.1. This will prepend this line in the resolv.conf file even after changes.\nNote: Using this options, every DNS request is forwarded to LocalStack, which will forward queries it does not need to modify (in essence all but certain aws domains). LocalStack will not store or share any forwarded DNS requests, except maybe in the local logs on exceptions / in debug mode.\n","categories":["LocalStack Pro","Tools","DNS"],"description":"Use LocalStack as DNS server to redirect AWS queries to LocalStack\n","excerpt":"Use LocalStack as DNS server to redirect AWS queries to LocalStack\n","ref":"/tools/local-endpoint-injection/dns-server/","tags":"","title":"DNS Server"},{"body":"Overview The Lambda runtime in LocalStack uses patched AWS SDKs, which are configured to target the local APIs instead of the real AWS. This behavior is enabled by default for most Lambda runtimes when using LocalStack Pro.\nAssuming you had a Python Lambda handler that attempts to list all S3 buckets. In the past, you had to manually configure the endpoint_url parameter on the boto3 client (and potentially use environment switches for dev/prod in your test code):\nimport boto3 def handler(event, context): client = boto3.client(\"s3\", endpoint_url=\"http://localhost:4566\") print(client.list_buckets()) With the patched AWS SDKs, it now becomes possible to deploy your unmodified production code to LocalStack, simply creating a boto3 client with default settings. The invocations of the boto3 client will be automatically forwarded to the local APIs:\nimport boto3 def handler(event, context): client = boto3.client(\"s3\") print(client.list_buckets())  Note: This functionality only works when using the SDKs provided by the Lambda execution environment itself. If you choose to ship your own SDKs with your Lambda or using a layer, it will fallback to the DNS based transparent execution if enabled, since those SDK versions will not be patched.  This feature works by patching the AWS SDKs in the docker images, which provide the execution environment for Lambdas within LocalStack.\nThe main advantage of this mode is, that no DNS magic is involved, and SSL certificate checks do not have to be disabled.\nConfiguration If you want to disable this behavior, and use the DNS server to resolve the endpoints for AWS, you can disable this behavior by using:\nTRANSPARENT_LOCAL_ENDPOINTS=0 Supported Runtimes Currently, LocalStack supports patching the SDKs for the following runtimes:\n Python (using boto3) NodeJS Ruby Java  Also, these patched SDKs are only available in the following Lambda execution modes:\n docker docker-reuse  This feature is currently not supported for custom Lambda container images.\n","categories":["LocalStack Pro","Tools"],"description":"Using patched SDKs in Lambdas to transparently redirect AWS API calls to LocalStack\n","excerpt":"Using patched SDKs in Lambdas to transparently redirect AWS API calls …","ref":"/tools/local-endpoint-injection/patched-sdks/","tags":"","title":"Patched AWS SDKs for Lambdas"},{"body":"Overview This guide describes how you can monitor and debug your AWS Lambda functions with Thundra.\nIntegrating Thundra with LocalStack Supported languages Currently only Node.js, Python and Java Lambdas are supported in this integration - support for other runtimes (.NET, Go) is coming soon.  LocalStack comes with out-of-the-box support for Thundra. Simply obtain a Thundra API key here and add it to your Lambda function’s environment variables (THUNDRA_APIKEY):\nAWS SAM  AWS CDK  Serverless Framework   Resources:MyFunction:Type:AWS::Serverless::FunctionProperties:// other function propertiesEnvironment:Variables:// other environment variablesTHUNDRA_APIKEY:\u003cYOUR-THUNDRA-API-KEY\u003e const myFunction = new Function(this, \"MyFunction\", { ..., // other function properties  environment: { ..., // other environment variables  THUNDRA_APIKEY: \u003cMY-THUNDRA-API-KEY\u003e } }); functions:MyFunction:// other function propertiesenvironment:// other environment variablesTHUNDRA_APIKEY:\u003cYOUR-THUNDRA-API-KEY\u003e  After invoking your AWS Lambda function, you can inspect the invocations and traces in the Thundra Console. You can find more details in the Thundra documentation.\nFurther Reading For a complete example, you may check our blog post “Test Monitoring for LocalStack Apps with Thundra” and take a look at the example project here.\n","categories":"","description":"Monitor and debug your AWS Lambda functions with LocalStack and [Thundra](https://thundra.io).\n","excerpt":"Monitor and debug your AWS Lambda functions with LocalStack and …","ref":"/integrations/thundra/","tags":["thundra","tracing","observability"],"title":"Thundra"},{"body":"This guide shows how to start and use LocalStack in your Travis CI jobs.\nSetting up the Travis CI job When you want to integrate LocalStack into your job configuration, you just have to execute the following steps:\n Install the LocalStack CLI (and maybe also awslocal). Make sure your LocalStack docker image is up-to-date by pulling the latest version. Use the LocalStack CLI to start LocalStack. Make sure to use the DOCKER_FLAGS='-d' to start the LocalStack docker container in detached mode. Wait for the container to report that it is up and running.  The following example Travis CI job config (.travis.yaml) executes these steps, creates a new S3 bucket, and prints a nice message in the end:\nlanguage:pythonservices:- dockerpython:- \"3.8\"before_install:# Install the LocalStack CLI and awslocal- python -m pip install localstack awscli-local[ver1]# Make sure to pull the latest version of the image- docker pull localstack/localstack# Start localstack- DOCKER_FLAGS='-d' localstack start# Wait for the localstack docker container to become ready- for i in {1..45}; do if [ `docker logs localstack_main | grep 'Ready.'` ]; then break; fi; sleep 1; donescript:# Test LocalStack by creating a new S3 bucket (and verify that it has been created by listing all buckets)- awslocal s3 mb s3://test- awslocal s3 ls- echo \"Execute your tests here :)\"Activate LocalStack Pro You can easily enable LocalStack Pro by adding your API key to the project’s environment variables. The LocalStack CLI will automatically pick it up and activate the Pro features.\nJust go to the project settings in Travis CI (More options → Settings), scroll down to the Environment Variables section, and add your API key:\n","categories":"","description":"Use LocalStack in [Travis CI](https://www.travis-ci.com/)\n","excerpt":"Use LocalStack in [Travis CI](https://www.travis-ci.com/)\n","ref":"/ci/travis-ci/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"Travis CI"},{"body":"Overview The AWS Serverless Application Model (SAM) is a framework on top of CloudFormation to quickly develop Cloud Applications with a focus on serverless services such as S3, Lambda, API Gateway, Step Functions and more.\nAWS SAM CLI for LocalStack To deploy SAM applications on LocalStack you can use samlocal, a wrapper for the AWS SAM CLI.\nInstallation Simply use pip to install samlocal as a Python library on your machine:\n$ pip install aws-sam-cli-local Usage The samlocal command has the exact same usage as the underlying sam command. The main difference is that for commands like samlocal deploy the operations will be executed against the LocalStack endpoints (http://localhost:4566 by default) instead of real AWS endpoints.\n$ samlocal --help Start using samlocal by deploying a Hello World Application. Please make sure to replace all sam calls with samlocal when following the AWS tutorial.\nConfiguration  EDGE_PORT: Port number under which the LocalStack edge service is available (default: 4566) LOCALSTACK_HOSTNAME: Host under which the LocalStack edge service is available (default: localhost)  ","categories":"","description":"Use the AWS SAM (Serverless Application Model) with LocalStack\n","excerpt":"Use the AWS SAM (Serverless Application Model) with LocalStack\n","ref":"/integrations/aws-sam/","tags":["sam","cloudformation","infrastructure-as-code"],"title":"AWS SAM"},{"body":"Overview The AWS Cloud Development Kit (CDK) is an IaC (Infrastructure-as-Code) tool using general-purpose programming languages such as TypeScript/JavaScript, Python, Java, and .NET to programmatically define your cloud architecture on AWS.\nAWS CDK CLI for LocalStack cdklocal is a thin wrapper script for using the AWS CDK library against local APIs provided by LocalStack.\nInstallation The cdklocal command line is published as an npm library:\n# Install globally npm install -g aws-cdk-local aws-cdk # Verify it installed correctly cdklocal --version # e.g. 1.65.5  Local node_modules Using cdklocal locally (e.g. within the node_modules of your repo instead of globally installed) does not work at the moment for some setups, so make sure you install both aws-cdk and aws-cdk-local with the -G flag.  Usage cdklocal can be used as a drop-in replacement of where you would otherwise use cdk when targeting the AWS Cloud.\n$ cdklocal --help Configuration The following environment variables can be configured:\n EDGE_PORT: Port under which LocalStack edge service is accessible (default: 4566) LOCALSTACK_HOSTNAME: Target host under which LocalStack edge service is accessible (default: localhost) LAMBDA_MOUNT_CODE: Whether to use local Lambda code mounting (via setting __local__ S3 bucket name)  Example Make sure that LocalStack is installed and successfully started with the required services before running the example\n$ curl http://localhost:4566/health The CDK command line ships with a sample app generator to run a quick test for getting started.\n# create sample app mkdir /tmp/test; cd /tmp/test cdklocal init sample-app --language=javascript # deploy the sample app  cdklocal deploy \u003e Do you wish to deploy these changes (y/n)? y Once the deployment is done, you can inspect the created resources via the awslocal command line\n$ awslocal sns list-topics { \"Topics\": [ { \"TopicArn\": \"arn:aws:sns:us-east-1:000000000000:TestStack-TestTopic339EC197-79F43WWCCS4Z\" } ] } External resources  aws-cdk-local AWS CDK API reference AWS CDK Developer Guide  Community resources  https://blog.dennisokeeffe.com/blog/2021-08-07-using-the-aws-cdk-with-localstack-and-aws-cdk-local https://www.youtube.com/watch?v=3_sqr0G9zb0  ","categories":"","description":"Use the AWS CDK (Cloud Development Kit) with LocalStack\n","excerpt":"Use the AWS CDK (Cloud Development Kit) with LocalStack\n","ref":"/integrations/aws-cdk/","tags":["cdk","cloudformation","infrastructure-as-code"],"title":"AWS CDK"},{"body":"LocalStack supports a wide range of tools from the cloud development ecosystem. This section of the documentation covers tools that are officially supported by LocalStack.\nThe Cloud Development Ecosystem Cloud development has many facets and a rich ecosystem of tools to cover them. Whether you are using Infrastructure-as-Code (IaC) to manage your AWS infrastructure, or are developing applications using AWS SDKs like boto, LocalStack allows you to run your workflow completely on your local machine.\n  Integrations We strive to make the integration of LocalStack into your workflow as seamless as possible. Sometimes it’s as easy as calling one of our wrapper tools, like awslocal, a drop-in replacement for the aws CLI. Other times there is a bit of configuration involved.\nHere is a list of tools we support, and documentation on how to integrate LocalStack:\n","categories":"","description":"How to use your favorite cloud development tools with LocalStack.\n","excerpt":"How to use your favorite cloud development tools with LocalStack.\n","ref":"/integrations/","tags":"","title":"Integrations"},{"body":"Lambdas are awesome!\n","categories":"","description":"Develop your Lambdas more efficiently.\n","excerpt":"Develop your Lambdas more efficiently.\n","ref":"/tools/lambda-tools/","tags":"","title":"Lambda Tools"},{"body":"In the community (open source) edition, the application code needs to configure each AWS SDK client instance with the target endpoint URL to point to the APIs on localhost or, in the case of Lambdas running in the context of LocalStack, the endpoint URL should point to http://${LOCALSTACK_HOSTNAME}:${EDGE_PORT}.\nThe Pro version provides two options for transparently making your application logic speak to the local APIs instead of real AWS (without having to change your production code):\n integrated DNS server patched AWS SDKs  More details can be found in the subsections below.\n","categories":"","description":"Transparently inject local endpoints into AWS SDKs and redirect your AWS calls to LocalStack\n","excerpt":"Transparently inject local endpoints into AWS SDKs and redirect your …","ref":"/tools/local-endpoint-injection/","tags":"","title":"Local Endpoint Injection"},{"body":"Overview Pulumi’s infrastructure-as-code SDK helps you create, deploy, and manage AWS containers, serverless functions, and infrastructure using familiar programming languages. The endpoints configuration environment of Pulumi allows us to easily point Pulumi to LocalStack. This guide follows the instructions from Pulumi’s Get Started with Pulumi and AWS guide, with additional explanations of how to make it work with LocalStack.\nQuickstart Create a new Pulumi stack First, run the following commands and follow the instructions in the CLI to create a new project.\n$ mkdir quickstart \u0026\u0026 cd quickstart $ pulumi new aws-typescript We use the default configuration values:\nThis command will walk you through creating a new Pulumi project. Enter a value or leave blank to accept the (default), and press \u003cENTER\u003e. Press ^C at any time to quit. project name: (quickstart) project description: (A minimal AWS TypeScript Pulumi program) Created project 'quickstart' Please enter your desired stack name. To create a stack in an organization, use the format \u003corg-name\u003e/\u003cstack-name\u003e (e.g. `acmecorp/dev`). stack name: (dev) Created stack 'dev' aws:region: The AWS region to deploy into: (us-east-1) Saved config Installing dependencies... This will create the following directory structure.\n$ tree -L 1 . ├── index.ts ├── node_modules ├── package.json ├── package-lock.json ├── Pulumi.dev.yaml ├── Pulumi.yaml └── tsconfig.json Now edit your stack configuration Pulumi.dev.yaml as follows:\nconfig:aws:accessKey:testaws:endpoints:- acm:http://localhost:4566amplify:http://localhost:4566apigateway:http://localhost:4566applicationautoscaling:http://localhost:4566appsync:http://localhost:4566athena:http://localhost:4566autoscaling:http://localhost:4566batch:http://localhost:4566cloudformation:http://localhost:4566cloudfront:http://localhost:4566cloudsearch:http://localhost:4566cloudtrail:http://localhost:4566cloudwatch:http://localhost:4566cloudwatchevents:http://localhost:4566cloudwatchlogs:http://localhost:4566codecommit:http://localhost:4566cognitoidentity:http://localhost:4566cognitoidp:http://localhost:4566docdb:http://localhost:4566dynamodb:http://localhost:4566ec2:http://localhost:4566ecr:http://localhost:4566ecs:http://localhost:4566eks:http://localhost:4566elasticache:http://localhost:4566elasticbeanstalk:http://localhost:4566elb:http://localhost:4566emr:http://localhost:4566es:http://localhost:4566firehose:http://localhost:4566glacier:http://localhost:4566glue:http://localhost:4566iam:http://localhost:4566iot:http://localhost:4566kafka:http://localhost:4566kinesis:http://localhost:4566kinesisanalytics:http://localhost:4566kms:http://localhost:4566lambda:http://localhost:4566mediastore:http://localhost:4566neptune:http://localhost:4566organizations:http://localhost:4566qldb:http://localhost:4566rds:http://localhost:4566redshift:http://localhost:4566route53:http://localhost:4566s3:http://localhost:4566sagemaker:http://localhost:4566secretsmanager:http://localhost:4566servicediscovery:http://localhost:4566ses:http://localhost:4566sns:http://localhost:4566sqs:http://localhost:4566ssm:http://localhost:4566stepfunctions:http://localhost:4566sts:http://localhost:4566swf:http://localhost:4566transfer:http://localhost:4566xray:http://localhost:4566aws:s3ForcePathStyle:'true'aws:secretKey:testaws:skipCredentialsValidation:'true'aws:skipRequestingAccountId:'true'Deploy the stack to LocalStack Make sure your LocalStack is running. For the example stack, the only required service is S3. After updating the stack configuration, and starting localstack, you can run:\n$ pulumi up once the stack update was performed, you can run:\n$ awslocal s3 ls Where you should see something like\n2021-09-30 11:50:59 my-bucket-6c21027 Pulumilocal pulumilocal is a wrapper script and drop-in replacement for the pulumi CLI, that also provides commands to better interface Pulumi with LocalStack. You can find the source code repository here: https://github.com/localstack/pulumi-local\nInstall pulumilocal requires that you already have the pulumi command in your path. Then, simply run\n$ pip install pulumi-local then,\npulumi version pulumilocal version should output the same value.\nUse Instead of manually editing a stack configuration as explained earlier, you can run\n$ pulumilocal init which will create a Pulumi.localstack.yaml stack configuration, and initialize an additional stack named localstack.\nYou can now run\n$ pulumilocal up to start the localstack stack.\nConfiguration You can configure the integration between pulumi-local and LocalStack by adding these environment variables before running pulumilocal:\n   Variable Default value Description     PULUMI_CMD pulumi The Pulumi command that is being delegated to   PULUMI_STACK_NAME localstack The Pulumi stack name used for looking up the stack file (Pulumi.\u003cstack\u003e.yaml)   LOCALSTACK_HOSTNAME localhost The name of the host LocalStack is reachable at   EDGE_PORT 4566 The port LocalStack is reachable at   USE_SSL 0 A truthy (1, true) string that indicates whether to use SSL when connecting to LocalStack    Community resources Articles  Pulumi and LocalStack – beyond the basics. 2021-08-26 How to deploy Localstack with Pulumi. 2020-09-22  ","categories":"","description":"Use the Pulumi Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Pulumi Infrastructure as Code framework with LocalStack\n","ref":"/integrations/pulumi/","tags":["pulumi","infrastructure-as-code"],"title":"Pulumi"},{"body":"We regularly run the test suite of the Terraform AWS provider against LocalStack to test the compatibility of LocalStack to Terraform. To that end we have a dedicated repository localstack/localstack-terraform-test, where you can also find instructions on how to run the tests.\n","categories":["Stub"],"description":"How to run the Terraform test suite.\n","excerpt":"How to run the Terraform test suite.\n","ref":"/developer-guide/terraform-tests/","tags":"","title":"Terraform test suite"},{"body":"LocalStack is key component of testing and delivering cloud-native applications in Continuous Integration/Delivery pipelines without complicated AWS testing and staging environments.\nExample workflow The following image shows an example workflow. The CI build is triggered through pushing code to the version control repository. The CI runner starts LocalStack and executes the test suite. The same Infrastructure-as-Code (IaC) configuration that sets up AWS in your production environment can be used to set up LocalStack in the CI environment. LocalStack Cloud Pods can be used to pre-seed state into the services (e.g., DynamoDB entries, or S3 files). The tests then execute the application in the cloud environment emulated by LocalStack. After a successful test run, the more expensive AWS CodeBuild pipeline for deploying your application can be executed. The test reports created by your testing framework can be enriched with traces and analytics generated inside LocalStack.\n  Running LocalStack in CI environments It is easy to run LocalStack in your CI runners. For some CI environments, for example Circle CI, we provide plugins that allow seamless integration of LocalStack in your workflow. But LocalStack can work in any CI environment, and we have several examples in the sections below.\n","categories":"","description":"Using LocalStack in your Continuous Integration workflow\n","excerpt":"Using LocalStack in your Continuous Integration workflow\n","ref":"/ci/","tags":"","title":"LocalStack in CI"},{"body":"","categories":"","description":"","excerpt":"","ref":"/aws/","tags":"","title":"Local AWS Services"},{"body":"The core of LocalStack is the cloud service emulation. But LocalStack also provides a variety of tools to make your life as a cloud developer easier.\nWith LocalStack Cloud Developer Tools you can:\n persist the state of the AWS services running in your LocalStack instance via Cloud Pods hot-swap your Lambda code changes instantly debug Lambda executions directly from your IDE inject LocalStack service endpoints automatically into your application … and much more!  ","categories":"","description":"Increase your development efficiency with LocalStack Cloud Developer Tools.\n","excerpt":"Increase your development efficiency with LocalStack Cloud Developer …","ref":"/tools/","tags":"","title":"LocalStack Tools"},{"body":"Covered Topics  Implementation Limitations Runtime Environment Limitations Integration Limitations  Implementation Limitations Limitations that exist due to missing features in LocalStack\nRuntime Environment Limitations OS-specific and other runtime environment limitations\n ARM64 (Including Apple M1 chip)  ARM64 (Including Apple M1 chip) Aarch64 Support The LocalStack team and community are working hard to bring M1 support to LocalStack images. There are still several limitations with LocalStack dependencies on ARM architectures.  Currently, LocalStack images do not fully support aarch64, including Apple M1 silicon.\nHowever, this does not mean you cannot run LocalStack on M1 machines. Folow the next workaround tip to get LocalStack up and running on your M1.\nNote on JVM Lambda You need to use the local lambda executor for JVM Lambda functions  To be on a safer side, you can enable “Rosetta” on your preferred Terminal. This way you’ll be installing packages for x86_64 platform.\nWhat we will be doing now is installing Java and Python executables using Homebrew, it should automatically resolve packages to proper architecture versions.\n# Install Homebrew /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" # Install java11 and follow instructions brew install java11 # Install jenv and follow instructions brew install jenv # Add Java11 to jenv and use it globally jenv add /Library/Java/JavaVirtualMachines/openjdk-11.jdk/Contents/Home/ jenv global 11 # Install pyenv and follow instructions brew install pyenv # Install python 3.8.10 and enable it globally pyenv install 3.8.10 pyenv global 3.8.10 Then clone LocalStack to your machine, run make install and then make start.\nDynamoDB At the moment only a locally launched LocalStack instance can properly run the DynamoDB service.\nLambda Functions Only the local executor with locally launched LocalStack can be used together with JVM Lambda Functions.\nIntegration Limitations Limitations that may occur because of third party integrations behavior\n CDK  CDK Stacks with validated certificates By default, stacks with validated certificates may not be deployed using the local lambda executor. This originates from the way how CDK ensures the certificate is ready - it creates a single-file lambda function with a single dependency on aws-sdk which is usually preinstalled and available globally in lambda runtime. When this lambda is executed locally from the /tmp folder, the package can not be discovered by Node due to the way how Node package resolution works.\n","categories":"","description":"Known limitations of LocalStack and its services\n","excerpt":"Known limitations of LocalStack and its services\n","ref":"/localstack/limitations/","tags":"","title":"LocalStack Limitations"},{"body":"The documents in this section are dedicated to the internals, the configuration options, and the limitations of LocalStack.\nThe following figure shows an overview of the covered topics:\n  ","categories":"","description":"Learn how LocalStack emulates services and runs your serverless applications.\n","excerpt":"Learn how LocalStack emulates services and runs your serverless …","ref":"/localstack/","tags":"","title":"Understanding LocalStack"},{"body":"We welcome contributions to LocalStack, under the Contributor LicenseAgreement (CLA).\nThe guides in this section are for developers of LocalStack, to better understand how LocalStack works internally, how to set up local development environments, and how to contribute to the codebase.\n","categories":"","description":"A guide to the LocalStack system, its code base on how to contribute to the project.\n","excerpt":"A guide to the LocalStack system, its code base on how to contribute …","ref":"/developer-guide/","tags":"","title":"Developer Guide"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/jvm/","tags":"","title":"jvm"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kotlin/","tags":"","title":"kotlin"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-community/","tags":"","title":"LocalStack Community"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-pro/","tags":"","title":"LocalStack Pro"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/serverless-framework/","tags":"","title":"serverless-framework"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring/","tags":"","title":"spring"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring-cloud/","tags":"","title":"spring-cloud"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring-cloud-function/","tags":"","title":"spring-cloud-function"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"Details coming soon.\n","categories":["LocalStack Pro","Stub"],"description":"Amplify\n","excerpt":"Amplify\n","ref":"/aws/amplify/","tags":"","title":"Amplify"},{"body":"Basic support for API Gateway V2 is included in the Pro version, which allows for creation of local WebSocket APIs for long-lived connections and bi-directional communication between the API and your clients.\nFor example, given the following Serverless configuration:\n...plugins:- serverless-localstackfunctions:actionHandler:handler:handler.handlerevents:- websocket:route:test-actionUpon deployment of the Serverless project, a new API Gateway V2 endpoint will be created in LocalStack. The awslocal CLI can be used to get the list of APIs, which should contain the WebSocket endpoint, e.g., ws://localhost:4510 in the example below:\n$ awslocal apigatewayv2 get-apis { \"Items\": [{ \"ApiEndpoint\": \"ws://localhost:4510\", \"ApiId\": \"129ca37e\", ... }] } Assuming your project contains a simple Lambda handler.js like this:\nmodule.exports.handler = function(event, context, callback) { callback(null, event); }; … then sending a message to the WebSocket at ws://localhost:4510 will result in the same message getting returned as a response on the same WebSocket.\nFor a simple, self-contained example please refer to this Github repository.\n","categories":["LocalStack Pro"],"description":"API Gateway V2\n","excerpt":"API Gateway V2\n","ref":"/aws/apigatewayv2/","tags":"","title":"API Gateway V2"},{"body":"Basic support for AppSync is included in LocalStack Pro. The local AppSync API allows you to spin up local GraphQL APIs and directly expose your data sources (e.g., DynamoDB tables) to external clients.\nFor example, you can create a DynamoDB table \"posts\" with a key attribute id, and define a GraphQL schema in a file schema.graphql like this:\nschema { query: Query } type Query { getPosts: [Post!]! } type Post { id: DDBString! } type DDBString { S: String! } … and then use the AppSync API (or CloudFormation) to create the following entities:\n a GraphQL API a data source of type AMAZON_DYNAMODB that references the \"posts\" DynamoDB table a request mapping template with a content like this:  { \"version\" : \"2017-02-28\", \"operation\" : \"Scan\" } a response mapping template with a content like this:  $util.toJson($context.result[\"Items\"]) Once things have been wired up properly, and assuming the ID of your GraphQL API is \"api123\", you should be able to run the following GraphQL query to retrieve all items from the \"posts\" DynamoDB table: $ curl -d '{\"query\":\"query {getPosts{id{S}}}\"}' http://localhost:4605/graphql/api123\nFor more details, please refer to the self-contained sample published in this Github repository.\n","categories":["LocalStack Pro"],"description":"AppSync\n","excerpt":"AppSync\n","ref":"/aws/appsync/","tags":"","title":"AppSync"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/architect/","tags":"","title":"architect"},{"body":"LocalStack Pro ships with built-in support for Athena, Amazon’s serverless data warehouse and analytics platform. Athena uses Presto under the covers, and your Athena instance will be automatically configured with a Hive metastore that connects seamlessly to the LocalStack S3 API. That is, you can easily connect your local S3 buckets and query data directly from S3 via the powerful Athena query API.\nThe following commands illustrate how to use Athena from the command line (assuming you have awslocal installed):\n$ awslocal athena start-query-execution --query-string 'SELECT 1, 2, 3' { \"QueryExecutionId\": \"c9f453ad\" } $ awslocal athena list-query-executions { \"QueryExecutionIds\": [ \"c9f453ad\" ] } $ awslocal athena get-query-results --query-execution-id c9f453ad { \"ResultSet\": { \"Rows\": [{ \"Data\": [ { \"VarCharValue\": \"1\" }, { \"VarCharValue\": \"2\" }, { \"VarCharValue\": \"3\" } ] }], \"ResultSetMetadata\": { \"ColumnInfo\": [] } }, \"UpdateCount\": 0 } Note: In order to use the Athena API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you’re on a decent internet connection when pulling the dependencies for the first time.  ","categories":["LocalStack Pro"],"description":"Athena\n","excerpt":"Athena\n","ref":"/aws/athena/","tags":"","title":"Athena"},{"body":"The Backup API allows to manage backup plans, to create scheduled or on-demand backups of certain resource types like DynamoDB tables or RDS databases. Details following soon…\n","categories":["LocalStack Pro","Stub"],"description":"Backup\n","excerpt":"Backup\n","ref":"/aws/backup/","tags":"","title":"Backup"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cdk/","tags":"","title":"cdk"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/ci/","tags":"","title":"ci"},{"body":"Overview AWS CloudFormation is AWS’s primary Infrastructure-as-Code (IaC) service. It is used to declaratively define your architecture on the AWS cloud, including resources such as S3 Buckets, Lambda Functions, and much more.\nCloudFormation Stack templates are written in either YAML or JSON and can be written manually or generated by higher-level tools such as AWS CDK, AWS SAM, Pulumi or Serverless Framework.\nQuickstart In this quickstart guide we will deploy a simple CloudFormation stack consisting of a single S3 Bucket.\nPrerequisites Make sure you’ve set up awslocal and that you have a running LocalStack instance.\nDeploy a CloudFormation Stack to LocalStack YAML  JSON   Resources:LocalBucket:Type:AWS::S3::BucketProperties:BucketName:cfn-quickstart-bucket { \"Resources\": { \"LocalBucket\": { \"Type\": \"AWS::S3::Bucket\", \"Properties\": { \"BucketName\": \"cfn-quickstart-bucket\" } } } }  Use this code snippet and save the content in either cfn-quickstart-stack.yaml or cfn-quickstart-stack.json respectively.\n# Deploy the bucket on LocalStack # The template file (ending with .yaml or .json) should contain the stack content from above awslocal cloudformation deploy --stack-name cfn-quickstart-stack --template-file \"./cfn-quickstart-stack.yaml\" # Verify the bucket was created successfully # The output should include a bucket with the name cfn-quickstart-bucket awslocal s3api list-buckets # Delete the stack (this will also delete the bucket) awslocal cloudformation delete-stack --stack-name cfn-quickstart-stack Check out the official AWS CloudFormation User Guide for a general introduction to CloudFormation concepts and a more comprehensive introduction on how to write CloudFormation templates.\nSupport We are constantly improving our feature coverage for CloudFormation, with new resource types getting added on an ongoing basis. Your feature requests help us prioritize which resources we need to prioritize, so please feel free to open a new GitHub issue or add a thumbs up to an existing issue.\nFeatures    Feature Support     Parameters Partial   Dynamic References -   Rules -   Mappings Full   Conditions Full   Transform Partial (Only for AWS::Serverless-2016-10-31)   Outputs Full   Custom resources Partial   Drift detection -   Importing Resources -   Change sets Full   Nested stacks Partial   StackSets Partial    In general UPDATE support for resources is currently limited. Prefer re-creating a stack rather than updating an existing one.\nResources (Community Edition)  AWS::ApiGateway::Account AWS::ApiGateway::ApiKey AWS::ApiGateway::BasePathMapping AWS::ApiGateway::Deployment AWS::ApiGateway::DomainName AWS::ApiGateway::GatewayResponse AWS::ApiGateway::Method AWS::ApiGateway::Model AWS::ApiGateway::RequestValidator AWS::ApiGateway::Resource AWS::ApiGateway::RestApi AWS::ApiGateway::Stage AWS::ApiGateway::UsagePlan AWS::ApiGateway::UsagePlanKey AWS::CertificateManager::Certificate AWS::CloudFormation::Stack AWS::CloudWatch::Alarm AWS::CloudWatch::CompositeAlarm AWS::DynamoDB::Table AWS::EC2::Instance AWS::EC2::InternetGateway AWS::EC2::NatGateway AWS::EC2::Route AWS::EC2::RouteTable AWS::EC2::SecurityGroup AWS::EC2::Subnet AWS::EC2::SubnetRouteTableAssociation AWS::EC2::VPC AWS::EC2::VPCGatewayAttachment AWS::Elasticsearch::Domain AWS::Events::Connection AWS::Events::EventBus AWS::Events::EventBusPolicy AWS::Events::Rule AWS::IAM::Group AWS::IAM::InstanceProfile AWS::IAM::ManagedPolicy AWS::IAM::Policy AWS::IAM::Role AWS::IAM::User AWS::KMS::Alias AWS::KMS::Key AWS::Kinesis::Stream AWS::Kinesis::StreamConsumer AWS::KinesisFirehose::DeliveryStream AWS::Lambda::EventInvokeConfig AWS::Lambda::EventSourceMapping AWS::Lambda::Function AWS::Lambda::Permission AWS::Lambda::Version AWS::Logs::LogGroup AWS::Logs::SubscriptionFilter AWS::Redshift::Cluster AWS::ResourceGroups::Group AWS::Route53::RecordSet AWS::S3::Bucket AWS::S3::BucketPolicy AWS::SNS::Subscription AWS::SNS::Topic AWS::SQS::Queue AWS::SQS::QueuePolicy AWS::SSM::Parameter AWS::SecretsManager::ResourcePolicy AWS::SecretsManager::RotationSchedule AWS::SecretsManager::Secret AWS::SecretsManager::SecretTargetAttachment AWS::StepFunctions::Activity AWS::StepFunctions::StateMachine  Resources (Pro / Enterprise Edition) The resources below are only available with a valid Pro license key. When running the Community Edition, any unsupported resources in the stack are ignored and will not get deployed.\n AWS::Amplify::App AWS::Amplify::Branch AWS::ApiGateway::Authorizer AWS::ApiGatewayV2::Api AWS::ApiGatewayV2::Authorizer AWS::ApiGatewayV2::Deployment AWS::ApiGatewayV2::DomainName AWS::ApiGatewayV2::Integration AWS::ApiGatewayV2::IntegrationResponse AWS::ApiGatewayV2::Route AWS::ApiGatewayV2::RouteResponse AWS::ApiGatewayV2::Stage AWS::ApiGatewayV2::VpcLink AWS::AppSync::ApiKey AWS::AppSync::DataSource AWS::AppSync::FunctionConfiguration AWS::AppSync::GraphQLApi AWS::AppSync::GraphQLSchema AWS::AppSync::Resolver AWS::ApplicationAutoScaling::ScalableTarget AWS::ApplicationAutoScaling::ScalingPolicy AWS::Backup::BackupPlan AWS::CDK::Metadata AWS::CloudFormation::CustomResource AWS::CloudFront::CloudFrontOriginAccessIdentity AWS::CloudFront::Distribution AWS::CloudFront::Function AWS::CloudFront::OriginRequestPolicy AWS::CloudTrail::Trail AWS::Cognito::IdentityPool AWS::Cognito::IdentityPoolRoleAttachment AWS::Cognito::UserPool AWS::Cognito::UserPoolClient AWS::Cognito::UserPoolDomain AWS::Cognito::UserPoolGroup AWS::Cognito::UserPoolIdentityProvider AWS::EC2::EIP AWS::EC2::SecurityGroupEgress AWS::EC2::SecurityGroupIngress AWS::EC2::SubnetRouteTableAssociation AWS::EC2::VPCEndpoint AWS::ECR::Repository AWS::ECS::Cluster AWS::ECS::Service AWS::ECS::TaskDefinition AWS::ElastiCache::CacheCluster AWS::ElastiCache::ParameterGroup AWS::ElastiCache::ReplicationGroup AWS::ElastiCache::SecurityGroup AWS::ElastiCache::SubnetGroup AWS::ElasticLoadBalancingV2::Listener AWS::ElasticLoadBalancingV2::ListenerRule AWS::ElasticLoadBalancingV2::LoadBalancer AWS::ElasticLoadBalancingV2::TargetGroup AWS::Glue::Classifier AWS::Glue::Crawler AWS::Glue::Database AWS::Glue::Job AWS::Glue::Table AWS::Glue::Trigger AWS::Glue::Workflow AWS::IoT::Certificate AWS::IoTAnalytics::Channel AWS::IoTAnalytics::Dataset AWS::IoTAnalytics::Datastore AWS::IoTAnalytics::Pipeline AWS::KinesisAnalytics::Application AWS::KinesisAnalytics::ApplicationOutput AWS::Lambda::Alias AWS::Lambda::LayerVersion AWS::Lambda::LayerVersionPermission AWS::RDS::DBCluster AWS::RDS::DBInstance AWS::RDS::DBParameterGroup AWS::RDS::DBSubnetGroup AWS::Redshift::ClusterParameterGroup AWS::Redshift::ClusterSecurityGroup AWS::Redshift::ClusterSubnetGroup AWS::Route53::HostedZone AWS::SES::Template AWS::ServiceDiscovery::HttpNamespace AWS::ServiceDiscovery::PrivateDnsNamespace AWS::ServiceDiscovery::PublicDnsNamespace AWS::ServiceDiscovery::Service  ","categories":"","description":"Use AWS CloudFormation with LocalStack\n","excerpt":"Use AWS CloudFormation with LocalStack\n","ref":"/aws/cloudformation/","tags":["cloudformation","infrastructure-as-code"],"title":"CloudFormation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cloudformation/","tags":"","title":"cloudformation"},{"body":"LocalStack Pro supports creation of local CloudFront distributions, which allows you to transparently access your applications and file artifacts via CloudFront URLs like https://abc123.cloudfront.net.\nFor example, take the following simple example which creates an S3 bucket, puts a small text file hello.txt to the bucket, and then creates a CloudFront distribution which makes the file accessible via a https://abc123.cloudfront.net/hello.txt proxy URL (where abc123 is a placeholder for the real distribution ID):\n$ awslocal s3 mb s3://bucket1 $ echo 'Hello World' \u003e /tmp/hello.txt $ awslocal s3 cp /tmp/hello.txt s3://bucket1/hello.txt --acl public-read $ domain=$(awslocal cloudfront create-distribution \\ --origin-domain-name bucket1.s3.amazonaws.com | jq -r '.Distribution.DomainName') $ curl -k https://$domain/hello.txt Note: In order for CloudFront to be fully functional, your local DNS setup needs to be properly configured. See the section on configuring the local DNS server for details.  Note: In the code example above, the last command (curl https://$domain/hello.txt) may temporarily fail with a warning message Could not resolve host. This is due to the fact that operating systems use different DNS caching strategies, and it may take some time for the CloudFront distribution’s DNS name (e.g., abc123.cloudfront.net) to become available in the system. Usually after a few retries the command should work, though. Note that a similar behavior can also be observed in the real AWS - CloudFront DNS names can also take up to 10-15 minutes to propagate across the network.  ","categories":["LocalStack Pro"],"description":"CloudFront\n","excerpt":"CloudFront\n","ref":"/aws/cloudfront/","tags":"","title":"CloudFront"},{"body":"LocalStack Pro contains basic support for CodeCommit code repositories. The CodeCommit API can be used to create Git repositories, clone these repos to local folders, push commits with changes, etc.\nA simple example has been added in this Github repository. The sample creates an Git repository via the AWS CodeCommit API locally, commits and pushes a test file to the repository, and then checks out the file in a fresh clone of the repository.\nPlease note that CodeCommit is a fairly large API and currently not all methods are supported yet, but we are actively extending the implementation on an ongoing basis.\n","categories":["LocalStack Pro"],"description":"CodeCommit\n","excerpt":"CodeCommit\n","ref":"/aws/codecommit/","tags":"","title":"CodeCommit"},{"body":"AWS Cognito enables you to manage authentication and access control for AWS-backed apps and resources.\nLocalStack Pro contains basic support for authentication via Cognito. You can create Cognito user pools, sign up and confirm users, set up Lambda triggers, and use the COGNITO_USER_POOLS authorizer integration with API Gateway.\nSMTP settings By default, Cognito does not send actual email messages. To enable this feature, you will require an e-mail address and the corresponding SMTP settings (see below).  Creating a User Pool Just as with AWS, you can create a user pool in LocalStack with the following command: $ awslocal cognito-idp create-user-pool --pool-name test\nThe response should look similar to this:\n\"UserPool\": { \"Id\": \"us-east-1_fd924693e9b04f549f989283123a29c2\", \"Name\": \"test\", \"Policies\": { \"PasswordPolicy\": { \"MinimumLength\": 8, \"RequireUppercase\": true, \"RequireLowercase\": true, \"RequireNumbers\": true, \"RequireSymbols\": true, \"TemporaryPasswordValidityDays\": 7 } }, \"LastModifiedDate\": \"2021-10-06T11:57:21.883Z\", \"CreationDate\": \"2021-10-06T11:57:21.883Z\", \"SchemaAttributes\": [], \"VerificationMessageTemplate\": { \"DefaultEmailOption\": \"CONFIRM_WITH_CODE\" }, \"EmailConfiguration\": { \"EmailSendingAccount\": \"COGNITO_DEFAULT\" }, \"AdminCreateUserConfig\": { \"AllowAdminCreateUserOnly\": false }, \"Arn\": \"arn:aws:cognito-idp:us-east-1:000000000000:userpool/us-east-1_fd924693e9b04f549f989283123a29c2\" } We will need the user pool’s id for further operations, so save it in a pool_id variable: $ pool_id=\u003cyour-pool-id\u003e\nAlternatively, you can also use a JSON processor like jq to directly extract the necessary information when creating a pool in the first place:\n$ pool_id=$(awslocal cognito-idp create-user-pool --pool-name test | jq -rc \".UserPool.Id\") Adding a Client Now we add a client to our newly created pool. Again, we will also need the ID of the created client for the next step. The complete command for client creation with subsequent ID extraction is therefore:\n$ client_id=$(awslocal cognito-idp create-user-pool-client --user-pool-id $pool_id --client-name test-client | jq -rc \".UserPoolClient.ClientId\") Signing up and confirming a user With these steps already taken, we can now sign up a user: $ awslocal cognito-idp sign-up --client-id $client_id --username example_user --password 12345678 --user-attributes Name=email,Value=\u003cyour.email@address.com\u003e\nThe response should look similar to this:\n{ \"UserConfirmed\": false, \"UserSub\": \"5fdbe1d5-7901-4fee-9d1d-518103789c94\" } After the user is created, a confirmation code is generated. The code is printed in the LocalStack container logs (see below), and can optionally also be sent via email if you have SMTP configured.\nINFO:localstack_ext.services.cognito.cognito_idp_api: Confirmation code for Cognito user example_user: 125796 DEBUG:localstack_ext.bootstrap.email_utils: Sending confirmation code via email to \"your.email@address.com\" We can confirm the user with the activation code, using the following command: $ awslocal cognito-idp confirm-sign-up --client-id $client_id --username example_user --confirmation-code \u003creceived-confirmation-code\u003e\nAs the above command doesn’t return an answer, we check the pool to see that the request was successful: $ awslocal cognito-idp list-users --user-pool-id $pool_id { \"Users\": [ { \"Username\": \"example_user\", \"Attributes\": [ { \"Name\": \"email\", \"Value\": \"your.email@address.com\" }, { \"Name\": \"sub\", \"Value\": \"5fdbe1d5-7901-4fee-9d1d-518103789c94\" }, { \"Name\": \"cognito:username\", \"Value\": \"example_user\" } ], \"Enabled\": true, \"UserStatus\": \"CONFIRMED\"  } ] }\nCognito Lambda Triggers Cognito provides a number of lifecycle hooks in the form of Cognito Lambda triggers. These triggers can be used to react to various lifecycle events and customize the behavior of user signup, confirmation, migration, etc.\nFor example, to define a user migration Lambda trigger, we can first create a Lambda function (say, named \"f1\") capable of performing the migration, and then define the corresponding --lambda-config on the user pool creation:\nawslocal cognito-idp create-user-pool --pool-name test2 --lambda-config '{\"UserMigration\":\"arn:aws:lambda:us-east-1:000000000000:function:f1\"}' Upon authentication of a non-registered user, Cognito will then automatically call the migration Lambda function and finally add the migrated user to the pool.\nMore details on Cognito Lambda triggers can be found in the AWS documentation.\nOAuth Flows via Cognito Login Form You can also access the local Cognito login form by entering the following URL in your browser:\nhttp://localhost:4566/login?response_type=code\u0026client_id=\u003cclient_id\u003e\u0026redirect_uri=\u003credirect_uri\u003e Please replace \u003cclient_id\u003e with the ID of an existing user pool client ID (in this case, example_user), and \u003credirect_uri\u003e with the redirect URI of your application (e.g., http://example.com).\nThe login form should look similar to the screenshot below:   After successful login, the page will redirect to the specified redirect URI, with a path parameter ?code=\u003ccode\u003e appended, e.g., http://example.com?code=test123. This authentication code can then be used to obtain a token via the Cognito OAuth2 TOKEN Endpoint documented here.\nSMTP Integration In order to enable sending activation emails, configure the following SMTP settings as environment variables:\nSMTP_HOST=\u003csmtp-host-address\u003e SMTP_USER=\u003cemail-user-name\u003e SMTP_PASS=\u003cemail-password\u003e SMTP_EMAIL=\u003cemail-address\u003e Please check with your email provider for details regarding the SMTP settings above.\nServerless and Cognito You can also use Cognito and Localstack in conjunction with the Serverless framework.\nFor example, take this snippet of a serverless.yml configuration:\nservice:testplugins:- serverless-deployment-bucket- serverless-pseudo-parameters- serverless-localstackcustom:localstack:stages:[local]functions:http_request:handler:http.requestevents:- http:path:v1/requestauthorizer:arn:arn:aws:cognito-idp:us-east-1:#{AWS::AccountId}:userpool/ExampleUserPoolresources:Resources:UserPool:Type:AWS::Cognito::UserPoolProperties:...The serverless configuration can then be deployed using serverless deploy --stage local. The example contains a Lambda function http_request which is connected to an API Gateway endpoint. Once deployed, the v1/request API Gateway endpoint will be secured against the Cognito user pool “ExampleUserPool”. You can then register users against that local pool, using the same API calls as for AWS.\nIn order to make requests against the secured API Gateway endpoint, use the local Cognito API to retrieve identity credentials which can be sent along as Authentication HTTP headers (where test-1234567 is the name of the access key ID generated by Cognito):\nAuthentication: AWS4-HMAC-SHA256 Credential=test-1234567/20190821/us-east-1/cognito-idp/aws4_request ... Further reading For a more detailed example, please check out our sample repository.\n","categories":["LocalStack Pro"],"description":"Cognito\n","excerpt":"Cognito\n","ref":"/aws/cognito/","tags":"","title":"Cognito"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/continuous-delivery/","tags":"","title":"continuous-delivery"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/continuous-integration/","tags":"","title":"continuous-integration"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/dns/","tags":"","title":"DNS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/","tags":"","title":"Documentation"},{"body":"A basic version of Elastic Container Registry (ECR) is available to store application images. ECR is often used in combination with other APIs that deploy containerized apps, like ECS or EKS.\n$ awslocal ecr create-repository --repository-name repo1 { \"repository\": { \"repositoryArn\": \"arn:aws:ecr:us-east-1:000000000000:repository/repo1\", \"registryId\": \"abc898c8\", \"repositoryName\": \"repo1\", \"repositoryUri\": \"localhost:4510/repo1\" } } You can then build and tag a new Docker image, and push it to the repository URL (localhost:4510/repo1 in the example above): $ cat Dockerfile FROM nginx ENV foo=bar\n$ docker build -t localhost:4510/repo1 . ... Successfully built e2cfb3cf012d Successfully tagged localhost:4510/repo1:latest $ docker push localhost:4510/repo1 The push refers to repository [localhost:4510/repo1] 318be7aea8fc: Pushed fe08d5d042ab: Pushed f2cb0ecef392: Pushed latest: digest: sha256:4dd893a43df24c8f779a5ab343b7ef172fb147c69ed5e1278d95b97fe0f584a5 size: 948 ... ","categories":["LocalStack Pro"],"description":"Elastic Container Registry (ECR)\n","excerpt":"Elastic Container Registry (ECR)\n","ref":"/aws/elastic-container-registry/","tags":"","title":"Elastic Container Registry (ECR)"},{"body":"Basic support for creating and deploying containerized apps using ECS is provided in the Pro version. LocalStack offers the basic APIs locally, including creation of ECS task definitions, services, and tasks.\nBy default, the ECS Fargate launch type is assumed, i.e., the local Docker engine is used for deployment of applications, and there is no need to create and manage EC2 virtual machines to run the containers.\nNote that more complex features like integration of application load balancers (ALBs) are currently not available, but are being developed and will be available in the near future.\nTask instances are started in a local Docker engine which needs to be accessible to the LocalStack container. The name pattern for task containers is localstack_\u003cfamily\u003e_\u003crevision\u003e, where \u003cfamily\u003e refers to the task family and \u003crevision\u003e refers to a task revision (for example, localstack_nginx_1).\n","categories":["LocalStack Pro"],"description":"Elastic Container Service (ECS)\n","excerpt":"Elastic Container Service (ECS)\n","ref":"/aws/elastic-container-service/","tags":"","title":"Elastic Container Service (ECS)"},{"body":"LocalStack Pro allows you to use the EKS API to create Kubernetes clusters and easily deploy containerized apps locally.\nThere are two modes for creating EKS clusters on LocalStack:\n spinning up an embedded kube cluster in your local Docker engine (preferred, simpler), or using an existing Kubernetes installation you can access from your local machine (defined in $HOME/.kube/config)  Auto-installing an embedded Kubernetes cluster The default method for creating Kubernetes clusters via the local EKS API is to spin up an embedded k3d kube cluster within Docker. LocalStack handles the download and installation transparently - on most systems the installation is performed automatically, and no customizations should be required.\nA new cluster can be created using the following command: $ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config '{}'\nYou should then see some Docker containers getting started, e.g.: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b335f7f089e4 rancher/k3d-proxy:5.0.1-rc.1 \"/bin/sh -c nginx-pr…\" 1 minute ago Up 1 minute 0.0.0.0:8081-\u003e80/tcp, 0.0.0.0:44959-\u003e6443/tcp k3d-cluster1-serverlb f05770ec8523 rancher/k3s:v1.21.5-k3s2 \"/bin/k3s server --t…\" 1 minute ago Up 1 minute\nOnce the cluster has been created and initialized, we can determine the server endpoint: % awslocal eks describe-cluster --name cluster1 { \"cluster\": { \"name\": \"cluster1\", \"status\": \"ACTIVE\", \"endpoint\": \"https://localhost.localstack.cloud:4513\", ... } }\nWe can then configure the kubectl command line with the new cluster endpoint: $ kubectl config set-cluster cluster1 --server=https://localhost.localstack.cloud:4513\nTroubleshooting In case you’re seeing an SSL certificate error when creating an EKS cluster using Terraform:\nError: Kubernetes cluster unreachable: Get \"https://localhost.localstack.cloud:4510/version?timeout=32s\": x509: certificate signed by unknown authority … you may need to download the following key file which contains a test SSL certificate: $ wget https://github.com/localstack/localstack-artifacts/raw/master/local-certs/server.key … and then add the following config to your Terraform provider section:\nprovider \"kubernetes\" { cluster_ca_certificate = \"${file(\"server.key\")}\" } Using an existing Kubernetes installation You can also use the EKS API using an existing local Kubernetes installation. This works by mounting the $HOME/.kube/config file into the LocalStack container - e.g., when using docker-compose.yml:\nvolumes:- \"${HOME}/.kube/config:/root/.kube/config\"In recent versions of Docker, you can simply enable Kubernetes as an embedded service running inside Docker. See below for a screenshot of the Docker settings for Kubernetes in MacOS (similar configurations apply for Linux/Windows). By default, it is asssumed that Kubernetes API runs on the local TCP port 6443.\nThe example below illustrates how to create an EKS cluster configuration (assuming you have awslocal installed): $ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config '{}' { \"cluster\": { \"name\": \"cluster1\", \"arn\": \"arn:aws:eks:eu-central-1:000000000000:cluster/cluster1\", \"createdAt\": \"Sat, 05 Oct 2019 12:29:26 GMT\", \"endpoint\": \"https://172.17.0.1:6443\", \"status\": \"ACTIVE\", ... } } $ awslocal eks list-clusters { \"clusters\": [ \"cluster1\" ] }\nSimply configure your Kubernetes client (e.g., kubectl or other SDK) to point to the endpoint specified in the create-cluster output above. Depending on whether you’re calling the Kubernetes API from the local machine or from within a Lambda, you may have to use different endpoint URLs (https://localhost:6443 vs https://172.17.0.1:6443).\n","categories":["LocalStack Pro"],"description":"Elastic Kubernetes Service (EKS)\n","excerpt":"Elastic Kubernetes Service (EKS)\n","ref":"/aws/elastic-kubernetes-service/","tags":"","title":"Elastic Kubernetes Service (EKS)"},{"body":"LocalStack Pro allows running data analytics workloads locally via the EMR API. EMR utilizes various tools in the Hadoop and Spark ecosystem, and your EMR instance is automatically configured to connect seamlessly to the LocalStack S3 API.\nTo create a virtual EMR cluster locally from the command line (assuming you have awslocal installed): $ awslocal emr create-cluster --release-label emr-5.9.0 --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=1,InstanceType=m4.large { \"ClusterId\": \"j-A2KF3EKLAOWRI\" }\nThe commmand above will spin up one more more Docker containers on your local machine that can be used to run analytics workloads using Spark, Hadoop, Pig, and other tools.\nNote that you can also specify startup commands using the --steps=... command line argument to the create-cluster command. A simple demo project with more details can be found in this Github repository.\nNote: In order to use the EMR API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you’re on a decent internet connection when pulling the dependencies for the first time.  ","categories":["LocalStack Pro"],"description":"Elastic MapReduce (EMR)\n","excerpt":"Elastic MapReduce (EMR)\n","ref":"/aws/elastic-mapreduce/","tags":"","title":"Elastic MapReduce (EMR)"},{"body":"A basic version of ElastiCache is provided. By default, the API is started on http://localhost:4598 and supports running a local Redis instance (Memcached support coming soon).\nAfter starting LocalStack Pro, you can test the following commands: $ awslocal elasticache create-cache-cluster --cache-cluster-id i1 { \"CacheCluster\": { \"CacheClusterId\": \"i1\", \"ConfigurationEndpoint\": { \"Address\": \"localhost\", \"Port\": 4530 } } }\nThen use the returned port number (4530) to connect to the Redis instance: $ redis-cli -p 4530 ping PONG $ redis-cli -p 4530 set foo bar OK $ redis-cli -p 4530 get foo \"bar\"\n","categories":["LocalStack Pro"],"description":"ElastiCache\n","excerpt":"ElastiCache\n","ref":"/aws/elasticache/","tags":"","title":"ElastiCache"},{"body":"The Elasticsearch Service in LocalStack lets you create a single node Elasticsearch cluster that behaves like the Amazon Elasticsearch Service.\nCreating an Elasticsearch cluster You can go ahead and use awslocal to create a new elasticsearch domain via the aws es create-elasticsearch-domain command.\nNote: The first time you create a cluster, the Elasticsearch binary is downloaded, which may take a while to download.  Note: The default Elasticsearch version used is 7.7.  $ awslocal es create-elasticsearch-domain --domain-name foobar { \"DomainStatus\": { \"DomainId\": \"000000000000/foobar\", \"DomainName\": \"foobar\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/foobar\", \"Created\": false, \"Deleted\": false, \"Endpoint\": \"http://localhost:4571\", \"Processing\": false, \"ElasticsearchVersion\": \"7.7\", \"ElasticsearchClusterConfig\": { \"InstanceType\": \"m3.medium.elasticsearch\", \"InstanceCount\": 1, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": false, \"DedicatedMasterType\": \"m3.medium.elasticsearch\", \"DedicatedMasterCount\": 1 }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"CognitoOptions\": { \"Enabled\": false } } } In the LocalStack log you will see something like\n2021-10-01T21:12:47:INFO:localstack.services.es.es_api: starting \u003cclass 'localstack.services.es.cluster.ProxiedElasticsearchCluster'\u003e on localhost:4571 2021-10-01T21:12:47:INFO:localstack.services.install: Downloading and installing local Elasticsearch (7.7.0) server. This may take some time. [2021-10-01 21:12:47 +0200] [16518] [INFO] Running on http://0.0.0.0:4571 (CTRL + C to quit) 2021-10-01T21:12:47:INFO:hypercorn.error: Running on http://0.0.0.0:4571 (CTRL + C to quit) 2021-10-01T21:13:32:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-icu 2021-10-01T21:13:41:INFO:localstack.services.install: Installing Elasticsearch plugin ingest-attachment 2021-10-01T21:13:54:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-kuromoji 2021-10-01T21:14:01:INFO:localstack.services.install: Installing Elasticsearch plugin mapper-murmur3 2021-10-01T21:14:07:INFO:localstack.services.install: Installing Elasticsearch plugin mapper-size 2021-10-01T21:14:14:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-phonetic 2021-10-01T21:14:21:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-smartcn 2021-10-01T21:14:27:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-stempel 2021-10-01T21:14:45:INFO:localstack.services.install: Installing Elasticsearch plugin analysis-ukrainian 2021-10-01T21:15:01:INFO:localstack.services.es.cluster: starting elasticsearch: /opt/code/localstack/localstack/infra/elasticsearch/bin/elasticsearch -E http.port=59237 -E http.publish_port=59237 -E transport.port=0 -E network.host=127.0.0.1 -E http.compression=false -E path.data=\"/opt/code/localstack/localstack/infra/elasticsearch/data\" -E path.repo=\"/tmp/localstack/es_backup\" -E xpack.ml.enabled=false with env {'ES_JAVA_OPTS': '-Xms200m -Xmx600m', 'ES_TMPDIR': '/opt/code/localstack/localstack/infra/elasticsearch/tmp'} and after some time, you should see that the Created state of the domain is set to true:\n$ awslocal es describe-elasticsearch-domain --domain-name foobar | jq \".DomainStatus.Created\" true Interact with the cluster You can now interact with the cluster at the cluster API endpoint http://localhost:4571.\nNote: Only one Elasticsearch cluster instance is created locally. Additional domains share the same Elasticsearch cluster.  For example:\n$ curl http://localhost:4571 { \"name\" : \"om\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"z8n5oqE1SAmmhg3bR9jd2A\", \"version\" : { \"number\" : \"7.7.0\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"81a1e9eda8e6183f5237786246f6dced26a10eaf\", \"build_date\" : \"2020-05-12T02:01:37.602180Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.5.1\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } Or the health endpoint:\n$ curl -s http://localhost:4571/_cluster/health | jq . { \"cluster_name\": \"elasticsearch\", \"status\": \"green\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"active_primary_shards\": 0, \"active_shards\": 0, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 0, \"delayed_unassigned_shards\": 0, \"number_of_pending_tasks\": 0, \"number_of_in_flight_fetch\": 0, \"task_max_waiting_in_queue_millis\": 0, \"active_shards_percent_as_number\": 100 } ","categories":["LocalStack Community"],"description":"Amazon Elasticsearch Service\n","excerpt":"Amazon Elasticsearch Service\n","ref":"/aws/elasticsearch/","tags":"","title":"Elasticsearch Service"},{"body":"The Glue API in LocalStack Pro allows you to run ETL (Extract-Transform-Load) jobs locally, maintaining table metadata in the local Glue data catalog, and using the Spark ecosystem (PySpark/Scala) to run data processing workflows.\nNote: In order to run Glue jobs, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Spark, Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you’re on a decent internet connection when pulling the dependencies for the first time.  Creating Databases and Table Metadata The commands below illustrate the creation of some very basic entries (databases, tables) in the Glue data catalog: $ awslocal glue create-database --database-input '{\"Name\":\"db1\"}' $ awslocal glue create-table --database db1 --table-input '{\"Name\":\"table1\"}' $ awslocal glue get-tables --database db1 { \"TableList\": [ { \"Name\": \"table1\", \"DatabaseName\": \"db1\" } ] }\nRunning Scripts with Scala and PySpark Assuming we would like to deploy a simple PySpark script job.py in the local folder, we can first copy the script to an S3 bucket: $ awslocal s3 mb s3://glue-test $ awslocal s3 cp job.py s3://glue-test/job.py\nNext, we can create a job definition: $ awslocal glue create-job --name job1 --role r1 \\ --command '{\"Name\": \"pythonshell\", \"ScriptLocation\": \"s3://glue-test/job.py\"}' … and finally start the job: $ awslocal glue start-job-run --job-name job1 { \"JobRunId\": \"733b76d0\" } The returned JobRunId can be used to query the status job the job execution, until it becomes SUCCEEDED: $ awslocal glue get-job-run --job-name job1 --run-id 733b76d0 { \"JobRun\": { \"Id\": \"733b76d0\", \"Attempt\": 1, \"JobRunState\": \"SUCCEEDED\" } }\nFor a more detailed example illustrating how to run a local Glue PySpark job, please refer to this sample repository.\nImporting Athena Tables into Glue Data Catalog The Glue data catalog is integrated with Athena, and the database/table definitions can be imported via the import-catalog-to-glue API.\nAssume you are running the following Athena queries to create databases and table definitions:\nCREATEDATABASEdb2CREATEEXTERNALTABLEdb2.table1(a1Date,a2STRING,a3INT)LOCATION's3://test/table1'CREATEEXTERNALTABLEdb2.table2(a1Date,a2STRING,a3INT)LOCATION's3://test/table2'Then this command will import these DB/table definitions into the Glue data catalog: $ awslocal glue import-catalog-to-glue\n… and finally they will be available in Glue: $ awslocal glue get-databases { \"DatabaseList\": [ ... { \"Name\": \"db2\", \"Description\": \"Database db2 imported from Athena\", \"TargetDatabase\": { \"CatalogId\": \"000000000000\", \"DatabaseName\": \"db2\" } } ] } $ awslocal glue get-tables --database-name db2 { \"TableList\": [ { \"Name\": \"table1\", \"DatabaseName\": \"db2\", \"Description\": \"Table db2.table1 imported from Athena\", \"CreateTime\": ... }, { \"Name\": \"table2\", \"DatabaseName\": \"db2\", \"Description\": \"Table db2.table2 imported from Athena\", \"CreateTime\": ... } ] }\nFurther Reading The AWS Glue API is a fairly comprehensive service - more details can be found in the official AWS Glue Developer Guide.\nCurrent Limitations Support for crawlers and triggers is currently limited - the basic API endpoints are implemented, but starting a crawler process is currently still under development (more details coming soon).\n","categories":["LocalStack Pro"],"description":"Glue\n","excerpt":"Glue\n","ref":"/aws/glue/","tags":"","title":"Glue"},{"body":"Overview The AWS SDK for Go, like other AWS SDKs, lets you set the endpoint when creating resource clients, which is the preferred way of integrating the Go SDK with LocalStack.\nThe Go SDK has two major versions, each with their own way of specifying the LocalStack endpoint:\n aws-sdk-go aws-sdk-go-v2  Examples Here is an example of how to create an S3 Client from a Session with the endpoint set to LocalStack. Full examples for both SDK versions can be found in our samples repository.\naws-go-sdk  aws-go-sdk-v2   package main import ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\" \"github.com/aws/aws-sdk-go/aws/credentials\" ) func main() { // Initialize a session  sess, _ := session.NewSession(\u0026aws.Config{ Region: aws.String(\"us-east-1\"), Credentials: credentials.NewStaticCredentials(\"test\", \"test\", \"\"), S3ForcePathStyle: aws.Bool(true), Endpoint: aws.String(\"http://localhost:4566\"), }) // Create S3 service client  client := s3.New(sess) // ... } package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/s3\" ) func main() { awsEndpoint = \"http://localhost:4566\" awsRegion = \"us-east-1\" customResolver := aws.EndpointResolverFunc(func(service, region string) (aws.Endpoint, error) { if awsEndpoint != \"\" { return aws.Endpoint{ PartitionID: \"aws\", URL: awsEndpoint, SigningRegion: awsRegion, }, nil } // returning EndpointNotFoundError will allow the service to fallback to its default resolution  return aws.Endpoint{}, \u0026aws.EndpointNotFoundError{} }) awsCfg, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(awsRegion), config.WithEndpointResolver(customResolver), ) if err != nil { log.Fatalf(\"Cannot load the AWS configs: %s\", err) } // Create the resource client  client = s3.NewFromConfig(awsCfg, func(o *s3.Options) { o.UsePathStyle = true }) // ... }  Resources  localstack-aws-sdk-examples for Go AWS SDK for Go Official repository of the AWS SDK for Go (v1) Official repository of the AWS SDK for Go (v2)  ","categories":"","description":"How to use the Go AWS SDK with LocalStack.\n","excerpt":"How to use the Go AWS SDK with LocalStack.\n","ref":"/integrations/sdks/go/","tags":["sdk"],"title":"Go"},{"body":"By default, LocalStack uses not enforce security policies for client requests. The IAM security enforcement feature can be used to test your security policies and create a more realistic environment that more closely resembles real AWS.\nNote: The environment configuration ENFORCE_IAM=1 is required to enable this feature. (By default, IAM enforcement is disabled, and all APIs can be accessed without authentication.)  Below is a simple example that illustrates the use of IAM policy enforcement. It first attempts to create an S3 bucket with the default user (which fails), then create a user and attempts to create a bucket with that user (which fails again), and then finally attaches a policy to the user to allow s3:CreateBucket, which allows the bucket to be created. $ awslocal s3 mb s3://test make_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied $ awslocal iam create-user --user-name test ... $ awslocal iam create-access-key --user-name test ... \"AccessKeyId\": \"AKIA4HPFP0TZHP3Z5VI6\", \"SecretAccessKey\": \"mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua\", ... $ export AWS_ACCESS_KEY_ID=AKIA4HPFP0TZHP3Z5VI6 AWS_SECRET_ACCESS_KEY=mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua $ awslocal s3 mb s3://test make_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied $ awslocal iam create-policy --policy-name p1 --policy-document '{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"s3:CreateBucket\",\"Resource\":\"*\"}]}' ... $ awslocal iam attach-user-policy --user-name test --policy-arn arn:aws:iam::000000000000:policy/p1 $ awslocal s3 mb s3://test make_bucket: test\nSupported APIs IAM security enforcement is available for the majority of LocalStack APIs - it has been tested, among others, for the following services: ACM, API Gateway, CloudFormation, CloudWatch (metrics/events/logs), DynamoDB, DynamoDB Streams, Elasticsearch Service, EventBus, Kinesis, KMS, Lambda, Redshift, S3 (partial support), SecretsManager, SNS, SQS.\n","categories":["LocalStack Pro"],"description":"Identity and Access Management (IAM)\n","excerpt":"Identity and Access Management (IAM)\n","ref":"/aws/iam/","tags":"","title":"Identity and Access Management (IAM)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/infrastructure-as-code/","tags":"","title":"infrastructure-as-code"},{"body":"Basic support for IoT (including IoT Analytics, IoT Data, and related APIs) is provided in the Pro version. The main endpoints for creating and updating entities are currently implemented, as well as the CloudFormation integrations for creating them.\nThe IoT API ships with a built-in MQTT message broker. In order to get the MQTT endpoint, the describe-endpoint API can be used; for example, using awslocal: $ awslocal iot describe-endpoint { \"endpointAddress\": \"localhost:4520\" }\nThis endpoint can then be used with any MQTT client to send/receive messages (e.g., using the endpoint URL mqtt://localhost:4520).\nLocalStack Pro also supports advanced features like SQL queries for IoT topic rules. For example, you can use the CreateTopicRule API to define a topic rule with a SQL query SELECT * FROM 'my/topic' where attr=123 which will trigger a Lambda function whenever a message with attribute attr=123 is received on the MQTT topic my/topic.\n","categories":["LocalStack Pro"],"description":"AWS IoT\n","excerpt":"AWS IoT\n","ref":"/aws/iot/","tags":"","title":"IoT"},{"body":"AWS Kinesis is a fully managed data streaming service, which enables your application to ingest, buffer, and process data in real-time. Kinesis is shipped with the LocalStack Community version and is extensively supported.\nQuickstart Trying to run the example applications from the official AWS developer guide against LocalStack is a great place to start. Assuming you have awslocal installed you can also try out the following commands:\n$ awslocal kinesis create-stream --stream-name samplestream --shard-count 1 $ awslocal kinesis list-streams { \"StreamNames\": [ \"samplestream\" ] } $ awslocal kinesis put-record --stream-name samplestream --data '{\"symbol\":\"TEST\",\"sampleno\":42}' --partition-key test1 { \"ShardId\": \"shardId-000000000001\", \"SequenceNumber\": \"49622467803485029265018102167378141645049970239670845458\", \"EncryptionType\": \"NONE\" } Kinesis backend providers LocalStack supports two third-party providers for Kinesis:\n kinesis-mock kinesalite  By default kinesis-mock is used. Your desired provider can be set with the environment variable KINESIS_PROVIDER. For instance, if you wish to use kinesalite you’d pass the environment variable as KINESIS_PROVIDER=kinesalite. While both providers are supported, we recommend working with kinesis-mock, as it is more actively maintained. Moreover, the Cloud Pods feature provides support only for kinesis-mock.\nConfiguration Regardless of which provider you’re working with, Kinesis can be further configured with the following environment variables:\n   Variable Description     KINESIS_ERROR_PROBABILITY Decimal value between 0.0 (default) and 1.0. Typically, it is difficult to know beforehand whether your application can handle the throughput and whether it can deal with backpressure. By setting this environment variable the application will randomly inject ProvisionedThroughputException. While this won’t tell you whether your application can handle sufficient throughput, it does help you to test whether your application can handle exceptions gracefully.   KINESIS_SHARD_LIMIT Integer value (default: 100) or Infinity (to disable). This variable can help you to test whether your application adheres to the allocated shard limit. This behavior can only be disabled by explicitly setting the environment variable as KINESIS_SHARD_LIMIT=Infinity   KINESIS_LATENCY Integer value of milliseconds (default: 500) or 0 (to disable). Especially important for testing latency-critical applications. Since latency cannot be tested with the local Kinesis service, you can use this variable to introduce artificial latency into your AWS calls. This behavior can only be disabled by explicitly setting the environment variable as KINESIS_LATENCY=0.   KINESIS_INITIALIZE_STREAMS A comma-delimited string of stream names, its corresponding shard count and an optional region to initialize during startup. If the region is not provided, the default region is used. For instance, KINESIS_INITIALIZE_STREAMS=my-first-stream:1,my-other-stream:2:us-west-2,my-last-stream:1 Important: Only supported by kinesis-mock    ","categories":["LocalStack Community"],"description":"Explaining the different Kinesis providers and how to configure the service.\n","excerpt":"Explaining the different Kinesis providers and how to configure the …","ref":"/aws/kinesis/","tags":"","title":"Kinesis"},{"body":"The Kinesis Data Analytics API allows you to run continuous SQL queries directly over your Kinesis data streams. Basic support is included in LocalStack Pro - it allows you to create Kinesis Analytics applications, define input and output streams and schema types, and run continuous queries locally.\nA simple example has been added to this sample repository on Github. More details are following soon.\n","categories":["LocalStack Pro","Stub"],"description":"Kinesis Data Analytics\n","excerpt":"Kinesis Data Analytics\n","ref":"/aws/kinesis-analytics/","tags":"","title":"Kinesis Data Analytics"},{"body":"Lambda layers are an AWS feature that allows to pull in additional code and content into your Lambda functions.\nSimply point your Lambda client code at your LocalStack instance, e.g., running on http://localhost. For more details on how to use Lambda layers, please follow the documentation and examples on the AWS website.\nMore details and samples following soon.\n","categories":["LocalStack Pro","Stub"],"description":"Lambda Layers\n","excerpt":"Lambda Layers\n","ref":"/aws/lambda-layers/","tags":"","title":"Lambda Layers"},{"body":"","categories":"","description":"How to use your favorite cloud development SDK with LocalStack.\n","excerpt":"How to use your favorite cloud development SDK with LocalStack.\n","ref":"/integrations/sdks/","tags":"","title":"Language SDKs"},{"body":"This guide shows how to use your shiny new LocalStack Pro license, and go over some best-practices regarding usage, activation, and safety of your LocalStack Pro API key.\nRequirements First, you need an API key for LocalStack Pro. You can get your key by signing up on our website.\nDon’t worry, you can sign-up without any payment details and try LocalStack Pro within your free trial for 14 days.\nGetting your API key You can find your API key in the LocalStack Web Interface in the Account → Subscriptions section.\nAPI Key Security   Do not share your API key with anyone. Especially make sure that you do not commit it to any source code management systems (like Git repositories). If you push an API key to a repository, it has potentially ben exposed to the public and it might remain in the history (even if you try to rewrite the history).\n  If you accidentally publish your API key, please contact us to get your API key rotated!\n  If you want to use your API key in your CI environment, please check out our CI documentation to see the proper way to handle secrets in your CI environment.\n   Using your API key LocalStack Pro expects your API key to be present in the environment variable LOCALSTACK_API_KEY. Before starting LocalStack, please define the environment variable in your terminal like this:\n$ export LOCALSTACK_API_KEY=\u003cyour-api-key\u003e Starting LocalStack Pro using the CLI When starting LocalStack using the LocalStack CLI, you dot not have to perform any further steps (after exporting the environment variable). $ localstack start\nLocalStack will detect the API key and properly pass it to the LocalStack container.\nStarting LocalStack Pro using Docker When starting LocalStack using a docker run command, you have to specify the API key using the -e flag for environment variables like this:\n$ docker run \\ --rm -it \\ -p 4566:4566 \\ -p 4571:4571 \\ -e LOCALSTACK_API_KEY=${LOCALSTACK_API_KEY:- } \\  localstack/localstack For more information about starting LocalStack, take a look at our general Getting Started guide.\nStarting LocalStack Pro using Docker-Compose When starting LocalStack using docker-compose, you have to make sure your API key is passed properly to the LocalStack container. For this, you have to make sure to include the LOCALSTACK_API_KEY environment variable in your docker-compose.yml like this:\nenvironment:- LOCALSTACK_API_KEY=${LOCALSTACK_API_KEY- }This statement sets the API key we defined before (by using the export command) into your LocalStack container, such that the key activation can take place.\nLicensing-related configuration If you want to make sure that LocalStack is only started if LocalStack Pro can be activated, or if you want to supporess licensing-related error messages, take a look at our configuration guide regarding LocalStack Pro.\nChecking license activation The easiest way to check if LocalStack Pro is activated is to check the health endpoing of LocalStack for a list of the running services:\n$ curl localhost:4566/health | jq If a Pro-only service – like XRay – is running, LocalStack Pro has started successfully.\nNote: This only works if your SERVICES config variable contains LocalStack Pro services. If in doubt, try starting LocalStack without this variable set, so all services can start.\nOtherwise, please check our collected most common activation issues.\nCommon activation issues Invalid API key If your API key is invalid, you will see an error message like this in the logs of LocalStack:\nActivation key \"abc...\"(10) is invalid or expired! Reason: ... If this error occurs, something is wrong with your API key or license. Please make sure your API key is set correctly (check for typos!) and your license is valid. If the API key still does not work, please contact us.\nNo connection to the LocalStack API If your log output contains lines like:\nWARNING:localstack_ext.bootstrap.licensing: Error activating API key \"abc...\"(10): ... ConnectionRefusedError: [Errno 111] Connection refused LocalStack cannot contact our API to perform the license activation. Please confirm with your network administrator that no policies block the connection to our backend.\nCannot resolve api.localstack.cloud Log output like the following indicates that your machine cannot resolve the domain of the LocalStack API.\nWARNING:localstack_ext.bootstrap.licensing: Error activating API key \"abc...\"(10): ... socket.gaierror: [Errno -3] Temporary failure in name resolution Please confirm this by using a tool like dig:\n$ dig api.localstack.cloud If the result has some other status than status: NOERROR, your machine cannot resolve this domain.\nSome corporate DNS servers might filter requests to certain domains. Please contact your network administrator in order to whitelist localstack.cloud domains.\nYour issue isn’t listed here? If you have any problems concerning your API key activation not mentioned here, or if these steps do not help, please do not hesitate to contact us.\n","categories":["LocalStack Pro"],"description":"Use your API key to start LocalStack Pro.\n","excerpt":"Use your API key to start LocalStack Pro.\n","ref":"/get-started/pro/","tags":"","title":"LocalStack Pro"},{"body":"Unlike the open source LocalStack, which uses a single hardcoded account ID (000000000000), the Pro version allows to use multiple instances for different AWS account IDs in parallel.\nIn order to set up a multi-account environment, simply configure the TEST_AWS_ACCOUNT_ID to include a comma-separated list of account IDs. For example, use the following to start up LocalStack with two account IDs: $ TEST_AWS_ACCOUNT_ID=000000000001,000000000002 SERVICES=s3 localstack start\nYou can then use AWS_ACCESS_KEY_ID to address resources in the two separate account instances: $ AWS_ACCESS_KEY_ID=000000000001 aws --endpoint-url=http://localhost:4566 s3 mb s3://bucket-account-one make_bucket: bucket-account-one $ AWS_ACCESS_KEY_ID=000000000002 aws --endpoint-url=http://localhost:4566 s3 mb s3://bucket-account-two make_bucket: bucket-account-two $ AWS_ACCESS_KEY_ID=000000000001 aws --endpoint-url=http://localhost:4566 s3 ls 2020-05-24 17:09:41 bucket-account-one $ AWS_ACCESS_KEY_ID=000000000002 aws --endpoint-url=http://localhost:4566 s3 ls 2020-05-24 17:09:53 bucket-account-two\nNote that using an invalid account ID should result in a 404 (not found) error response from the API: $ AWS_ACCESS_KEY_ID=123000000123 aws --endpoint-url=http://localhost:4566 s3 ls An error occurred (404) when calling the ListBuckets operation: Not Found\nNote: For now, the account ID is encoded directly in the AWS_ACCESS_KEY_ID client-side variable, for simplicity. In a future version, we will support proper access key IDs issued by the local IAM service, which will then internally be translated to corresponding account IDs.  ","categories":["LocalStack Pro"],"description":"Multi-Account Setups\n","excerpt":"Multi-Account Setups\n","ref":"/aws/multi-account-setups/","tags":"","title":"Multi-Account Setups"},{"body":"While the open source version of LocalStack can only be configured to use a single region (e.g., us-east-1), the Pro version contains several extensions that allow resources to be addressed across regions, using their unique ARN identifiers.\n","categories":["LocalStack Pro","Stub"],"description":"Multi-Region Support\n","excerpt":"Multi-Region Support\n","ref":"/aws/multi-region-support/","tags":"","title":"Multi-Region Support"},{"body":"The Neptune API provides a graph database to store nodes and edges that can be accessed via Apache TinkerPop and Gremlin queries.\nFor example, you can create a Neptune cluster like this:\nimport boto3 from gremlin_python.driver import client as gremlin_client client = boto3.client('neptune', endpoint_url='http://localhost:4566') cluster = client.create_db_cluster(DBClusterIdentifier='c1', Engine='neptune')['DBCluster'] cluster_url = 'ws://localhost:%s/gremlin' % cluster['Port'] graph_client = gremlin_client.Client(cluster_url, 'g') … and then submit and query values to the DB like this:\nvalues = '[1,2,3,4]' result_set = graph_client.submit(values) results = result_set.all().result() assert results == [1, 2, 3, 4] For a simple Neptune sample running on LocalStack, please refer to this Github repository.\n","categories":["LocalStack Pro"],"description":"Amazon Neptune\n","excerpt":"Amazon Neptune\n","ref":"/aws/neptune/","tags":"","title":"Neptune"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/observability/","tags":"","title":"observability"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/persistence/","tags":"","title":"Persistence"},{"body":"Overview The AWS SDK for PHP, like other AWS SDKs, lets you set the endpoint when creating resource clients, which is the preferred way of integrating the PHP SDK with LocalStack.\nExample Here is an example of how to create an S3Client with the endpoint set to LocalStack.\nuse Aws\\S3\\S3Client; use Aws\\Exception\\AwsException; // Configuring S3 Client $s3 = new Aws\\S3\\S3Client([ 'version' =\u003e '2006-03-01', 'region' =\u003e 'us-east-1', // Enable 'use_path_style_endpoint' =\u003e true, if bucket name is non DNS compliant  'use_path_style_endpoint' =\u003e true, 'endpoint' =\u003e 'http://s3.localhost.localstack.cloud:4566', ]); A full example can be found in our samples repository.\nResources  localstack-aws-sdk-examples for PHP AWS SDK for PHP Official repository of the AWS SDK for PHP  ","categories":"","description":"How to use the PHP AWS SDK with LocalStack.\n","excerpt":"How to use the PHP AWS SDK with LocalStack.\n","ref":"/integrations/sdks/php/","tags":["sdk"],"title":"PHP"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/pulumi/","tags":"","title":"pulumi"},{"body":"Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of AWS services.\nYou can easily create a boto3 client that interacts with your LocalStack instance. The example below creates a boto3 client that lists all available Lambda functions:\nimport boto3 endpoint_url = \"http://localhost.localstack.cloud:4566\" # alternatively, to use HTTPS endpoint on port 443: # endpoint_url = \"https://localhost.localstack.cloud\" def main(): client = boto3.client(\"lambda\", endpoint_url=endpoint_url) result = client.list_functions() print(result) if __name__ == \"__main__\": main() Note: If you’re connecting from within a Python Lambda function handler in LocalStack, you can create a default client without configuring the endpoint_url - LocalStack will automatically forward the invocations to the local API endpoints (available in Pro, see here for more details).\nclient = boto3.client(\"lambda\") ... Alternatively, if you prefer to (or need to) set the endpoints directly, you can use the $LOCALSTACK_HOSTNAME environment variable which is available when executing user code (e.g., Lambda functions, ECS containers) in LocalStack:\nimport os endpoint_url = f\"http://{os.getenv(\"LOCALSTACK_HOSTNAME\")}:{os.getenv(\"EDGE_PORT\")}\" client = boto3.client(\"lambda\", endpoint_url=endpoint_url) ... Further Material:  localstack-python-client: small Python library with additional utils for interacting with LocalStack  ","categories":"","description":"How to use the Boto3 Python AWS SDK with LocalStack.\n","excerpt":"How to use the Boto3 Python AWS SDK with LocalStack.\n","ref":"/integrations/sdks/python/","tags":["sdk"],"title":"Python Boto3"},{"body":"The Quantum Ledger Database (QLDB) API supports queries over cryptographically verifiable data, stored in a journal of immutable transaction events. LocalStack allows to create local ledgers and journals, to perform CREATE TABLE statements, to insert data via INSERT statements, and to query data via SELECT statements.\nQLDB uses the Amazon ION data format, a data serialization format that represents a superset of JSON, with a number of additional features.\nA simple QLDB example running on LocalStack is provided in this Github repository. The sample consists of two simple scenarios: (1) to create and list tables via the pyqldb Python library, and (2) to insert data into two tables and perform a JOIN query that combines data from the two tables. The sample output is posted below:\nScenario 1: create and list tables in ledger ----------- Creating new test ledger in QLDB API: ledger-test-1 Creating two test tables in ledger Retrieved list of tables in ledger ledger-test-1: ['foobar1', 'foobar2'] ----------- Scenario 2: create ledger tables and run join query ----------- Creating two test tables in ledger - \"Vehicle\" and \"VehicleRegistration\" Running a query that joins data from the two tables Query result: [{'Vehicle': {'id': 'v1'}}, {'Vehicle': {'id': 'v2'}}, {'Vehicle': {'id': 'v3'}}] ","categories":["LocalStack Pro"],"description":"Quantum Ledger Database (QLDB)\n","excerpt":"Quantum Ledger Database (QLDB)\n","ref":"/aws/qldb/","tags":"","title":"Quantum Ledger Database (QLDB)"},{"body":"LocalStack supports a basic version of RDS for testing. Currently, it is possible to spin up PostgreSQL databases on the local machine; support for MySQL and other DB engines is under development and coming soon.\nThe local RDS service also supports the RDS Data API, which allows executing data queries over a JSON/REST interface. Below is a simple example that illustrates (1) creation of an RDS database, (2) creation of a SecretsManager secret with the DB password, and (3) running a simple SELECT 123 query via the RDS Data API. $ awslocal rds create-db-instance --db-instance-identifier db1 --db-instance-class c1 --engine postgres ... $ awslocal secretsmanager create-secret --name dbpass --secret-string test { \"ARN\": \"arn:aws:secretsmanager:eu-central-1:1234567890:secret:dbpass-cfnAX\", \"Name\": \"dbpass\", \"VersionId\": \"fffa1f4a-2381-4a2b-a977-4869d59a16c0\" } $ awslocal rds-data execute-statement --database test --resource-arn arn:aws:rds:eu-central-1:000000000000:db:db1 --secret-arn arn:aws:secretsmanager:eu-central-1:1234567890:secret:dbpass-cfnAX --sql 'SELECT 123' { \"columnMetadata\": [{ \"name\": \"?column?\", \"type\": 23 }], \"records\": [[ { \"doubleValue\": 123 } ]] }\n","categories":["LocalStack Pro"],"description":"Relational Database Service (RDS)\n","excerpt":"Relational Database Service (RDS)\n","ref":"/aws/rds/","tags":"","title":"Relational Database Service (RDS)"},{"body":"The Route53 API in LocalStack Pro allows you to create hosted zones and to manage DNS entries (e.g., A records) which can then be queried via the built-in DNS server.\nThe example below illustrates the creation of a hosted zone example.com, registration of an A record named test.example.com that points to 1.2.3.4, and finally querying the DNS record by using the dig command against the DNS server running on localhost (inside the LocalStack container, on port 53): $ zone_id=$(awslocal route53 create-hosted-zone --name example.com --caller-reference r1 | jq -r '.HostedZone.Id') $ awslocal route53 change-resource-record-sets --hosted-zone-id $zone_id --change-batch 'Changes=[{Action=CREATE,ResourceRecordSet={Name=test.example.com,Type=A,ResourceRecords=[{Value=1.2.3.4}]}}]' $ dig @localhost test.example.com ... ;; ANSWER SECTION: test.example.com.\t300\tIN\tA\t1.2.3.4\nNote: Using the built-in DNS capabilities requires privileged access for the LocalStack container (please also refer to the DNS_ADDRESS configuration variable).  ","categories":["LocalStack Pro"],"description":"Route 53\n","excerpt":"Route 53\n","ref":"/aws/route53/","tags":"","title":"Route 53"},{"body":"AWS S3 is a managed scalable object storage service that can be used to store any amount of data for a wide range of use cases.\nS3 is shipped with the LocalStack Community version and is extensively supported. Trying to run the examples in the official AWS developer guide against LocalStack is a great place to start.\nAssuming you have awslocal installed you can also try the following commands:\n$ awslocal s3api create-bucket --bucket sample-bucket { \"Location\": \"/sample-bucket\" } $ awslocal s3api list-buckets { \"Buckets\": [ { \"Name\": \"sample-bucket\", \"CreationDate\": \"2021-10-05T10:48:38+00:00\" } ], \"Owner\": { \"DisplayName\": \"webfile\", \"ID\": \"bcaf1ffd86f41161ca5fb16fd081034f\" } $ awslocal s3api put-object --bucket sample-bucket --key index.html --body index.html { \"ETag\": \"\\\"d41d8cd98f00b204e9800998ecf8427e\\\"\" } When working with the SERVICES environment variable, please make sure to include s3 in the list of services. For instance, to load the S3, SQS, and Kinesis service you’d pass the variable as SERVICES=s3,sqs,kinesis.\nPath-Style Requests versus Virtual Hosted-Style Requests  Just like AWS, LocalStack differentiates between Path-Style and Virtual Hosted-Style Requests depending on your Host header for a request.\nExample:\n\u003cbucket-name\u003e.s3.\u003cregion\u003e.localhost.localstack.cloud # host-style request \u003cbucket-name\u003e.s3.\u003cregion\u003e.amazonaws.com # host-style request As a special case in LocalStack, leaving out .s3.\u003cregion\u003e also works for the localhost.localstack.cloud domain:\n\u003cbucket-name\u003e.localhost.localstack.cloud is also a host-style request.\nAll other requests will be considered path-style requests.\n ","categories":["LocalStack Community"],"description":"S3\n","excerpt":"S3\n","ref":"/aws/s3/","tags":"","title":"S3"},{"body":"LocalStack Pro provides a local version of the SageMaker API, which allows running jobs to create machine learning models (e.g., using TensorFlow).\nA basic example using the sagemaker.tensorflow.TensorFlow class is provided in this Github repository. Essentially, the code boils down to these core lines:\ninputs = ... # load training data files mnist_estimator = TensorFlow(entry_point='mnist.py', role='arn:aws:...', framework_version='1.12.0', sagemaker_session=sagemaker_session, train_instance_count=1, training_steps=10, evaluation_steps=10) mnist_estimator.fit(inputs, logs=False) The code snippet above uploads the model training code to local S3, submits a new training job to the local SageMaker API, and finally puts the trained model back to an output S3 bucket. Please refer to the sample repo for more details.\nNote: SageMaker is a fairly comprehensive API - for now, only a subset of the functionality is provided locally, but new features are being added on a regular basis.  ","categories":["LocalStack Pro"],"description":"SageMaker\n","excerpt":"SageMaker\n","ref":"/aws/sagemaker/","tags":"","title":"SageMaker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sam/","tags":"","title":"sam"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sdk/","tags":"","title":"sdk"},{"body":"The Pro version ships with extended support Simple Email Service (SES), including a simple user interface to inspect email accounts and sent messages, as well as support for sending SES messages through an actual SMTP email server.\nPlease refer to the Configuration section for instructions on how to configure the connection parameters of your SMTP server (SMTP_HOST/SMTP_USER/SMTP_PASS).\nOnce your SMTP server has been configured, you can use the SES user interface in the Web app to create a new email account (e.g., user1@yourdomain.com), and then send an email via the command line (or your SES client SDK): $ awslocal ses send-email --from user1@yourdomain.com --message 'Body={Text={Data=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, ...\"}},Subject={Data=Test Email}' --destination 'ToAddresses=recipient1@example.com'\nThe Web user interface then allows you to interactively browse through the sent email messages, as illustrated in the screenshot below:\n","categories":["LocalStack Pro"],"description":"Simple Email Service (SES)\n","excerpt":"Simple Email Service (SES)\n","ref":"/aws/ses/","tags":"","title":"Simple Email Service (SES)"},{"body":"AWS SQS is a fully managed distributed message queuing service. SQS is shipped with the LocalStack Community version and is extensively supported.\nExample Trying to run the examples in the official AWS developer guide against LocalStack is a great place to start. Assuming you have awslocal installed you can also try the following commands:\n$ awslocal sqs create-queue --queue-name sample-queue { \"QueueUrl\": \"http://localhost:4566/000000000000/sample-queue\" } $ awslocal sqs list-queues { \"QueueUrls\": [ \"http://localhost:4566/000000000000/sample-queue\" ] } $ awslocal sqs send-message --queue-url http://localhost:4566/00000000000/sample-queue --message-body test { \"MD5OfMessageBody\": \"098f6bcd4621d373cade4e832627b4f6\", \"MessageId\": \"74861aab-05f8-0a75-ae20-74d109b7a76e\" } Providers LocalStack supports two third-party providers for SQS - namely, moto and elasticmq. By default, moto is used. Your desired provider can be set with the environment variable SQS_PROVIDER.\nFor instance, if you wish to use elasticmq you’d pass the environment variable as SQS_PROVIDER=elasticmq.\nElasticMQ only supports a subset of the SQS query (only the REST query interface). However, it provides better scalability for local development and test servers that wish to create realistic scenarios in which lots of messages are sent with a high throughput. On the other hand, moto has near-complete support for SQS but has limited scalability.\nPersistence Support As of now the LocalStack Pro persistence mechanism is only supported for moto.  ","categories":["LocalStack Community"],"description":"Explaining the different SQS providers and how to configure the service.\n","excerpt":"Explaining the different SQS providers and how to configure the …","ref":"/aws/sqs/","tags":"","title":"Simple Queue Service (SQS)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/stub/","tags":"","title":"Stub"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/terraform/","tags":"","title":"terraform"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/testing/","tags":"","title":"testing"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/thundra/","tags":"","title":"thundra"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/tools/","tags":"","title":"Tools"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/tracing/","tags":"","title":"tracing"},{"body":"The AWS Transfer API provides the ability to create FTP(S) servers to make files in S3 buckets accessible directly via FTP.\nA simple example using AWS Transfer is included in this Github repository. The sample creates an FTP server via the Transfer API locally, uploads two files via FTP to S3, and then finally downloads the files from the target S3 bucket.\nNote: The Transfer API does not provide a way to return the endpoint URL of created FTP servers. Hence, in order to determine the server endpoint, the local port is encoded as a suffix in the ServerId attribute, using the pattern s-\u003cid\u003e:\u003cport\u003e. For example, assume the following is the response from the CreateServer API call, then the FTP server is accessible on port 4511 (i.e., ftp://localhost:4511):\n{ \"ServerId\": \"s-73c53daf86da4:4511\" }   ","categories":["LocalStack Pro"],"description":"Transfer\n","excerpt":"Transfer\n","ref":"/aws/transfer/","tags":"","title":"Transfer"},{"body":"LocalStack Pro allows to instrument your applications using XRay tracing. This helps in optimizing the interactions between service calls, and facilitates debugging of performance bottlenecks.\nFor example, a Python Lambda function can be instrumented as follows (based on the example here):\nimport boto3 from aws_xray_sdk.core import xray_recorder from aws_xray_sdk.core import patch patch(['boto3']) s3_client = boto3.client('s3') def lambda_handler(event, context): s3_client.create_bucket(Bucket='mybucket') xray_recorder.begin_subsegment('my_code') # your function code goes here... xray_recorder.end_subsegment() Running this code in Lambda on LocalStack will result in two trace segments being created in XRay - one from the instrumented boto3 client when running create_bucket(..), and one for the custom subsegment denoted 'my_code'. You can use the regular XRay API calls (e.g., GetTraceSummaries, BatchGetTraces) to retrieve the details (timestamps, IDs, etc) of these segments.\n","categories":["LocalStack Pro"],"description":"XRay Tracing\n","excerpt":"XRay Tracing\n","ref":"/aws/xray-tracing/","tags":"","title":"XRay Tracing"}]